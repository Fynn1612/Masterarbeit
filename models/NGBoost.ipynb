{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NGBoost for outputting Probalitiy Distribution instead of single value\n",
    "\n",
    "https://stanfordmlgroup.github.io/ngboost/1-useage.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary imports\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ngboost import NGBRegressor\n",
    "from ngboost.scores import LogScore\n",
    "from ngboost.distns import  Normal\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import uncertainty_toolbox as uct\n",
    "\n",
    "# check the computer name and set the path accordingly\n",
    "if os.environ['COMPUTERNAME'] == 'FYNN':            # name of surface PC\n",
    "    sys.path.append(r'C:\\Users\\Surface\\Masterarbeit')\n",
    "elif os.environ['COMPUTERNAME'] == 'FYNNS-PC':  # desktop name\n",
    "    sys.path.append(r'C:\\Users\\test\\Masterarbeit')\n",
    "    \n",
    "else:\n",
    "    raise ValueError(\"Unbekannter Computername: \" + os.environ['COMPUTERNAME'])\n",
    "\n",
    "from utils.data_prep import load_tranform_and_split_data, set_seed\n",
    "from utils.metrics import evaluate_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading and Preprocessing to compare the algorithms, although Decision Trees are not sensitve to feature scalling, they do not use geometric distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and transform the data, split it into training, validation, and test sets\n",
    "# uses random state 42 internally for reproducibility\n",
    "# the split ratio is 60% training, 20% validation, and 20%\n",
    "# return the feature names for later use\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, feature_names = load_tranform_and_split_data('C1_V01_delta_kan', \n",
    "                                                                                                       split_ratio=(0.6, 0.2, 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # Define the hyperparameters to tune\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 1000, step = 50)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2,log=True)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 4, 20)\n",
    "    \n",
    "    # Create the NGBRegressor model with the suggested hyperparameters\n",
    "    ngb = NGBRegressor(\n",
    "        Dist=Normal, \n",
    "        Score=LogScore, \n",
    "        Base=DecisionTreeRegressor(criterion='friedman_mse', max_depth=max_depth),\n",
    "        verbose=False, \n",
    "        n_estimators=n_estimators, \n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    ngb.fit(X_train, y_train, X_val=X_val, Y_val=y_val, early_stopping_rounds=20)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_preds = ngb.predict(X_val)\n",
    "    y_dists = ngb.pred_dist(X_val)\n",
    "    \n",
    "    # Calculate the negative log likelihood\n",
    "    nll = -y_dists.logpdf(y_val).mean()\n",
    "    rmse = root_mean_squared_error(y_val, y_preds)\n",
    "    print(f\"Trial {trial.number}: NLL={nll}, RMSE={rmse}\")\n",
    "    \n",
    "    return nll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=optuna.samplers.TPESampler(),  # Use TPE sampler for hyperparameter optimization\n",
    "    pruner=optuna.pruners.MedianPruner(        \n",
    "        n_startup_trials=20,                                    # Number of trials to run before pruning starts\n",
    "        n_warmup_steps=5                                        # Number of warmup steps before pruning starts\n",
    "    )\n",
    ")\n",
    "study.optimize(objective, n_trials=200, timeout=None, n_jobs=1, show_progress_bar=True)\n",
    "\n",
    "print(study.best_params)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do 10 Runs for a more representative Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "predictions_list = []\n",
    "list_of_seeds = [42, 123, 777, 2024, 5250, 8888, 9876, 10001, 31415, 54321]\n",
    "ngb_prediction_path = r\"C:\\Users\\test\\Masterarbeit\\models\\Modelresults\\NGBoost\"\n",
    "ngb_result_path = r\"C:\\Users\\test\\OneDrive\\Master Management und Engineering\\Masterarbeit\\Experimente\\Evaluation\\10 Runs\\NGBoost\"\n",
    "\n",
    "for run, seed in enumerate(list_of_seeds):\n",
    "\n",
    "    print(f\"Run {run+1} with seed {seed}\")\n",
    "    set_seed(seed)\n",
    "\n",
    "    # Define model, use seed to intialize the base learner and ngboost\n",
    "    ngb = NGBRegressor(Dist=Normal, \n",
    "                        Score = LogScore, \n",
    "                        Base = DecisionTreeRegressor(criterion='friedman_mse',\n",
    "                                                        max_depth=9,\n",
    "                                                        random_state=seed), \n",
    "                        verbose = True, \n",
    "                        n_estimators=750, \n",
    "                        learning_rate=0.003,\n",
    "                        random_state=seed)\n",
    "    \n",
    "    # Train and evaluate the model\n",
    "    ngb.fit(X_train, y_train, X_val=X_val, Y_val=y_val, early_stopping_rounds=50)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    y_test_preds = ngb.predict(X_test)\n",
    "    y_test_dists = ngb.pred_dist(X_test)\n",
    "    # Extract standard deviation from test predictions\n",
    "    test_stddev = y_test_dists.scale\n",
    "\n",
    "    # Calculate and print all metrics inclunding RMSE, MAE, R²-Score, NLL, CRPS\n",
    "    pnn_metrics = uct.metrics.get_all_metrics( y_test_preds, test_stddev,y_test)\n",
    "    print(pnn_metrics)\n",
    "\n",
    "    # use own function to calculate coverage and MPIW\n",
    "    ev_intervals = evaluate_intervals(y_test_preds, test_stddev, y_test, coverage=0.95)\n",
    "    print(f'coverage: {ev_intervals[\"coverage\"]}, MPIW: {ev_intervals[\"MPIW\"]}')\n",
    "\n",
    "    predictions_per_run = {\n",
    "        'mean_prediction': y_test_preds,\n",
    "        'std_prediction': test_stddev,\n",
    "    }\n",
    "\n",
    "    results_per_run = {\n",
    "    'RMSE': pnn_metrics['accuracy']['rmse'],\n",
    "    'MAE': pnn_metrics['accuracy']['mae'],\n",
    "    'R2': pnn_metrics['accuracy']['r2'], \n",
    "    'Correlation' : pnn_metrics['accuracy']['corr'],\n",
    "    'NLL': pnn_metrics['scoring_rule']['nll'],\n",
    "    'CRPS': pnn_metrics['scoring_rule']['crps'],\n",
    "    'coverage': ev_intervals[\"coverage\"],\n",
    "    'MPIW': ev_intervals[\"MPIW\"],\n",
    "    }\n",
    "\n",
    "    predictions_list.append(predictions_per_run)\n",
    "    results_list.append(results_per_run)\n",
    "#save the predictions \n",
    "with open(os.path.join(ngb_prediction_path, \"ngboost_predictions_list.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(predictions_list, f)\n",
    "\n",
    "#save the results in an excel file\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df.to_excel(os.path.join(ngb_result_path, \"ngboost_results.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb_prediction_path = r\"C:\\Users\\test\\Masterarbeit\\models\\Modelresults\\NGBoost\"\n",
    "ngb_result_path = r\"C:\\Users\\test\\OneDrive\\Master Management und Engineering\\Masterarbeit\\Experimente\\Evaluation\\10 Runs\\NGBoost\"\n",
    "\n",
    "with open(os.path.join(ngb_prediction_path, \"ngboost_predictions_list.pkl\"), \"rb\") as f:\n",
    "    predictions_list = pickle.load(f)\n",
    "\n",
    "mean_list = []\n",
    "std_list = []\n",
    "\n",
    "for id, run in enumerate(predictions_list):\n",
    "    # extract mean and std predictions\n",
    "    mean = run['mean_prediction']\n",
    "    std = run['std_prediction']\n",
    "    \n",
    "    # append to lists\n",
    "    mean_list.append(mean)\n",
    "    std_list.append(std)\n",
    "    \n",
    "    # calibration Curve with UCT\n",
    "    uct.viz.plot_calibration(mean, std, y_test)\n",
    "    plt.savefig(os.path.join(ngb_result_path, f\"calibration_run_{id+1}.svg\"), format ='svg')\n",
    "    plt.savefig(os.path.join(ngb_result_path, f\"calibration_run_{id+1}.png\"), format ='png')\n",
    "    plt.close()\n",
    "\n",
    "    # adversarial group calibration\n",
    "    uct.viz.plot_adversarial_group_calibration(mean, std, y_test)\n",
    "    plt.savefig(os.path.join(ngb_result_path, f\"adversarial_group_calibration_run_{id+1}.svg\"), format ='svg')\n",
    "    plt.savefig(os.path.join(ngb_result_path, f\"adversarial_group_calibration_run_{id+1}.png\"), format ='png')\n",
    "    plt.close()\n",
    "\n",
    "# predictions_list enthält pro Run ein Array mit 10403 Werten\n",
    "mean_matrix = np.array(mean_list)  # Shape: (n_runs, 10403)\n",
    "std_matrix = np.array(std_list)    # Shape: (n_runs, 10403)\n",
    "\n",
    "# Mittelwert und Std für jeden Datenpunkt über alle Runs\n",
    "mean_per_datapoint = np.mean(mean_matrix, axis=0)  # Shape: (10403,)\n",
    "std_per_datapoint = np.mean(std_matrix, axis=0)    # Shape: (10403,)\n",
    "\n",
    "# calibration Curve with UCT\n",
    "uct.viz.plot_calibration(mean_per_datapoint, std_per_datapoint, y_test)\n",
    "plt.savefig(os.path.join(ngb_result_path, \"calibration_run_mean.svg\"), format ='svg')\n",
    "plt.savefig(os.path.join(ngb_result_path, \"calibration_run_mean.png\"), format ='png')\n",
    "plt.close()\n",
    "\n",
    "# adversarial group calibration\n",
    "uct.viz.plot_adversarial_group_calibration(mean_per_datapoint, std_per_datapoint, y_test)\n",
    "plt.savefig(os.path.join(ngb_result_path, \"adversarial_group_calibration_run_mean.svg\"), format ='svg')\n",
    "plt.savefig(os.path.join(ngb_result_path, \"adversarial_group_calibration_run_mean.png\"), format ='png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train one model for feature importance extraction\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "ngb = NGBRegressor(Dist=Normal, \n",
    "                   Score = LogScore, \n",
    "                   Base = DecisionTreeRegressor(criterion='friedman_mse',                                                \n",
    "                                                 max_depth=9,\n",
    "                                                 random_state=SEED), \n",
    "                   verbose = True, \n",
    "                   n_estimators=750, \n",
    "                   learning_rate=0.003,\n",
    "                   random_state=SEED)\n",
    "\n",
    "ngb.fit(X_train, y_train, X_val=X_val, Y_val=y_val, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change feature names to categories\n",
    "feature_names_cat = ['act_mach_param_1', 'act_mach_param_2', 'env_param_1', 'env_param_2', 'env_param_3',\n",
    "       'env_param_4', 'env_param_5', 'env_param_6', 'env_param_7', 'env_param_8', 'env_param_9', 'env_param_10', 'env_param_11', 'env_param_12',\n",
    "       'env_param_13', 'env_param_14', 'env_param_15', 'time_param_1 ', 'time_param_2',\n",
    "       'time_param_3', 'time_param_4', 'time_param_5', 'time_param_6', 'time_param_7',\n",
    "       'time_param_8', 'time_param_9', 'time_param_10', 'time_param_11', 'time_param_12',\n",
    "       'time_param_13', 'diff_param_1', 'diff_param_2',\n",
    "       'diff_param_3', 'diff_param_4', 'diff_param_5', 'comp_param_1', 'comp_param_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "ngb_result_path = r\"C:\\Users\\test\\OneDrive\\Master Management und Engineering\\Masterarbeit\\Experimente\\Evaluation\\10 Runs\\NGBoost\"\n",
    "\n",
    "feature_importance_loc = ngb.feature_importances_[:, 0]  # Importance for mean prediction\n",
    "feature_importance_scale = ngb.feature_importances_[:, 1]  # Importance for standard deviation prediction\n",
    "\n",
    "df_loc = pd.DataFrame({\n",
    "                       'feature':feature_names_cat,\n",
    "                       'importance':feature_importance_loc})\\\n",
    "                        .sort_values('importance',ascending=False)\n",
    "df_scale = pd.DataFrame({   \n",
    "                         'feature':feature_names_cat,\n",
    "                         'importance':feature_importance_scale})\\\n",
    "                        .sort_values('importance',ascending=False)\n",
    "\n",
    "# Feature importance for mean prediction\n",
    "fig1, ax1 = plt.subplots(figsize=(10,8))\n",
    "sns.barplot(x='importance',y='feature',data=df_loc)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(\"C:\\\\Users\\\\Surface\\\\OneDrive\\\\Master Management und Engineering\\\\Masterarbeit\\\\Experimente\", \"feature_importance_mean.svg\"), format ='svg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Feature importance for std prediction\n",
    "fig2, ax2 = plt.subplots(figsize=(10,8))\n",
    "sns.barplot(x='importance',y='feature',data=df_scale)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(\"C:\\\\Users\\\\Surface\\\\OneDrive\\\\Master Management und Engineering\\\\Masterarbeit\\\\Experimente\", \"feature_importance_std.svg\"), format ='svg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
