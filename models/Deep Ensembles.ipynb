{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d0d3b88",
   "metadata": {},
   "source": [
    "Heteroscedastic Implementation of Deep Ensembles\n",
    "\n",
    "no adversarial Training is used\n",
    "\n",
    "Most of the code inspired by:\n",
    "https://github.com/cameronccohen/deep-ensembles/blob/master/Tutorial.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0981020c",
   "metadata": {},
   "source": [
    "Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23cc680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import uncertainty_toolbox as uct\n",
    "\n",
    "# define the device for the setting\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# check the computer name and set the path accordingly\n",
    "if os.environ['COMPUTERNAME'] == 'FYNN':            # name of surface PC\n",
    "    sys.path.append(r'C:\\Users\\Surface\\Masterarbeit')\n",
    "elif os.environ['COMPUTERNAME'] == 'FYNNS-PC':  # desktop name\n",
    "    sys.path.append(r'C:\\Users\\test\\Masterarbeit')\n",
    "    \n",
    "else:\n",
    "    raise ValueError(\"Unbekannter Computername: \" + os.environ['COMPUTERNAME'])\n",
    "\n",
    "from utils.data_prep import load_tranform_and_split_data, set_seed\n",
    "from utils.metrices import evaluate_intervals\n",
    "from utils.NN_model import Custom_NN_Model, train_model, heteroscedastic_loss\n",
    "from utils.NN_model import create_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9405e4f5",
   "metadata": {},
   "source": [
    "Load, Transform and Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35e781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and transform the data, split it into training, validation, and test sets\n",
    "# the split ratio is 60% training, 20% validation, and 20%\n",
    "# return the feature names for later use\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, feature_names = load_tranform_and_split_data('C1_V01_delta_kan', split_ratio=(0.6, 0.2, 0.2))\n",
    "\n",
    "# convert the data to PyTorch tensors\n",
    "# and add an extra dimension for the target variable\n",
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "X_val_tensor = torch.from_numpy(X_val).float()\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float().reshape(-1,1) # Add extra dimension for compatibility\n",
    "y_val_tensor = torch.from_numpy(y_val).float().reshape(-1,1)\n",
    "y_test_tensor = torch.from_numpy(y_test).float().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b2c5d5",
   "metadata": {},
   "source": [
    "Optuna Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d5b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    # hyperparameter for sampling with Optuna\n",
    "    n_layer = trial.suggest_int(\"n_layer\", 2, 5)  # number of hidden layers\n",
    "    n_neurons = trial.suggest_int(\"n_neurons\", 64, 320, step=32)  # number of neurons in each hidden layer\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)    # learning rate\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [64, 128]) \n",
    "    decay = trial.suggest_float('decay', 0.5, 0.7, step = 0.1)\n",
    "\n",
    "    # decay factor for the number of neurons in each layer\n",
    "    # e.g. if n_neurons = 256 and n_layer = 3\n",
    "    # then the hidden_dims will be [256, 128, 64]\n",
    "    # this creates a list of integers representing the number of neurons in each hidden layer\n",
    "    hidden_dims = [int(n_neurons * decay**i) for i in range(n_layer)]\n",
    "    print(f\"Hidden dimensions: {hidden_dims}\")\n",
    "        \n",
    "    # generate the model with the sampled hyperparameters\n",
    "    # and move it to the device (GPU or CPU)\n",
    "    model = Custom_NN_Model(\n",
    "        input_dim=X_train_tensor.shape[1],\n",
    "        hidden_dims=hidden_dims,\n",
    "        output_dim=1,\n",
    "        do_rate=0,\n",
    "        loss_type = 'heteroscedastic'\n",
    "    ).to(device)\n",
    "\n",
    "    # AdamW optimizer, where weight decay does not accumulate in the momentum nor variance.\n",
    "    optimizer = torch.optim.AdamW(params = model.parameters(), lr = lr, weight_decay=0.0001)  \n",
    "\n",
    "    # DataLoader for batching the data\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # integrate early stopping\n",
    "    patience = 20  # number of epochs with no improvement after which training will be stopped\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    # training the model\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch = X_batch.to(device)  # Move data to the device (GPU or CPU)\n",
    "            y_batch = y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss = heteroscedastic_loss(model, X_batch, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # validation loss calculation after each epoch\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = heteroscedastic_loss(model, X_val_tensor, y_val_tensor)\n",
    "        \n",
    "        # report the validation loss to Optuna\n",
    "        trial.report(val_loss, step=epoch)\n",
    "        # handle pruning based on the intermediate value\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "           \n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}, Best Val Loss: {best_val_loss:.4f}\")\n",
    "                break\n",
    "    \n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074311a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epochs for training\n",
    "epochs = 500\n",
    "\n",
    "# create a study object for Optuna\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    sampler=optuna.samplers.TPESampler(),                       #TPE (Tree-structured Parzen Estimator) sampler by default\n",
    "    pruner=optuna.pruners.MedianPruner(        \n",
    "        n_startup_trials=20,                                    # Number of trials to run before pruning starts\n",
    "        n_warmup_steps=5                                        # Number of warmup steps before pruning starts)\n",
    "    )\n",
    ")\n",
    "\n",
    "# move the tensors to the device\n",
    "X_train_tensor = X_train_tensor.to(device)\n",
    "y_train_tensor = y_train_tensor.to(device)\n",
    "X_val_tensor = X_val_tensor.to(device)\n",
    "y_val_tensor = y_val_tensor.to(device)\n",
    "\n",
    "# optimize the objective function with Optuna\n",
    "# timeout=None means no time limit for the optimization, all trials will be run\n",
    "study.optimize(objective, n_trials=200, timeout=None, n_jobs=1, show_progress_bar=True)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89386231",
   "metadata": {},
   "source": [
    "Create an Ensemble, train it and make predictions\n",
    "\n",
    "best Model Architectur implemented:\n",
    "hidden_dims=[320,224,156]\n",
    "\n",
    "Best trial:\n",
    "  Value:  1.4413212537765503\n",
    "  Params: \n",
    "    n_layer: 3\n",
    "    n_neurons: 320\n",
    "    lr: 0.0004348009611810878\n",
    "    batch_size: 64\n",
    "    decay: 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98b6ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an ensemble of 5 networks with the defined net architecture and optimizer\n",
    "nets_ops = create_ensemble(2, input_dim = X_train.shape[1], hidden_dims=[320,224,156], \n",
    "                           do_rate=0, loss_type='heteroscedastic', lr=0.0004, weight_decay=0.0001)\n",
    "\n",
    "# lists to store the output means and log variances of each network in the ensemble\n",
    "outputs_mean = []\n",
    "outputs_log_var = []\n",
    "\n",
    "#train the ensemble of networks and make predictions on the test set\n",
    "for net, ops in nets_ops:\n",
    "    model = train_model(model= net, X_train_tensor=X_train_tensor, y_train_tensor=y_train_tensor,\n",
    "                        X_val_tensor= X_val_tensor, y_val_tensor=y_val_tensor, batch_size=64, \n",
    "                        optimizer=ops, n_epochs=1000, patience=50, loss_type='heteroscedastic',\n",
    "                        )\n",
    "    print(\"Model training mode:\", model.training)\n",
    "    # set the model to evaluation mode and make predictions on the test set\n",
    "    model.eval()   \n",
    "    print(\"Model training mode:\", model.training)\n",
    "    with torch.no_grad():\n",
    "        output_mean, output_log_var = model(X_test_tensor.to(device))\n",
    "        output_mean_np, output_log_var_np = output_mean.detach().cpu().numpy(), output_log_var.detach().cpu().numpy()\n",
    "        outputs_mean.append(output_mean_np)\n",
    "        outputs_log_var.append(np.exp(output_log_var_np))\n",
    "\n",
    "outputs_mean = np.array(outputs_mean)\n",
    "outputs_log_var = np.array(outputs_log_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fba33e",
   "metadata": {},
   "source": [
    "Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a719f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation of the predictions on the test data\n",
    "DE_mean = np.mean(outputs_mean, axis = 0).reshape(-1)\n",
    "\n",
    "# Calculate epistemic\n",
    "epistemic_var_heteroscedastic = np.var(outputs_mean, axis=0)\n",
    "print(f\"Epistemic Variance: {epistemic_var_heteroscedastic.mean():.6f}\")\n",
    "\n",
    "# Calculate aleatoric variance (heteroscedastic)\n",
    "aleatoric_var_heteroscedastic = np.mean(outputs_log_var, axis=0)\n",
    "print(f\"Aleatoric Variance: {aleatoric_var_heteroscedastic.mean():.6f}\")\n",
    "\n",
    "# Calculate total standard deviation\n",
    "DE_std = np.sqrt(epistemic_var_heteroscedastic + aleatoric_var_heteroscedastic).reshape(-1)\n",
    "\n",
    "# Calculate and print all metrics inclunding RMSE, MAE, R²-Score, NLL, CRPS\n",
    "pnn_metrics = uct.metrics.get_all_metrics( DE_mean, DE_std, y_test)\n",
    "print(pnn_metrics)\n",
    "print(pnn_metrics['accuracy']['rmse'])\n",
    "# Calculate coverage for 95% confidence interval\n",
    "coverage_95 = uct.metrics_calibration.get_proportion_in_interval(DE_mean, DE_std, y_test, quantile = 0.95 )\n",
    "print(f\"Coverage 95%: {coverage_95}\")\n",
    "\n",
    "# use own function to calculate coverage and MPIW\n",
    "ev_intervals = evaluate_intervals(DE_mean, DE_std, y_test, coverage=0.95)\n",
    "print(f'coverage: {ev_intervals[\"coverage\"]}, MPIW: {ev_intervals[\"MPIW\"]}')\n",
    "\n",
    "# calibration Curve with UCT\n",
    "uct.viz.plot_calibration(DE_mean, DE_std, y_test)\n",
    "\n",
    "# adversarial group calibration\n",
    "uct.viz.plot_adversarial_group_calibration(DE_mean, DE_std, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9f40cb",
   "metadata": {},
   "source": [
    "Evaluate Deep Ensemble predictions with 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb045a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1 with seed 42\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 142.1510, Val Loss: 5.5156, Best Val Loss: 5.5156\n",
      "Epoch 2/1000, Train Loss: 5.4695, Val Loss: 5.4248, Best Val Loss: 5.4248\n",
      "Epoch 3/1000, Train Loss: 5.3937, Val Loss: 5.3583, Best Val Loss: 5.3583\n",
      "Epoch 4/1000, Train Loss: 5.3288, Val Loss: 5.2952, Best Val Loss: 5.2952\n",
      "Epoch 5/1000, Train Loss: 5.2648, Val Loss: 5.2313, Best Val Loss: 5.2313\n",
      "Epoch 6/1000, Train Loss: 5.1928, Val Loss: 5.1450, Best Val Loss: 5.1450\n",
      "Epoch 7/1000, Train Loss: 5.0568, Val Loss: 4.9153, Best Val Loss: 4.9153\n",
      "Epoch 8/1000, Train Loss: 3.7240, Val Loss: 2.3674, Best Val Loss: 2.3674\n",
      "Epoch 9/1000, Train Loss: 2.2071, Val Loss: 2.1284, Best Val Loss: 2.1284\n",
      "Epoch 10/1000, Train Loss: 2.0266, Val Loss: 1.9779, Best Val Loss: 1.9779\n",
      "Epoch 11/1000, Train Loss: 1.9279, Val Loss: 1.9249, Best Val Loss: 1.9249\n",
      "Epoch 12/1000, Train Loss: 1.8630, Val Loss: 1.8318, Best Val Loss: 1.8318\n",
      "Epoch 13/1000, Train Loss: 1.8270, Val Loss: 1.8175, Best Val Loss: 1.8175\n",
      "Epoch 14/1000, Train Loss: 1.7861, Val Loss: 1.7813, Best Val Loss: 1.7813\n",
      "Epoch 15/1000, Train Loss: 1.7679, Val Loss: 1.7438, Best Val Loss: 1.7438\n",
      "Epoch 16/1000, Train Loss: 1.7418, Val Loss: 1.7127, Best Val Loss: 1.7127\n",
      "Epoch 18/1000, Train Loss: 1.7189, Val Loss: 1.7076, Best Val Loss: 1.7076\n",
      "Epoch 19/1000, Train Loss: 1.6995, Val Loss: 1.6964, Best Val Loss: 1.6964\n",
      "Epoch 20/1000, Train Loss: 1.6856, Val Loss: 1.6896, Best Val Loss: 1.6896\n",
      "Epoch 21/1000, Train Loss: 1.6860, Val Loss: 1.6644, Best Val Loss: 1.6644\n",
      "Epoch 23/1000, Train Loss: 1.6721, Val Loss: 1.6561, Best Val Loss: 1.6561\n",
      "Epoch 28/1000, Train Loss: 1.6316, Val Loss: 1.6491, Best Val Loss: 1.6491\n",
      "Epoch 29/1000, Train Loss: 1.6326, Val Loss: 1.6171, Best Val Loss: 1.6171\n",
      "Epoch 31/1000, Train Loss: 1.6136, Val Loss: 1.6087, Best Val Loss: 1.6087\n",
      "Epoch 36/1000, Train Loss: 1.5864, Val Loss: 1.5929, Best Val Loss: 1.5929\n",
      "Epoch 38/1000, Train Loss: 1.5755, Val Loss: 1.5553, Best Val Loss: 1.5553\n",
      "Epoch 47/1000, Train Loss: 1.5388, Val Loss: 1.5316, Best Val Loss: 1.5316\n",
      "Epoch 62/1000, Train Loss: 1.4905, Val Loss: 1.5098, Best Val Loss: 1.5098\n",
      "Epoch 80/1000, Train Loss: 1.4511, Val Loss: 1.5043, Best Val Loss: 1.5043\n",
      "Epoch 81/1000, Train Loss: 1.4442, Val Loss: 1.5028, Best Val Loss: 1.5028\n",
      "Epoch 87/1000, Train Loss: 1.4267, Val Loss: 1.4977, Best Val Loss: 1.4977\n",
      "Epoch 95/1000, Train Loss: 1.4166, Val Loss: 1.4736, Best Val Loss: 1.4736\n",
      "Epoch 118/1000, Train Loss: 1.4003, Val Loss: 1.4694, Best Val Loss: 1.4694\n",
      "Epoch 122/1000, Train Loss: 1.3683, Val Loss: 1.4691, Best Val Loss: 1.4691\n",
      "Early stopping at epoch 172, Best Val Loss: 1.4691\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 165.2325, Val Loss: 5.4124, Best Val Loss: 5.4124\n",
      "Epoch 2/1000, Train Loss: 5.3621, Val Loss: 5.3148, Best Val Loss: 5.3148\n",
      "Epoch 3/1000, Train Loss: 5.2822, Val Loss: 5.2471, Best Val Loss: 5.2471\n",
      "Epoch 4/1000, Train Loss: 5.2144, Val Loss: 5.1750, Best Val Loss: 5.1750\n",
      "Epoch 5/1000, Train Loss: 5.1080, Val Loss: 5.0058, Best Val Loss: 5.0058\n",
      "Epoch 6/1000, Train Loss: 4.1437, Val Loss: 2.4217, Best Val Loss: 2.4217\n",
      "Epoch 7/1000, Train Loss: 2.2318, Val Loss: 2.1062, Best Val Loss: 2.1062\n",
      "Epoch 8/1000, Train Loss: 2.0127, Val Loss: 1.9586, Best Val Loss: 1.9586\n",
      "Epoch 9/1000, Train Loss: 1.9073, Val Loss: 1.8927, Best Val Loss: 1.8927\n",
      "Epoch 10/1000, Train Loss: 1.8491, Val Loss: 1.8459, Best Val Loss: 1.8459\n",
      "Epoch 12/1000, Train Loss: 1.7778, Val Loss: 1.7564, Best Val Loss: 1.7564\n",
      "Epoch 14/1000, Train Loss: 1.7371, Val Loss: 1.7522, Best Val Loss: 1.7522\n",
      "Epoch 15/1000, Train Loss: 1.7256, Val Loss: 1.7275, Best Val Loss: 1.7275\n",
      "Epoch 17/1000, Train Loss: 1.6972, Val Loss: 1.7041, Best Val Loss: 1.7041\n",
      "Epoch 18/1000, Train Loss: 1.6867, Val Loss: 1.7003, Best Val Loss: 1.7003\n",
      "Epoch 19/1000, Train Loss: 1.6706, Val Loss: 1.6609, Best Val Loss: 1.6609\n",
      "Epoch 24/1000, Train Loss: 1.6360, Val Loss: 1.6412, Best Val Loss: 1.6412\n",
      "Epoch 30/1000, Train Loss: 1.6081, Val Loss: 1.6108, Best Val Loss: 1.6108\n",
      "Epoch 34/1000, Train Loss: 1.5875, Val Loss: 1.5709, Best Val Loss: 1.5709\n",
      "Epoch 46/1000, Train Loss: 1.5209, Val Loss: 1.5579, Best Val Loss: 1.5579\n",
      "Epoch 52/1000, Train Loss: 1.5094, Val Loss: 1.5468, Best Val Loss: 1.5468\n",
      "Epoch 55/1000, Train Loss: 1.4859, Val Loss: 1.5252, Best Val Loss: 1.5252\n",
      "Epoch 63/1000, Train Loss: 1.4670, Val Loss: 1.5246, Best Val Loss: 1.5246\n",
      "Epoch 69/1000, Train Loss: 1.4549, Val Loss: 1.5021, Best Val Loss: 1.5021\n",
      "Epoch 78/1000, Train Loss: 1.4278, Val Loss: 1.4930, Best Val Loss: 1.4930\n",
      "Epoch 81/1000, Train Loss: 1.4290, Val Loss: 1.4864, Best Val Loss: 1.4864\n",
      "Epoch 105/1000, Train Loss: 1.3854, Val Loss: 1.4806, Best Val Loss: 1.4806\n",
      "Early stopping at epoch 155, Best Val Loss: 1.4806\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 167.5436, Val Loss: 5.4986, Best Val Loss: 5.4986\n",
      "Epoch 2/1000, Train Loss: 5.4529, Val Loss: 5.4104, Best Val Loss: 5.4104\n",
      "Epoch 3/1000, Train Loss: 5.3757, Val Loss: 5.3390, Best Val Loss: 5.3390\n",
      "Epoch 4/1000, Train Loss: 5.2857, Val Loss: 5.2307, Best Val Loss: 5.2307\n",
      "Epoch 5/1000, Train Loss: 5.1812, Val Loss: 5.1224, Best Val Loss: 5.1224\n",
      "Epoch 6/1000, Train Loss: 4.9038, Val Loss: 4.1974, Best Val Loss: 4.1974\n",
      "Epoch 7/1000, Train Loss: 2.6824, Val Loss: 2.2995, Best Val Loss: 2.2995\n",
      "Epoch 8/1000, Train Loss: 2.1589, Val Loss: 2.0628, Best Val Loss: 2.0628\n",
      "Epoch 9/1000, Train Loss: 1.9994, Val Loss: 1.9471, Best Val Loss: 1.9471\n",
      "Epoch 10/1000, Train Loss: 1.9091, Val Loss: 1.8776, Best Val Loss: 1.8776\n",
      "Epoch 11/1000, Train Loss: 1.8587, Val Loss: 1.8402, Best Val Loss: 1.8402\n",
      "Epoch 12/1000, Train Loss: 1.8158, Val Loss: 1.8040, Best Val Loss: 1.8040\n",
      "Epoch 13/1000, Train Loss: 1.7863, Val Loss: 1.7953, Best Val Loss: 1.7953\n",
      "Epoch 14/1000, Train Loss: 1.7677, Val Loss: 1.7622, Best Val Loss: 1.7622\n",
      "Epoch 16/1000, Train Loss: 1.7301, Val Loss: 1.7131, Best Val Loss: 1.7131\n",
      "Epoch 17/1000, Train Loss: 1.7175, Val Loss: 1.6990, Best Val Loss: 1.6990\n",
      "Epoch 18/1000, Train Loss: 1.6974, Val Loss: 1.6908, Best Val Loss: 1.6908\n",
      "Epoch 22/1000, Train Loss: 1.6570, Val Loss: 1.6682, Best Val Loss: 1.6682\n",
      "Epoch 25/1000, Train Loss: 1.6392, Val Loss: 1.6650, Best Val Loss: 1.6650\n",
      "Epoch 27/1000, Train Loss: 1.6190, Val Loss: 1.6167, Best Val Loss: 1.6167\n",
      "Epoch 28/1000, Train Loss: 1.6105, Val Loss: 1.6121, Best Val Loss: 1.6121\n",
      "Epoch 32/1000, Train Loss: 1.5814, Val Loss: 1.6037, Best Val Loss: 1.6037\n",
      "Epoch 35/1000, Train Loss: 1.5677, Val Loss: 1.5781, Best Val Loss: 1.5781\n",
      "Epoch 40/1000, Train Loss: 1.5400, Val Loss: 1.5489, Best Val Loss: 1.5489\n",
      "Epoch 47/1000, Train Loss: 1.5083, Val Loss: 1.5387, Best Val Loss: 1.5387\n",
      "Epoch 56/1000, Train Loss: 1.4677, Val Loss: 1.5384, Best Val Loss: 1.5384\n",
      "Epoch 59/1000, Train Loss: 1.4628, Val Loss: 1.5183, Best Val Loss: 1.5183\n",
      "Epoch 61/1000, Train Loss: 1.4600, Val Loss: 1.5114, Best Val Loss: 1.5114\n",
      "Epoch 62/1000, Train Loss: 1.4510, Val Loss: 1.5079, Best Val Loss: 1.5079\n",
      "Epoch 65/1000, Train Loss: 1.4486, Val Loss: 1.4982, Best Val Loss: 1.4982\n",
      "Epoch 72/1000, Train Loss: 1.4291, Val Loss: 1.4972, Best Val Loss: 1.4972\n",
      "Epoch 79/1000, Train Loss: 1.4124, Val Loss: 1.4864, Best Val Loss: 1.4864\n",
      "Epoch 83/1000, Train Loss: 1.4038, Val Loss: 1.4767, Best Val Loss: 1.4767\n",
      "Epoch 95/1000, Train Loss: 1.3823, Val Loss: 1.4753, Best Val Loss: 1.4753\n",
      "Epoch 98/1000, Train Loss: 1.3835, Val Loss: 1.4738, Best Val Loss: 1.4738\n",
      "Epoch 105/1000, Train Loss: 1.3656, Val Loss: 1.4707, Best Val Loss: 1.4707\n",
      "Epoch 116/1000, Train Loss: 1.3420, Val Loss: 1.4698, Best Val Loss: 1.4698\n",
      "Epoch 123/1000, Train Loss: 1.3402, Val Loss: 1.4688, Best Val Loss: 1.4688\n",
      "Epoch 133/1000, Train Loss: 1.3297, Val Loss: 1.4583, Best Val Loss: 1.4583\n",
      "Early stopping at epoch 183, Best Val Loss: 1.4583\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 169.0705, Val Loss: 5.5546, Best Val Loss: 5.5546\n",
      "Epoch 2/1000, Train Loss: 5.5006, Val Loss: 5.4453, Best Val Loss: 5.4453\n",
      "Epoch 3/1000, Train Loss: 5.4082, Val Loss: 5.3640, Best Val Loss: 5.3640\n",
      "Epoch 4/1000, Train Loss: 5.3250, Val Loss: 5.2801, Best Val Loss: 5.2801\n",
      "Epoch 5/1000, Train Loss: 5.2314, Val Loss: 5.1742, Best Val Loss: 5.1742\n",
      "Epoch 6/1000, Train Loss: 5.0673, Val Loss: 4.8800, Best Val Loss: 4.8800\n",
      "Epoch 7/1000, Train Loss: 3.4578, Val Loss: 2.3928, Best Val Loss: 2.3928\n",
      "Epoch 8/1000, Train Loss: 2.2556, Val Loss: 2.1637, Best Val Loss: 2.1637\n",
      "Epoch 9/1000, Train Loss: 2.0756, Val Loss: 2.0178, Best Val Loss: 2.0178\n",
      "Epoch 10/1000, Train Loss: 1.9669, Val Loss: 1.9366, Best Val Loss: 1.9366\n",
      "Epoch 11/1000, Train Loss: 1.8946, Val Loss: 1.8698, Best Val Loss: 1.8698\n",
      "Epoch 12/1000, Train Loss: 1.8469, Val Loss: 1.8311, Best Val Loss: 1.8311\n",
      "Epoch 13/1000, Train Loss: 1.8060, Val Loss: 1.7983, Best Val Loss: 1.7983\n",
      "Epoch 14/1000, Train Loss: 1.7748, Val Loss: 1.7784, Best Val Loss: 1.7784\n",
      "Epoch 15/1000, Train Loss: 1.7587, Val Loss: 1.7739, Best Val Loss: 1.7739\n",
      "Epoch 16/1000, Train Loss: 1.7443, Val Loss: 1.7409, Best Val Loss: 1.7409\n",
      "Epoch 19/1000, Train Loss: 1.6990, Val Loss: 1.7237, Best Val Loss: 1.7237\n",
      "Epoch 20/1000, Train Loss: 1.6843, Val Loss: 1.7117, Best Val Loss: 1.7117\n",
      "Epoch 21/1000, Train Loss: 1.6832, Val Loss: 1.6820, Best Val Loss: 1.6820\n",
      "Epoch 23/1000, Train Loss: 1.6733, Val Loss: 1.6803, Best Val Loss: 1.6803\n",
      "Epoch 24/1000, Train Loss: 1.6700, Val Loss: 1.6762, Best Val Loss: 1.6762\n",
      "Epoch 25/1000, Train Loss: 1.6522, Val Loss: 1.6652, Best Val Loss: 1.6652\n",
      "Epoch 26/1000, Train Loss: 1.6517, Val Loss: 1.6438, Best Val Loss: 1.6438\n",
      "Epoch 27/1000, Train Loss: 1.6360, Val Loss: 1.6399, Best Val Loss: 1.6399\n",
      "Epoch 28/1000, Train Loss: 1.6304, Val Loss: 1.6077, Best Val Loss: 1.6077\n",
      "Epoch 36/1000, Train Loss: 1.5800, Val Loss: 1.5984, Best Val Loss: 1.5984\n",
      "Epoch 38/1000, Train Loss: 1.5819, Val Loss: 1.5752, Best Val Loss: 1.5752\n",
      "Epoch 42/1000, Train Loss: 1.5549, Val Loss: 1.5524, Best Val Loss: 1.5524\n",
      "Epoch 50/1000, Train Loss: 1.5174, Val Loss: 1.5281, Best Val Loss: 1.5281\n",
      "Epoch 51/1000, Train Loss: 1.5177, Val Loss: 1.5245, Best Val Loss: 1.5245\n",
      "Epoch 52/1000, Train Loss: 1.5102, Val Loss: 1.5165, Best Val Loss: 1.5165\n",
      "Epoch 67/1000, Train Loss: 1.4789, Val Loss: 1.5017, Best Val Loss: 1.5017\n",
      "Epoch 72/1000, Train Loss: 1.4562, Val Loss: 1.5012, Best Val Loss: 1.5012\n",
      "Epoch 76/1000, Train Loss: 1.4478, Val Loss: 1.4882, Best Val Loss: 1.4882\n",
      "Epoch 84/1000, Train Loss: 1.4272, Val Loss: 1.4774, Best Val Loss: 1.4774\n",
      "Epoch 94/1000, Train Loss: 1.4144, Val Loss: 1.4697, Best Val Loss: 1.4697\n",
      "Epoch 100/1000, Train Loss: 1.4025, Val Loss: 1.4685, Best Val Loss: 1.4685\n",
      "Epoch 128/1000, Train Loss: 1.3646, Val Loss: 1.4596, Best Val Loss: 1.4596\n",
      "Epoch 155/1000, Train Loss: 1.3419, Val Loss: 1.4549, Best Val Loss: 1.4549\n",
      "Epoch 157/1000, Train Loss: 1.3287, Val Loss: 1.4482, Best Val Loss: 1.4482\n",
      "Early stopping at epoch 207, Best Val Loss: 1.4482\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 137.9138, Val Loss: 5.3369, Best Val Loss: 5.3369\n",
      "Epoch 2/1000, Train Loss: 5.2919, Val Loss: 5.2575, Best Val Loss: 5.2575\n",
      "Epoch 3/1000, Train Loss: 5.2309, Val Loss: 5.2076, Best Val Loss: 5.2076\n",
      "Epoch 4/1000, Train Loss: 5.1676, Val Loss: 5.0853, Best Val Loss: 5.0853\n",
      "Epoch 5/1000, Train Loss: 3.7218, Val Loss: 2.7635, Best Val Loss: 2.7635\n",
      "Epoch 6/1000, Train Loss: 2.5735, Val Loss: 2.4113, Best Val Loss: 2.4113\n",
      "Epoch 7/1000, Train Loss: 2.2962, Val Loss: 2.1906, Best Val Loss: 2.1906\n",
      "Epoch 8/1000, Train Loss: 2.1175, Val Loss: 2.0537, Best Val Loss: 2.0537\n",
      "Epoch 9/1000, Train Loss: 2.0026, Val Loss: 1.9793, Best Val Loss: 1.9793\n",
      "Epoch 10/1000, Train Loss: 1.9314, Val Loss: 1.9160, Best Val Loss: 1.9160\n",
      "Epoch 11/1000, Train Loss: 1.8730, Val Loss: 1.8558, Best Val Loss: 1.8558\n",
      "Epoch 12/1000, Train Loss: 1.8299, Val Loss: 1.8287, Best Val Loss: 1.8287\n",
      "Epoch 13/1000, Train Loss: 1.8056, Val Loss: 1.8052, Best Val Loss: 1.8052\n",
      "Epoch 14/1000, Train Loss: 1.7735, Val Loss: 1.7907, Best Val Loss: 1.7907\n",
      "Epoch 15/1000, Train Loss: 1.7659, Val Loss: 1.7506, Best Val Loss: 1.7506\n",
      "Epoch 17/1000, Train Loss: 1.7261, Val Loss: 1.7351, Best Val Loss: 1.7351\n",
      "Epoch 18/1000, Train Loss: 1.7094, Val Loss: 1.7221, Best Val Loss: 1.7221\n",
      "Epoch 20/1000, Train Loss: 1.7008, Val Loss: 1.6895, Best Val Loss: 1.6895\n",
      "Epoch 21/1000, Train Loss: 1.6809, Val Loss: 1.6761, Best Val Loss: 1.6761\n",
      "Epoch 28/1000, Train Loss: 1.6329, Val Loss: 1.6535, Best Val Loss: 1.6535\n",
      "Epoch 29/1000, Train Loss: 1.6239, Val Loss: 1.6176, Best Val Loss: 1.6176\n",
      "Epoch 33/1000, Train Loss: 1.6099, Val Loss: 1.6069, Best Val Loss: 1.6069\n",
      "Epoch 34/1000, Train Loss: 1.5968, Val Loss: 1.5988, Best Val Loss: 1.5988\n",
      "Epoch 42/1000, Train Loss: 1.5598, Val Loss: 1.5967, Best Val Loss: 1.5967\n",
      "Epoch 44/1000, Train Loss: 1.5526, Val Loss: 1.5807, Best Val Loss: 1.5807\n",
      "Epoch 45/1000, Train Loss: 1.5523, Val Loss: 1.5695, Best Val Loss: 1.5695\n",
      "Epoch 48/1000, Train Loss: 1.5264, Val Loss: 1.5562, Best Val Loss: 1.5562\n",
      "Epoch 49/1000, Train Loss: 1.5164, Val Loss: 1.5454, Best Val Loss: 1.5454\n",
      "Epoch 55/1000, Train Loss: 1.5055, Val Loss: 1.5332, Best Val Loss: 1.5332\n",
      "Epoch 58/1000, Train Loss: 1.4919, Val Loss: 1.5269, Best Val Loss: 1.5269\n",
      "Epoch 69/1000, Train Loss: 1.4650, Val Loss: 1.4896, Best Val Loss: 1.4896\n",
      "Epoch 83/1000, Train Loss: 1.4329, Val Loss: 1.4792, Best Val Loss: 1.4792\n",
      "Epoch 90/1000, Train Loss: 1.4413, Val Loss: 1.4739, Best Val Loss: 1.4739\n",
      "Epoch 117/1000, Train Loss: 1.3764, Val Loss: 1.4727, Best Val Loss: 1.4727\n",
      "Epoch 154/1000, Train Loss: 1.3350, Val Loss: 1.4698, Best Val Loss: 1.4698\n",
      "Epoch 166/1000, Train Loss: 1.3299, Val Loss: 1.4684, Best Val Loss: 1.4684\n",
      "Early stopping at epoch 216, Best Val Loss: 1.4684\n",
      "Epistemic Variance: 0.838448\n",
      "Aleatoric Variance: 7.394613\n",
      " (1/n) Calculating accuracy metrics\n",
      " (2/n) Calculating average calibration metrics\n",
      " (3/n) Calculating adversarial group calibration metrics\n",
      "  [1/2] for mean absolute calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [2/2] for root mean squared calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (4/n) Calculating sharpness metrics\n",
      " (n/n) Calculating proper scoring rule metrics\n",
      "**Finished Calculating All Metrics**\n",
      "\n",
      "\n",
      "===================== Accuracy Metrics =====================\n",
      "  MAE           1.966\n",
      "  RMSE          2.765\n",
      "  MDAE          1.457\n",
      "  MARPD         1.717\n",
      "  R2            0.866\n",
      "  Correlation   0.931\n",
      "=============== Average Calibration Metrics ================\n",
      "  Root-mean-squared Calibration Error   0.032\n",
      "  Mean-absolute Calibration Error       0.028\n",
      "  Miscalibration Area                   0.028\n",
      "========== Adversarial Group Calibration Metrics ===========\n",
      "  Mean-absolute Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.041\n",
      "     Group Size: 0.56 -- Calibration Error: 0.032\n",
      "     Group Size: 1.00 -- Calibration Error: 0.028\n",
      "  Root-mean-squared Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.044\n",
      "     Group Size: 0.56 -- Calibration Error: 0.036\n",
      "     Group Size: 1.00 -- Calibration Error: 0.032\n",
      "==================== Sharpness Metrics =====================\n",
      "  Sharpness   2.869\n",
      "=================== Scoring Rule Metrics ===================\n",
      "  Negative-log-likelihood   2.277\n",
      "  CRPS                      1.408\n",
      "  Check Score               0.711\n",
      "  Interval Score            7.054\n",
      "{'accuracy': {'mae': 1.9656434433546346, 'rmse': np.float64(2.7646984118294737), 'mdae': 1.4569797241210978, 'marpd': np.float64(1.7171301826578853), 'r2': 0.8661403454264198, 'corr': np.float64(0.9307628716902713)}, 'avg_calibration': {'rms_cal': np.float64(0.03211520848659491), 'ma_cal': np.float64(0.02773334615014896), 'miscal_area': np.float64(0.028009634176597128)}, 'adv_group_calibration': {'ma_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.3685303 , 0.04147754, 0.03369977, 0.03286661, 0.03272452,\n",
      "       0.03196072, 0.0307782 , 0.02949306, 0.02939045, 0.02773335]), 'adv_group_cali_stderr': array([0.0511452 , 0.00443823, 0.00400501, 0.00195548, 0.00182905,\n",
      "       0.00105899, 0.00092574, 0.00066818, 0.00041146, 0.        ])}, 'rms_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.46302495, 0.04412527, 0.04081114, 0.03959221, 0.03822595,\n",
      "       0.0360851 , 0.0354079 , 0.03454436, 0.03357455, 0.03211521]), 'adv_group_cali_stderr': array([6.70526040e-02, 5.68014633e-03, 2.93480848e-03, 2.70676658e-03,\n",
      "       1.61982606e-03, 1.59419971e-03, 1.14100233e-03, 1.22097107e-03,\n",
      "       6.18357709e-04, 7.31423639e-18])}}, 'sharpness': {'sharp': np.float32(2.8693314)}, 'scoring_rule': {'nll': np.float64(2.277140061346625), 'crps': np.float64(1.4076962209774568), 'check': np.float64(0.7107720761913753), 'interval': np.float64(7.054087467163622)}}\n",
      "coverage: 0.9519369412669423, MPIW: 10.162967980396473\n",
      "Run 2 with seed 123\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 156.0092, Val Loss: 5.5488, Best Val Loss: 5.5488\n",
      "Epoch 2/1000, Train Loss: 5.4987, Val Loss: 5.4531, Best Val Loss: 5.4531\n",
      "Epoch 3/1000, Train Loss: 5.4138, Val Loss: 5.3746, Best Val Loss: 5.3746\n",
      "Epoch 4/1000, Train Loss: 5.3371, Val Loss: 5.2990, Best Val Loss: 5.2990\n",
      "Epoch 5/1000, Train Loss: 5.2558, Val Loss: 5.2038, Best Val Loss: 5.2038\n",
      "Epoch 6/1000, Train Loss: 5.0973, Val Loss: 4.9031, Best Val Loss: 4.9031\n",
      "Epoch 7/1000, Train Loss: 3.3912, Val Loss: 2.3764, Best Val Loss: 2.3764\n",
      "Epoch 8/1000, Train Loss: 2.2252, Val Loss: 2.1127, Best Val Loss: 2.1127\n",
      "Epoch 9/1000, Train Loss: 2.0256, Val Loss: 1.9596, Best Val Loss: 1.9596\n",
      "Epoch 10/1000, Train Loss: 1.9231, Val Loss: 1.8958, Best Val Loss: 1.8958\n",
      "Epoch 11/1000, Train Loss: 1.8593, Val Loss: 1.8351, Best Val Loss: 1.8351\n",
      "Epoch 12/1000, Train Loss: 1.8208, Val Loss: 1.8073, Best Val Loss: 1.8073\n",
      "Epoch 13/1000, Train Loss: 1.7874, Val Loss: 1.7906, Best Val Loss: 1.7906\n",
      "Epoch 14/1000, Train Loss: 1.7611, Val Loss: 1.7556, Best Val Loss: 1.7556\n",
      "Epoch 15/1000, Train Loss: 1.7491, Val Loss: 1.7326, Best Val Loss: 1.7326\n",
      "Epoch 17/1000, Train Loss: 1.7244, Val Loss: 1.7269, Best Val Loss: 1.7269\n",
      "Epoch 19/1000, Train Loss: 1.7037, Val Loss: 1.7209, Best Val Loss: 1.7209\n",
      "Epoch 20/1000, Train Loss: 1.6982, Val Loss: 1.6911, Best Val Loss: 1.6911\n",
      "Epoch 21/1000, Train Loss: 1.6896, Val Loss: 1.6830, Best Val Loss: 1.6830\n",
      "Epoch 24/1000, Train Loss: 1.6781, Val Loss: 1.6803, Best Val Loss: 1.6803\n",
      "Epoch 27/1000, Train Loss: 1.6467, Val Loss: 1.6417, Best Val Loss: 1.6417\n",
      "Epoch 30/1000, Train Loss: 1.6332, Val Loss: 1.6371, Best Val Loss: 1.6371\n",
      "Epoch 32/1000, Train Loss: 1.6167, Val Loss: 1.6172, Best Val Loss: 1.6172\n",
      "Epoch 35/1000, Train Loss: 1.5987, Val Loss: 1.6105, Best Val Loss: 1.6105\n",
      "Epoch 38/1000, Train Loss: 1.5764, Val Loss: 1.5967, Best Val Loss: 1.5967\n",
      "Epoch 41/1000, Train Loss: 1.5677, Val Loss: 1.5800, Best Val Loss: 1.5800\n",
      "Epoch 46/1000, Train Loss: 1.5347, Val Loss: 1.5590, Best Val Loss: 1.5590\n",
      "Epoch 49/1000, Train Loss: 1.5215, Val Loss: 1.5474, Best Val Loss: 1.5474\n",
      "Epoch 50/1000, Train Loss: 1.5272, Val Loss: 1.5458, Best Val Loss: 1.5458\n",
      "Epoch 51/1000, Train Loss: 1.5248, Val Loss: 1.5446, Best Val Loss: 1.5446\n",
      "Epoch 53/1000, Train Loss: 1.5123, Val Loss: 1.5375, Best Val Loss: 1.5375\n",
      "Epoch 57/1000, Train Loss: 1.5074, Val Loss: 1.5292, Best Val Loss: 1.5292\n",
      "Epoch 63/1000, Train Loss: 1.4830, Val Loss: 1.5261, Best Val Loss: 1.5261\n",
      "Epoch 66/1000, Train Loss: 1.4692, Val Loss: 1.5109, Best Val Loss: 1.5109\n",
      "Epoch 81/1000, Train Loss: 1.4397, Val Loss: 1.5041, Best Val Loss: 1.5041\n",
      "Epoch 84/1000, Train Loss: 1.4387, Val Loss: 1.5039, Best Val Loss: 1.5039\n",
      "Epoch 86/1000, Train Loss: 1.4291, Val Loss: 1.4929, Best Val Loss: 1.4929\n",
      "Epoch 89/1000, Train Loss: 1.4283, Val Loss: 1.4882, Best Val Loss: 1.4882\n",
      "Epoch 90/1000, Train Loss: 1.4256, Val Loss: 1.4859, Best Val Loss: 1.4859\n",
      "Epoch 91/1000, Train Loss: 1.4237, Val Loss: 1.4825, Best Val Loss: 1.4825\n",
      "Epoch 106/1000, Train Loss: 1.4072, Val Loss: 1.4676, Best Val Loss: 1.4676\n",
      "Epoch 119/1000, Train Loss: 1.3870, Val Loss: 1.4645, Best Val Loss: 1.4645\n",
      "Epoch 156/1000, Train Loss: 1.3546, Val Loss: 1.4576, Best Val Loss: 1.4576\n",
      "Early stopping at epoch 206, Best Val Loss: 1.4576\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 124.3247, Val Loss: 5.5396, Best Val Loss: 5.5396\n",
      "Epoch 2/1000, Train Loss: 5.4829, Val Loss: 5.4153, Best Val Loss: 5.4153\n",
      "Epoch 3/1000, Train Loss: 5.3672, Val Loss: 5.2928, Best Val Loss: 5.2928\n",
      "Epoch 4/1000, Train Loss: 5.1673, Val Loss: 4.9429, Best Val Loss: 4.9429\n",
      "Epoch 5/1000, Train Loss: 3.4837, Val Loss: 2.4825, Best Val Loss: 2.4825\n",
      "Epoch 6/1000, Train Loss: 2.3411, Val Loss: 2.2394, Best Val Loss: 2.2394\n",
      "Epoch 7/1000, Train Loss: 2.1342, Val Loss: 2.0633, Best Val Loss: 2.0633\n",
      "Epoch 8/1000, Train Loss: 1.9964, Val Loss: 1.9681, Best Val Loss: 1.9681\n",
      "Epoch 9/1000, Train Loss: 1.9062, Val Loss: 1.8739, Best Val Loss: 1.8739\n",
      "Epoch 10/1000, Train Loss: 1.8477, Val Loss: 1.8109, Best Val Loss: 1.8109\n",
      "Epoch 12/1000, Train Loss: 1.7802, Val Loss: 1.7506, Best Val Loss: 1.7506\n",
      "Epoch 16/1000, Train Loss: 1.7148, Val Loss: 1.7083, Best Val Loss: 1.7083\n",
      "Epoch 18/1000, Train Loss: 1.7025, Val Loss: 1.6649, Best Val Loss: 1.6649\n",
      "Epoch 21/1000, Train Loss: 1.6656, Val Loss: 1.6465, Best Val Loss: 1.6465\n",
      "Epoch 25/1000, Train Loss: 1.6477, Val Loss: 1.6406, Best Val Loss: 1.6406\n",
      "Epoch 29/1000, Train Loss: 1.6177, Val Loss: 1.6047, Best Val Loss: 1.6047\n",
      "Epoch 35/1000, Train Loss: 1.5874, Val Loss: 1.5982, Best Val Loss: 1.5982\n",
      "Epoch 37/1000, Train Loss: 1.5699, Val Loss: 1.5853, Best Val Loss: 1.5853\n",
      "Epoch 38/1000, Train Loss: 1.5561, Val Loss: 1.5567, Best Val Loss: 1.5567\n",
      "Epoch 44/1000, Train Loss: 1.5399, Val Loss: 1.5555, Best Val Loss: 1.5555\n",
      "Epoch 48/1000, Train Loss: 1.5120, Val Loss: 1.5540, Best Val Loss: 1.5540\n",
      "Epoch 49/1000, Train Loss: 1.5270, Val Loss: 1.5393, Best Val Loss: 1.5393\n",
      "Epoch 53/1000, Train Loss: 1.5017, Val Loss: 1.5374, Best Val Loss: 1.5374\n",
      "Epoch 59/1000, Train Loss: 1.4848, Val Loss: 1.5115, Best Val Loss: 1.5115\n",
      "Epoch 65/1000, Train Loss: 1.4720, Val Loss: 1.5035, Best Val Loss: 1.5035\n",
      "Epoch 74/1000, Train Loss: 1.4481, Val Loss: 1.4903, Best Val Loss: 1.4903\n",
      "Epoch 96/1000, Train Loss: 1.4065, Val Loss: 1.4878, Best Val Loss: 1.4878\n",
      "Epoch 98/1000, Train Loss: 1.3975, Val Loss: 1.4857, Best Val Loss: 1.4857\n",
      "Epoch 101/1000, Train Loss: 1.4062, Val Loss: 1.4732, Best Val Loss: 1.4732\n",
      "Epoch 119/1000, Train Loss: 1.3738, Val Loss: 1.4731, Best Val Loss: 1.4731\n",
      "Epoch 125/1000, Train Loss: 1.3687, Val Loss: 1.4665, Best Val Loss: 1.4665\n",
      "Epoch 165/1000, Train Loss: 1.3155, Val Loss: 1.4620, Best Val Loss: 1.4620\n",
      "Early stopping at epoch 215, Best Val Loss: 1.4620\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 135.6368, Val Loss: 5.5211, Best Val Loss: 5.5211\n",
      "Epoch 2/1000, Train Loss: 5.4772, Val Loss: 5.4293, Best Val Loss: 5.4293\n",
      "Epoch 3/1000, Train Loss: 5.3927, Val Loss: 5.3507, Best Val Loss: 5.3507\n",
      "Epoch 4/1000, Train Loss: 5.3132, Val Loss: 5.2742, Best Val Loss: 5.2742\n",
      "Epoch 5/1000, Train Loss: 5.2374, Val Loss: 5.2016, Best Val Loss: 5.2016\n",
      "Epoch 6/1000, Train Loss: 5.1494, Val Loss: 5.0771, Best Val Loss: 5.0771\n",
      "Epoch 7/1000, Train Loss: 4.1774, Val Loss: 2.4207, Best Val Loss: 2.4207\n",
      "Epoch 8/1000, Train Loss: 2.2352, Val Loss: 2.1472, Best Val Loss: 2.1472\n",
      "Epoch 9/1000, Train Loss: 2.0514, Val Loss: 2.0260, Best Val Loss: 2.0260\n",
      "Epoch 10/1000, Train Loss: 1.9465, Val Loss: 1.9300, Best Val Loss: 1.9300\n",
      "Epoch 11/1000, Train Loss: 1.8776, Val Loss: 1.8667, Best Val Loss: 1.8667\n",
      "Epoch 12/1000, Train Loss: 1.8312, Val Loss: 1.7993, Best Val Loss: 1.7993\n",
      "Epoch 13/1000, Train Loss: 1.7948, Val Loss: 1.7817, Best Val Loss: 1.7817\n",
      "Epoch 14/1000, Train Loss: 1.7670, Val Loss: 1.7674, Best Val Loss: 1.7674\n",
      "Epoch 15/1000, Train Loss: 1.7469, Val Loss: 1.7647, Best Val Loss: 1.7647\n",
      "Epoch 16/1000, Train Loss: 1.7299, Val Loss: 1.7525, Best Val Loss: 1.7525\n",
      "Epoch 17/1000, Train Loss: 1.7121, Val Loss: 1.7171, Best Val Loss: 1.7171\n",
      "Epoch 18/1000, Train Loss: 1.7042, Val Loss: 1.7028, Best Val Loss: 1.7028\n",
      "Epoch 21/1000, Train Loss: 1.6672, Val Loss: 1.7004, Best Val Loss: 1.7004\n",
      "Epoch 22/1000, Train Loss: 1.6639, Val Loss: 1.6759, Best Val Loss: 1.6759\n",
      "Epoch 23/1000, Train Loss: 1.6518, Val Loss: 1.6626, Best Val Loss: 1.6626\n",
      "Epoch 26/1000, Train Loss: 1.6260, Val Loss: 1.6229, Best Val Loss: 1.6229\n",
      "Epoch 30/1000, Train Loss: 1.5983, Val Loss: 1.6172, Best Val Loss: 1.6172\n",
      "Epoch 31/1000, Train Loss: 1.5894, Val Loss: 1.6040, Best Val Loss: 1.6040\n",
      "Epoch 33/1000, Train Loss: 1.5695, Val Loss: 1.5901, Best Val Loss: 1.5901\n",
      "Epoch 34/1000, Train Loss: 1.5655, Val Loss: 1.5893, Best Val Loss: 1.5893\n",
      "Epoch 35/1000, Train Loss: 1.5568, Val Loss: 1.5851, Best Val Loss: 1.5851\n",
      "Epoch 37/1000, Train Loss: 1.5510, Val Loss: 1.5583, Best Val Loss: 1.5583\n",
      "Epoch 41/1000, Train Loss: 1.5351, Val Loss: 1.5532, Best Val Loss: 1.5532\n",
      "Epoch 42/1000, Train Loss: 1.5150, Val Loss: 1.5470, Best Val Loss: 1.5470\n",
      "Epoch 43/1000, Train Loss: 1.5145, Val Loss: 1.5241, Best Val Loss: 1.5241\n",
      "Epoch 54/1000, Train Loss: 1.4649, Val Loss: 1.5033, Best Val Loss: 1.5033\n",
      "Epoch 57/1000, Train Loss: 1.4549, Val Loss: 1.4889, Best Val Loss: 1.4889\n",
      "Epoch 75/1000, Train Loss: 1.4179, Val Loss: 1.4686, Best Val Loss: 1.4686\n",
      "Early stopping at epoch 125, Best Val Loss: 1.4686\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 144.0583, Val Loss: 5.4603, Best Val Loss: 5.4603\n",
      "Epoch 2/1000, Train Loss: 5.3986, Val Loss: 5.3502, Best Val Loss: 5.3502\n",
      "Epoch 3/1000, Train Loss: 5.3189, Val Loss: 5.2849, Best Val Loss: 5.2849\n",
      "Epoch 4/1000, Train Loss: 5.2589, Val Loss: 5.2311, Best Val Loss: 5.2311\n",
      "Epoch 5/1000, Train Loss: 5.2054, Val Loss: 5.1768, Best Val Loss: 5.1768\n",
      "Epoch 6/1000, Train Loss: 5.1286, Val Loss: 5.0374, Best Val Loss: 5.0374\n",
      "Epoch 7/1000, Train Loss: 3.7724, Val Loss: 2.3232, Best Val Loss: 2.3232\n",
      "Epoch 8/1000, Train Loss: 2.1438, Val Loss: 2.0287, Best Val Loss: 2.0287\n",
      "Epoch 9/1000, Train Loss: 1.9592, Val Loss: 1.9275, Best Val Loss: 1.9275\n",
      "Epoch 10/1000, Train Loss: 1.8767, Val Loss: 1.8632, Best Val Loss: 1.8632\n",
      "Epoch 11/1000, Train Loss: 1.8211, Val Loss: 1.8007, Best Val Loss: 1.8007\n",
      "Epoch 12/1000, Train Loss: 1.8001, Val Loss: 1.7865, Best Val Loss: 1.7865\n",
      "Epoch 13/1000, Train Loss: 1.7544, Val Loss: 1.7453, Best Val Loss: 1.7453\n",
      "Epoch 14/1000, Train Loss: 1.7452, Val Loss: 1.7218, Best Val Loss: 1.7218\n",
      "Epoch 16/1000, Train Loss: 1.7163, Val Loss: 1.7015, Best Val Loss: 1.7015\n",
      "Epoch 17/1000, Train Loss: 1.6968, Val Loss: 1.6765, Best Val Loss: 1.6765\n",
      "Epoch 21/1000, Train Loss: 1.6674, Val Loss: 1.6650, Best Val Loss: 1.6650\n",
      "Epoch 22/1000, Train Loss: 1.6612, Val Loss: 1.6418, Best Val Loss: 1.6418\n",
      "Epoch 26/1000, Train Loss: 1.6170, Val Loss: 1.6254, Best Val Loss: 1.6254\n",
      "Epoch 28/1000, Train Loss: 1.6009, Val Loss: 1.6093, Best Val Loss: 1.6093\n",
      "Epoch 32/1000, Train Loss: 1.5836, Val Loss: 1.6021, Best Val Loss: 1.6021\n",
      "Epoch 35/1000, Train Loss: 1.5569, Val Loss: 1.5814, Best Val Loss: 1.5814\n",
      "Epoch 36/1000, Train Loss: 1.5477, Val Loss: 1.5792, Best Val Loss: 1.5792\n",
      "Epoch 37/1000, Train Loss: 1.5432, Val Loss: 1.5630, Best Val Loss: 1.5630\n",
      "Epoch 38/1000, Train Loss: 1.5394, Val Loss: 1.5599, Best Val Loss: 1.5599\n",
      "Epoch 39/1000, Train Loss: 1.5366, Val Loss: 1.5543, Best Val Loss: 1.5543\n",
      "Epoch 44/1000, Train Loss: 1.5070, Val Loss: 1.5501, Best Val Loss: 1.5501\n",
      "Epoch 47/1000, Train Loss: 1.5043, Val Loss: 1.5463, Best Val Loss: 1.5463\n",
      "Epoch 51/1000, Train Loss: 1.4815, Val Loss: 1.5368, Best Val Loss: 1.5368\n",
      "Epoch 54/1000, Train Loss: 1.4691, Val Loss: 1.5294, Best Val Loss: 1.5294\n",
      "Epoch 57/1000, Train Loss: 1.4639, Val Loss: 1.5059, Best Val Loss: 1.5059\n",
      "Epoch 61/1000, Train Loss: 1.4492, Val Loss: 1.5028, Best Val Loss: 1.5028\n",
      "Epoch 64/1000, Train Loss: 1.4404, Val Loss: 1.4761, Best Val Loss: 1.4761\n",
      "Early stopping at epoch 114, Best Val Loss: 1.4761\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 137.0009, Val Loss: 5.4440, Best Val Loss: 5.4440\n",
      "Epoch 2/1000, Train Loss: 5.3930, Val Loss: 5.3362, Best Val Loss: 5.3362\n",
      "Epoch 3/1000, Train Loss: 5.2828, Val Loss: 5.2041, Best Val Loss: 5.2041\n",
      "Epoch 4/1000, Train Loss: 5.0625, Val Loss: 4.8181, Best Val Loss: 4.8181\n",
      "Epoch 5/1000, Train Loss: 3.4332, Val Loss: 2.3831, Best Val Loss: 2.3831\n",
      "Epoch 6/1000, Train Loss: 2.2302, Val Loss: 2.1208, Best Val Loss: 2.1208\n",
      "Epoch 7/1000, Train Loss: 2.0411, Val Loss: 1.9834, Best Val Loss: 1.9834\n",
      "Epoch 8/1000, Train Loss: 1.9349, Val Loss: 1.9100, Best Val Loss: 1.9100\n",
      "Epoch 9/1000, Train Loss: 1.8741, Val Loss: 1.8404, Best Val Loss: 1.8404\n",
      "Epoch 11/1000, Train Loss: 1.8043, Val Loss: 1.7893, Best Val Loss: 1.7893\n",
      "Epoch 12/1000, Train Loss: 1.7915, Val Loss: 1.7598, Best Val Loss: 1.7598\n",
      "Epoch 14/1000, Train Loss: 1.7391, Val Loss: 1.7489, Best Val Loss: 1.7489\n",
      "Epoch 15/1000, Train Loss: 1.7355, Val Loss: 1.7308, Best Val Loss: 1.7308\n",
      "Epoch 16/1000, Train Loss: 1.7162, Val Loss: 1.7072, Best Val Loss: 1.7072\n",
      "Epoch 20/1000, Train Loss: 1.6841, Val Loss: 1.6503, Best Val Loss: 1.6503\n",
      "Epoch 29/1000, Train Loss: 1.6299, Val Loss: 1.6424, Best Val Loss: 1.6424\n",
      "Epoch 31/1000, Train Loss: 1.6089, Val Loss: 1.6174, Best Val Loss: 1.6174\n",
      "Epoch 34/1000, Train Loss: 1.5958, Val Loss: 1.5969, Best Val Loss: 1.5969\n",
      "Epoch 37/1000, Train Loss: 1.5790, Val Loss: 1.5845, Best Val Loss: 1.5845\n",
      "Epoch 40/1000, Train Loss: 1.5505, Val Loss: 1.5637, Best Val Loss: 1.5637\n",
      "Epoch 45/1000, Train Loss: 1.5277, Val Loss: 1.5411, Best Val Loss: 1.5411\n",
      "Epoch 47/1000, Train Loss: 1.5256, Val Loss: 1.5407, Best Val Loss: 1.5407\n",
      "Epoch 54/1000, Train Loss: 1.4968, Val Loss: 1.5280, Best Val Loss: 1.5280\n",
      "Epoch 57/1000, Train Loss: 1.4899, Val Loss: 1.5274, Best Val Loss: 1.5274\n",
      "Epoch 62/1000, Train Loss: 1.4730, Val Loss: 1.5138, Best Val Loss: 1.5138\n",
      "Epoch 71/1000, Train Loss: 1.4502, Val Loss: 1.5129, Best Val Loss: 1.5129\n",
      "Epoch 82/1000, Train Loss: 1.4291, Val Loss: 1.5002, Best Val Loss: 1.5002\n",
      "Epoch 88/1000, Train Loss: 1.4212, Val Loss: 1.4972, Best Val Loss: 1.4972\n",
      "Epoch 95/1000, Train Loss: 1.4011, Val Loss: 1.4871, Best Val Loss: 1.4871\n",
      "Epoch 96/1000, Train Loss: 1.4069, Val Loss: 1.4778, Best Val Loss: 1.4778\n",
      "Epoch 101/1000, Train Loss: 1.3993, Val Loss: 1.4774, Best Val Loss: 1.4774\n",
      "Epoch 112/1000, Train Loss: 1.3801, Val Loss: 1.4725, Best Val Loss: 1.4725\n",
      "Early stopping at epoch 162, Best Val Loss: 1.4725\n",
      "Epistemic Variance: 0.865886\n",
      "Aleatoric Variance: 10.355071\n",
      " (1/n) Calculating accuracy metrics\n",
      " (2/n) Calculating average calibration metrics\n",
      " (3/n) Calculating adversarial group calibration metrics\n",
      "  [1/2] for mean absolute calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [2/2] for root mean squared calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (4/n) Calculating sharpness metrics\n",
      " (n/n) Calculating proper scoring rule metrics\n",
      "**Finished Calculating All Metrics**\n",
      "\n",
      "\n",
      "===================== Accuracy Metrics =====================\n",
      "  MAE           1.987\n",
      "  RMSE          2.817\n",
      "  MDAE          1.482\n",
      "  MARPD         1.735\n",
      "  R2            0.861\n",
      "  Correlation   0.928\n",
      "=============== Average Calibration Metrics ================\n",
      "  Root-mean-squared Calibration Error   0.035\n",
      "  Mean-absolute Calibration Error       0.032\n",
      "  Miscalibration Area                   0.032\n",
      "========== Adversarial Group Calibration Metrics ===========\n",
      "  Mean-absolute Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.043\n",
      "     Group Size: 0.56 -- Calibration Error: 0.036\n",
      "     Group Size: 1.00 -- Calibration Error: 0.032\n",
      "  Root-mean-squared Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.047\n",
      "     Group Size: 0.56 -- Calibration Error: 0.039\n",
      "     Group Size: 1.00 -- Calibration Error: 0.035\n",
      "==================== Sharpness Metrics =====================\n",
      "  Sharpness   3.350\n",
      "=================== Scoring Rule Metrics ===================\n",
      "  Negative-log-likelihood   2.294\n",
      "  CRPS                      1.433\n",
      "  Check Score               0.723\n",
      "  Interval Score            7.201\n",
      "{'accuracy': {'mae': 1.9872824606338202, 'rmse': np.float64(2.817089032082645), 'mdae': 1.4818587524414113, 'marpd': np.float64(1.7352368032359893), 'r2': 0.8610190360950551, 'corr': np.float64(0.9281527467035683)}, 'avg_calibration': {'rms_cal': np.float64(0.03495274442117548), 'ma_cal': np.float64(0.03169166431206223), 'miscal_area': np.float64(0.03200716062089398)}, 'adv_group_calibration': {'ma_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.35543434, 0.04336637, 0.03947367, 0.03723627, 0.0362691 ,\n",
      "       0.03558678, 0.03527994, 0.03413293, 0.03315483, 0.03169166]), 'adv_group_cali_stderr': array([0.06259313, 0.00512378, 0.00272976, 0.00279784, 0.00169522,\n",
      "       0.00148073, 0.00129154, 0.00082831, 0.00057673, 0.        ])}, 'rms_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.45725644, 0.04748497, 0.0433621 , 0.04193364, 0.04042642,\n",
      "       0.03946564, 0.03832286, 0.03761076, 0.03682379, 0.03495274]), 'adv_group_cali_stderr': array([0.06913812, 0.00441717, 0.00354323, 0.00218433, 0.00239253,\n",
      "       0.00135503, 0.00197913, 0.00090076, 0.00074443, 0.        ])}}, 'sharpness': {'sharp': np.float32(3.3497698)}, 'scoring_rule': {'nll': np.float64(2.2943989222758376), 'crps': np.float64(1.4328701542026647), 'check': np.float64(0.7234761536416943), 'interval': np.float64(7.200831966081777)}}\n",
      "coverage: 0.953378833028934, MPIW: 10.459032960057037\n",
      "Run 3 with seed 777\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 165.9495, Val Loss: 5.5439, Best Val Loss: 5.5439\n",
      "Epoch 2/1000, Train Loss: 5.4886, Val Loss: 5.4278, Best Val Loss: 5.4278\n",
      "Epoch 3/1000, Train Loss: 5.3828, Val Loss: 5.3385, Best Val Loss: 5.3385\n",
      "Epoch 4/1000, Train Loss: 5.3066, Val Loss: 5.2757, Best Val Loss: 5.2757\n",
      "Epoch 5/1000, Train Loss: 5.2495, Val Loss: 5.2242, Best Val Loss: 5.2242\n",
      "Epoch 6/1000, Train Loss: 5.1947, Val Loss: 5.1600, Best Val Loss: 5.1600\n",
      "Epoch 7/1000, Train Loss: 4.9288, Val Loss: 3.0560, Best Val Loss: 3.0560\n",
      "Epoch 8/1000, Train Loss: 2.3194, Val Loss: 2.1279, Best Val Loss: 2.1279\n",
      "Epoch 9/1000, Train Loss: 2.0178, Val Loss: 1.9608, Best Val Loss: 1.9608\n",
      "Epoch 10/1000, Train Loss: 1.8956, Val Loss: 1.8828, Best Val Loss: 1.8828\n",
      "Epoch 11/1000, Train Loss: 1.8383, Val Loss: 1.8344, Best Val Loss: 1.8344\n",
      "Epoch 12/1000, Train Loss: 1.8031, Val Loss: 1.7966, Best Val Loss: 1.7966\n",
      "Epoch 14/1000, Train Loss: 1.7462, Val Loss: 1.7642, Best Val Loss: 1.7642\n",
      "Epoch 15/1000, Train Loss: 1.7306, Val Loss: 1.7274, Best Val Loss: 1.7274\n",
      "Epoch 16/1000, Train Loss: 1.7132, Val Loss: 1.7187, Best Val Loss: 1.7187\n",
      "Epoch 20/1000, Train Loss: 1.6595, Val Loss: 1.6736, Best Val Loss: 1.6736\n",
      "Epoch 22/1000, Train Loss: 1.6611, Val Loss: 1.6557, Best Val Loss: 1.6557\n",
      "Epoch 23/1000, Train Loss: 1.6391, Val Loss: 1.6495, Best Val Loss: 1.6495\n",
      "Epoch 27/1000, Train Loss: 1.6057, Val Loss: 1.6356, Best Val Loss: 1.6356\n",
      "Epoch 28/1000, Train Loss: 1.6005, Val Loss: 1.6196, Best Val Loss: 1.6196\n",
      "Epoch 30/1000, Train Loss: 1.5911, Val Loss: 1.6159, Best Val Loss: 1.6159\n",
      "Epoch 32/1000, Train Loss: 1.5831, Val Loss: 1.6063, Best Val Loss: 1.6063\n",
      "Epoch 34/1000, Train Loss: 1.5675, Val Loss: 1.5911, Best Val Loss: 1.5911\n",
      "Epoch 35/1000, Train Loss: 1.5629, Val Loss: 1.5584, Best Val Loss: 1.5584\n",
      "Epoch 42/1000, Train Loss: 1.5214, Val Loss: 1.5525, Best Val Loss: 1.5525\n",
      "Epoch 45/1000, Train Loss: 1.5116, Val Loss: 1.5445, Best Val Loss: 1.5445\n",
      "Epoch 46/1000, Train Loss: 1.5117, Val Loss: 1.5408, Best Val Loss: 1.5408\n",
      "Epoch 49/1000, Train Loss: 1.4967, Val Loss: 1.5354, Best Val Loss: 1.5354\n",
      "Epoch 53/1000, Train Loss: 1.4828, Val Loss: 1.5115, Best Val Loss: 1.5115\n",
      "Epoch 58/1000, Train Loss: 1.4797, Val Loss: 1.5067, Best Val Loss: 1.5067\n",
      "Epoch 59/1000, Train Loss: 1.4707, Val Loss: 1.4922, Best Val Loss: 1.4922\n",
      "Epoch 68/1000, Train Loss: 1.4432, Val Loss: 1.4890, Best Val Loss: 1.4890\n",
      "Epoch 71/1000, Train Loss: 1.4342, Val Loss: 1.4826, Best Val Loss: 1.4826\n",
      "Epoch 82/1000, Train Loss: 1.4162, Val Loss: 1.4722, Best Val Loss: 1.4722\n",
      "Epoch 113/1000, Train Loss: 1.3603, Val Loss: 1.4543, Best Val Loss: 1.4543\n",
      "Early stopping at epoch 163, Best Val Loss: 1.4543\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 140.9380, Val Loss: 5.5253, Best Val Loss: 5.5253\n",
      "Epoch 2/1000, Train Loss: 5.4861, Val Loss: 5.4468, Best Val Loss: 5.4468\n",
      "Epoch 3/1000, Train Loss: 5.4159, Val Loss: 5.3816, Best Val Loss: 5.3816\n",
      "Epoch 4/1000, Train Loss: 5.3526, Val Loss: 5.3201, Best Val Loss: 5.3201\n",
      "Epoch 5/1000, Train Loss: 5.2909, Val Loss: 5.2624, Best Val Loss: 5.2624\n",
      "Epoch 6/1000, Train Loss: 5.2364, Val Loss: 5.2090, Best Val Loss: 5.2090\n",
      "Epoch 7/1000, Train Loss: 5.1743, Val Loss: 5.1339, Best Val Loss: 5.1339\n",
      "Epoch 8/1000, Train Loss: 5.0580, Val Loss: 4.8983, Best Val Loss: 4.8983\n",
      "Epoch 9/1000, Train Loss: 2.7444, Val Loss: 2.1388, Best Val Loss: 2.1388\n",
      "Epoch 10/1000, Train Loss: 2.0420, Val Loss: 1.9827, Best Val Loss: 1.9827\n",
      "Epoch 11/1000, Train Loss: 1.9295, Val Loss: 1.8987, Best Val Loss: 1.8987\n",
      "Epoch 12/1000, Train Loss: 1.8602, Val Loss: 1.8506, Best Val Loss: 1.8506\n",
      "Epoch 13/1000, Train Loss: 1.8216, Val Loss: 1.7972, Best Val Loss: 1.7972\n",
      "Epoch 16/1000, Train Loss: 1.7515, Val Loss: 1.7617, Best Val Loss: 1.7617\n",
      "Epoch 17/1000, Train Loss: 1.7325, Val Loss: 1.7228, Best Val Loss: 1.7228\n",
      "Epoch 19/1000, Train Loss: 1.7085, Val Loss: 1.7172, Best Val Loss: 1.7172\n",
      "Epoch 21/1000, Train Loss: 1.6834, Val Loss: 1.7157, Best Val Loss: 1.7157\n",
      "Epoch 22/1000, Train Loss: 1.6813, Val Loss: 1.6924, Best Val Loss: 1.6924\n",
      "Epoch 24/1000, Train Loss: 1.6554, Val Loss: 1.6376, Best Val Loss: 1.6376\n",
      "Epoch 32/1000, Train Loss: 1.5981, Val Loss: 1.6093, Best Val Loss: 1.6093\n",
      "Epoch 34/1000, Train Loss: 1.5782, Val Loss: 1.5962, Best Val Loss: 1.5962\n",
      "Epoch 37/1000, Train Loss: 1.5624, Val Loss: 1.5782, Best Val Loss: 1.5782\n",
      "Epoch 39/1000, Train Loss: 1.5581, Val Loss: 1.5589, Best Val Loss: 1.5589\n",
      "Epoch 48/1000, Train Loss: 1.5109, Val Loss: 1.5447, Best Val Loss: 1.5447\n",
      "Epoch 50/1000, Train Loss: 1.4991, Val Loss: 1.5281, Best Val Loss: 1.5281\n",
      "Epoch 51/1000, Train Loss: 1.5019, Val Loss: 1.5265, Best Val Loss: 1.5265\n",
      "Epoch 54/1000, Train Loss: 1.4836, Val Loss: 1.5177, Best Val Loss: 1.5177\n",
      "Epoch 58/1000, Train Loss: 1.4756, Val Loss: 1.5101, Best Val Loss: 1.5101\n",
      "Epoch 60/1000, Train Loss: 1.4675, Val Loss: 1.5084, Best Val Loss: 1.5084\n",
      "Epoch 62/1000, Train Loss: 1.4638, Val Loss: 1.5051, Best Val Loss: 1.5051\n",
      "Epoch 70/1000, Train Loss: 1.4456, Val Loss: 1.5030, Best Val Loss: 1.5030\n",
      "Epoch 72/1000, Train Loss: 1.4397, Val Loss: 1.4798, Best Val Loss: 1.4798\n",
      "Epoch 77/1000, Train Loss: 1.4196, Val Loss: 1.4797, Best Val Loss: 1.4797\n",
      "Epoch 79/1000, Train Loss: 1.4159, Val Loss: 1.4644, Best Val Loss: 1.4644\n",
      "Epoch 90/1000, Train Loss: 1.3966, Val Loss: 1.4596, Best Val Loss: 1.4596\n",
      "Early stopping at epoch 140, Best Val Loss: 1.4596\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 159.8454, Val Loss: 5.5023, Best Val Loss: 5.5023\n",
      "Epoch 2/1000, Train Loss: 5.4474, Val Loss: 5.3902, Best Val Loss: 5.3902\n",
      "Epoch 3/1000, Train Loss: 5.3472, Val Loss: 5.3051, Best Val Loss: 5.3051\n",
      "Epoch 4/1000, Train Loss: 5.2702, Val Loss: 5.2364, Best Val Loss: 5.2364\n",
      "Epoch 5/1000, Train Loss: 5.2083, Val Loss: 5.1797, Best Val Loss: 5.1797\n",
      "Epoch 6/1000, Train Loss: 5.1446, Val Loss: 5.1021, Best Val Loss: 5.1021\n",
      "Epoch 7/1000, Train Loss: 4.4623, Val Loss: 2.4276, Best Val Loss: 2.4276\n",
      "Epoch 8/1000, Train Loss: 2.1749, Val Loss: 2.0584, Best Val Loss: 2.0584\n",
      "Epoch 9/1000, Train Loss: 1.9700, Val Loss: 1.9632, Best Val Loss: 1.9632\n",
      "Epoch 10/1000, Train Loss: 1.8812, Val Loss: 1.8559, Best Val Loss: 1.8559\n",
      "Epoch 11/1000, Train Loss: 1.8332, Val Loss: 1.8379, Best Val Loss: 1.8379\n",
      "Epoch 12/1000, Train Loss: 1.7926, Val Loss: 1.7850, Best Val Loss: 1.7850\n",
      "Epoch 14/1000, Train Loss: 1.7443, Val Loss: 1.7628, Best Val Loss: 1.7628\n",
      "Epoch 15/1000, Train Loss: 1.7308, Val Loss: 1.7467, Best Val Loss: 1.7467\n",
      "Epoch 16/1000, Train Loss: 1.7048, Val Loss: 1.7006, Best Val Loss: 1.7006\n",
      "Epoch 18/1000, Train Loss: 1.6729, Val Loss: 1.6910, Best Val Loss: 1.6910\n",
      "Epoch 19/1000, Train Loss: 1.6709, Val Loss: 1.6813, Best Val Loss: 1.6813\n",
      "Epoch 20/1000, Train Loss: 1.6583, Val Loss: 1.6664, Best Val Loss: 1.6664\n",
      "Epoch 22/1000, Train Loss: 1.6368, Val Loss: 1.6574, Best Val Loss: 1.6574\n",
      "Epoch 24/1000, Train Loss: 1.6191, Val Loss: 1.6307, Best Val Loss: 1.6307\n",
      "Epoch 28/1000, Train Loss: 1.5972, Val Loss: 1.6282, Best Val Loss: 1.6282\n",
      "Epoch 29/1000, Train Loss: 1.5892, Val Loss: 1.5795, Best Val Loss: 1.5795\n",
      "Epoch 38/1000, Train Loss: 1.5326, Val Loss: 1.5720, Best Val Loss: 1.5720\n",
      "Epoch 39/1000, Train Loss: 1.5280, Val Loss: 1.5657, Best Val Loss: 1.5657\n",
      "Epoch 40/1000, Train Loss: 1.5268, Val Loss: 1.5520, Best Val Loss: 1.5520\n",
      "Epoch 44/1000, Train Loss: 1.5113, Val Loss: 1.5264, Best Val Loss: 1.5264\n",
      "Epoch 55/1000, Train Loss: 1.4708, Val Loss: 1.5240, Best Val Loss: 1.5240\n",
      "Epoch 57/1000, Train Loss: 1.4606, Val Loss: 1.4990, Best Val Loss: 1.4990\n",
      "Epoch 71/1000, Train Loss: 1.4217, Val Loss: 1.4884, Best Val Loss: 1.4884\n",
      "Epoch 85/1000, Train Loss: 1.3988, Val Loss: 1.4747, Best Val Loss: 1.4747\n",
      "Epoch 91/1000, Train Loss: 1.3875, Val Loss: 1.4654, Best Val Loss: 1.4654\n",
      "Epoch 117/1000, Train Loss: 1.3420, Val Loss: 1.4653, Best Val Loss: 1.4653\n",
      "Epoch 132/1000, Train Loss: 1.3233, Val Loss: 1.4611, Best Val Loss: 1.4611\n",
      "Early stopping at epoch 182, Best Val Loss: 1.4611\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 144.7298, Val Loss: 5.5223, Best Val Loss: 5.5223\n",
      "Epoch 2/1000, Train Loss: 5.4815, Val Loss: 5.4417, Best Val Loss: 5.4417\n",
      "Epoch 3/1000, Train Loss: 5.4113, Val Loss: 5.3792, Best Val Loss: 5.3792\n",
      "Epoch 4/1000, Train Loss: 5.3524, Val Loss: 5.3264, Best Val Loss: 5.3264\n",
      "Epoch 5/1000, Train Loss: 5.3036, Val Loss: 5.2822, Best Val Loss: 5.2822\n",
      "Epoch 6/1000, Train Loss: 5.2586, Val Loss: 5.2344, Best Val Loss: 5.2344\n",
      "Epoch 7/1000, Train Loss: 5.2035, Val Loss: 5.1680, Best Val Loss: 5.1680\n",
      "Epoch 8/1000, Train Loss: 5.1073, Val Loss: 5.0173, Best Val Loss: 5.0173\n",
      "Epoch 9/1000, Train Loss: 4.0123, Val Loss: 2.3603, Best Val Loss: 2.3603\n",
      "Epoch 10/1000, Train Loss: 2.2001, Val Loss: 2.0960, Best Val Loss: 2.0960\n",
      "Epoch 11/1000, Train Loss: 2.0172, Val Loss: 1.9627, Best Val Loss: 1.9627\n",
      "Epoch 12/1000, Train Loss: 1.9275, Val Loss: 1.8961, Best Val Loss: 1.8961\n",
      "Epoch 13/1000, Train Loss: 1.8644, Val Loss: 1.8491, Best Val Loss: 1.8491\n",
      "Epoch 14/1000, Train Loss: 1.8212, Val Loss: 1.8130, Best Val Loss: 1.8130\n",
      "Epoch 15/1000, Train Loss: 1.7960, Val Loss: 1.8069, Best Val Loss: 1.8069\n",
      "Epoch 16/1000, Train Loss: 1.7658, Val Loss: 1.7509, Best Val Loss: 1.7509\n",
      "Epoch 20/1000, Train Loss: 1.7036, Val Loss: 1.6939, Best Val Loss: 1.6939\n",
      "Epoch 22/1000, Train Loss: 1.6869, Val Loss: 1.6852, Best Val Loss: 1.6852\n",
      "Epoch 24/1000, Train Loss: 1.6605, Val Loss: 1.6652, Best Val Loss: 1.6652\n",
      "Epoch 25/1000, Train Loss: 1.6620, Val Loss: 1.6632, Best Val Loss: 1.6632\n",
      "Epoch 26/1000, Train Loss: 1.6399, Val Loss: 1.6491, Best Val Loss: 1.6491\n",
      "Epoch 27/1000, Train Loss: 1.6353, Val Loss: 1.6410, Best Val Loss: 1.6410\n",
      "Epoch 30/1000, Train Loss: 1.6174, Val Loss: 1.6023, Best Val Loss: 1.6023\n",
      "Epoch 33/1000, Train Loss: 1.5810, Val Loss: 1.5961, Best Val Loss: 1.5961\n",
      "Epoch 37/1000, Train Loss: 1.5568, Val Loss: 1.5914, Best Val Loss: 1.5914\n",
      "Epoch 40/1000, Train Loss: 1.5322, Val Loss: 1.5523, Best Val Loss: 1.5523\n",
      "Epoch 48/1000, Train Loss: 1.5016, Val Loss: 1.5460, Best Val Loss: 1.5460\n",
      "Epoch 52/1000, Train Loss: 1.4833, Val Loss: 1.5379, Best Val Loss: 1.5379\n",
      "Epoch 53/1000, Train Loss: 1.4916, Val Loss: 1.5214, Best Val Loss: 1.5214\n",
      "Epoch 54/1000, Train Loss: 1.4837, Val Loss: 1.5189, Best Val Loss: 1.5189\n",
      "Epoch 56/1000, Train Loss: 1.4778, Val Loss: 1.5060, Best Val Loss: 1.5060\n",
      "Epoch 67/1000, Train Loss: 1.4507, Val Loss: 1.4951, Best Val Loss: 1.4951\n",
      "Epoch 71/1000, Train Loss: 1.4432, Val Loss: 1.4847, Best Val Loss: 1.4847\n",
      "Epoch 77/1000, Train Loss: 1.4238, Val Loss: 1.4836, Best Val Loss: 1.4836\n",
      "Epoch 106/1000, Train Loss: 1.3771, Val Loss: 1.4832, Best Val Loss: 1.4832\n",
      "Epoch 118/1000, Train Loss: 1.3593, Val Loss: 1.4705, Best Val Loss: 1.4705\n",
      "Early stopping at epoch 168, Best Val Loss: 1.4705\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 137.3998, Val Loss: 5.5874, Best Val Loss: 5.5874\n",
      "Epoch 2/1000, Train Loss: 5.5199, Val Loss: 5.4521, Best Val Loss: 5.4521\n",
      "Epoch 3/1000, Train Loss: 5.3947, Val Loss: 5.3279, Best Val Loss: 5.3279\n",
      "Epoch 4/1000, Train Loss: 5.2286, Val Loss: 5.0765, Best Val Loss: 5.0765\n",
      "Epoch 5/1000, Train Loss: 4.1129, Val Loss: 2.5671, Best Val Loss: 2.5671\n",
      "Epoch 6/1000, Train Loss: 2.4027, Val Loss: 2.2824, Best Val Loss: 2.2824\n",
      "Epoch 7/1000, Train Loss: 2.1739, Val Loss: 2.1084, Best Val Loss: 2.1084\n",
      "Epoch 8/1000, Train Loss: 2.0239, Val Loss: 1.9882, Best Val Loss: 1.9882\n",
      "Epoch 9/1000, Train Loss: 1.9324, Val Loss: 1.9033, Best Val Loss: 1.9033\n",
      "Epoch 11/1000, Train Loss: 1.8378, Val Loss: 1.8140, Best Val Loss: 1.8140\n",
      "Epoch 13/1000, Train Loss: 1.7786, Val Loss: 1.7869, Best Val Loss: 1.7869\n",
      "Epoch 14/1000, Train Loss: 1.7553, Val Loss: 1.7596, Best Val Loss: 1.7596\n",
      "Epoch 16/1000, Train Loss: 1.7296, Val Loss: 1.7238, Best Val Loss: 1.7238\n",
      "Epoch 18/1000, Train Loss: 1.6990, Val Loss: 1.7137, Best Val Loss: 1.7137\n",
      "Epoch 19/1000, Train Loss: 1.7080, Val Loss: 1.6796, Best Val Loss: 1.6796\n",
      "Epoch 23/1000, Train Loss: 1.6644, Val Loss: 1.6499, Best Val Loss: 1.6499\n",
      "Epoch 25/1000, Train Loss: 1.6491, Val Loss: 1.6392, Best Val Loss: 1.6392\n",
      "Epoch 26/1000, Train Loss: 1.6385, Val Loss: 1.6324, Best Val Loss: 1.6324\n",
      "Epoch 34/1000, Train Loss: 1.5979, Val Loss: 1.6036, Best Val Loss: 1.6036\n",
      "Epoch 35/1000, Train Loss: 1.5915, Val Loss: 1.5735, Best Val Loss: 1.5735\n",
      "Epoch 41/1000, Train Loss: 1.5439, Val Loss: 1.5657, Best Val Loss: 1.5657\n",
      "Epoch 45/1000, Train Loss: 1.5332, Val Loss: 1.5542, Best Val Loss: 1.5542\n",
      "Epoch 47/1000, Train Loss: 1.5256, Val Loss: 1.5436, Best Val Loss: 1.5436\n",
      "Epoch 52/1000, Train Loss: 1.5090, Val Loss: 1.5228, Best Val Loss: 1.5228\n",
      "Epoch 57/1000, Train Loss: 1.4954, Val Loss: 1.5055, Best Val Loss: 1.5055\n",
      "Epoch 69/1000, Train Loss: 1.4506, Val Loss: 1.4992, Best Val Loss: 1.4992\n",
      "Epoch 70/1000, Train Loss: 1.4521, Val Loss: 1.4873, Best Val Loss: 1.4873\n",
      "Epoch 97/1000, Train Loss: 1.3947, Val Loss: 1.4866, Best Val Loss: 1.4866\n",
      "Epoch 100/1000, Train Loss: 1.4006, Val Loss: 1.4815, Best Val Loss: 1.4815\n",
      "Epoch 102/1000, Train Loss: 1.3907, Val Loss: 1.4698, Best Val Loss: 1.4698\n",
      "Epoch 128/1000, Train Loss: 1.3621, Val Loss: 1.4653, Best Val Loss: 1.4653\n",
      "Epoch 156/1000, Train Loss: 1.3247, Val Loss: 1.4626, Best Val Loss: 1.4626\n",
      "Early stopping at epoch 206, Best Val Loss: 1.4626\n",
      "Epistemic Variance: 0.950219\n",
      "Aleatoric Variance: 8.131834\n",
      " (1/n) Calculating accuracy metrics\n",
      " (2/n) Calculating average calibration metrics\n",
      " (3/n) Calculating adversarial group calibration metrics\n",
      "  [1/2] for mean absolute calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [2/2] for root mean squared calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (4/n) Calculating sharpness metrics\n",
      " (n/n) Calculating proper scoring rule metrics\n",
      "**Finished Calculating All Metrics**\n",
      "\n",
      "\n",
      "===================== Accuracy Metrics =====================\n",
      "  MAE           1.955\n",
      "  RMSE          2.772\n",
      "  MDAE          1.437\n",
      "  MARPD         1.707\n",
      "  R2            0.865\n",
      "  Correlation   0.930\n",
      "=============== Average Calibration Metrics ================\n",
      "  Root-mean-squared Calibration Error   0.038\n",
      "  Mean-absolute Calibration Error       0.035\n",
      "  Miscalibration Area                   0.035\n",
      "========== Adversarial Group Calibration Metrics ===========\n",
      "  Mean-absolute Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.047\n",
      "     Group Size: 0.56 -- Calibration Error: 0.038\n",
      "     Group Size: 1.00 -- Calibration Error: 0.035\n",
      "  Root-mean-squared Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.052\n",
      "     Group Size: 0.56 -- Calibration Error: 0.041\n",
      "     Group Size: 1.00 -- Calibration Error: 0.038\n",
      "==================== Sharpness Metrics =====================\n",
      "  Sharpness   3.014\n",
      "=================== Scoring Rule Metrics ===================\n",
      "  Negative-log-likelihood   2.275\n",
      "  CRPS                      1.407\n",
      "  Check Score               0.710\n",
      "  Interval Score            7.071\n",
      "{'accuracy': {'mae': 1.9553234257196221, 'rmse': np.float64(2.7723194239936166), 'mdae': 1.4367778320312539, 'marpd': np.float64(1.7074280226481813), 'r2': 0.8654013482974411, 'corr': np.float64(0.9303692146981556)}, 'avg_calibration': {'rms_cal': np.float64(0.038198241820928736), 'ma_cal': np.float64(0.03466934072047977), 'miscal_area': np.float64(0.035017906729243146)}, 'adv_group_calibration': {'ma_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.35806566, 0.0468882 , 0.0431441 , 0.03978249, 0.03973291,\n",
      "       0.03792473, 0.0372925 , 0.03697093, 0.03621653, 0.03466934]), 'adv_group_cali_stderr': array([0.03815362, 0.00549001, 0.00223598, 0.00230389, 0.00181237,\n",
      "       0.0016834 , 0.00082792, 0.0007906 , 0.00095906, 0.        ])}, 'rms_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.42927098, 0.0515571 , 0.0489745 , 0.04698195, 0.04286063,\n",
      "       0.04134018, 0.04137244, 0.04077623, 0.04009723, 0.03819824]), 'adv_group_cali_stderr': array([0.06359357, 0.0050217 , 0.00551743, 0.00270776, 0.00204423,\n",
      "       0.00116332, 0.00119303, 0.00106979, 0.00057727, 0.        ])}}, 'sharpness': {'sharp': np.float32(3.0136445)}, 'scoring_rule': {'nll': np.float64(2.2752694691825286), 'crps': np.float64(1.4068051165002082), 'check': np.float64(0.7103174672683034), 'interval': np.float64(7.070962110682711)}}\n",
      "coverage: 0.9543400942035951, MPIW: 10.323772811019042\n",
      "Run 4 with seed 2024\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 150.6342, Val Loss: 5.4654, Best Val Loss: 5.4654\n",
      "Epoch 2/1000, Train Loss: 5.4191, Val Loss: 5.3673, Best Val Loss: 5.3673\n",
      "Epoch 3/1000, Train Loss: 5.3242, Val Loss: 5.2774, Best Val Loss: 5.2774\n",
      "Epoch 4/1000, Train Loss: 5.2248, Val Loss: 5.1557, Best Val Loss: 5.1557\n",
      "Epoch 5/1000, Train Loss: 4.4915, Val Loss: 2.5514, Best Val Loss: 2.5514\n",
      "Epoch 6/1000, Train Loss: 2.3217, Val Loss: 2.1962, Best Val Loss: 2.1962\n",
      "Epoch 7/1000, Train Loss: 2.0974, Val Loss: 2.0475, Best Val Loss: 2.0475\n",
      "Epoch 8/1000, Train Loss: 1.9775, Val Loss: 1.9392, Best Val Loss: 1.9392\n",
      "Epoch 9/1000, Train Loss: 1.8946, Val Loss: 1.9035, Best Val Loss: 1.9035\n",
      "Epoch 10/1000, Train Loss: 1.8441, Val Loss: 1.8176, Best Val Loss: 1.8176\n",
      "Epoch 11/1000, Train Loss: 1.8061, Val Loss: 1.8072, Best Val Loss: 1.8072\n",
      "Epoch 12/1000, Train Loss: 1.7847, Val Loss: 1.7571, Best Val Loss: 1.7571\n",
      "Epoch 13/1000, Train Loss: 1.7607, Val Loss: 1.7462, Best Val Loss: 1.7462\n",
      "Epoch 16/1000, Train Loss: 1.7141, Val Loss: 1.7051, Best Val Loss: 1.7051\n",
      "Epoch 19/1000, Train Loss: 1.6753, Val Loss: 1.6919, Best Val Loss: 1.6919\n",
      "Epoch 21/1000, Train Loss: 1.6528, Val Loss: 1.6644, Best Val Loss: 1.6644\n",
      "Epoch 22/1000, Train Loss: 1.6552, Val Loss: 1.6294, Best Val Loss: 1.6294\n",
      "Epoch 26/1000, Train Loss: 1.6210, Val Loss: 1.6228, Best Val Loss: 1.6228\n",
      "Epoch 29/1000, Train Loss: 1.5985, Val Loss: 1.6109, Best Val Loss: 1.6109\n",
      "Epoch 32/1000, Train Loss: 1.5826, Val Loss: 1.5949, Best Val Loss: 1.5949\n",
      "Epoch 35/1000, Train Loss: 1.5629, Val Loss: 1.5918, Best Val Loss: 1.5918\n",
      "Epoch 36/1000, Train Loss: 1.5550, Val Loss: 1.5579, Best Val Loss: 1.5579\n",
      "Epoch 41/1000, Train Loss: 1.5224, Val Loss: 1.5448, Best Val Loss: 1.5448\n",
      "Epoch 44/1000, Train Loss: 1.5106, Val Loss: 1.5277, Best Val Loss: 1.5277\n",
      "Epoch 47/1000, Train Loss: 1.4980, Val Loss: 1.5258, Best Val Loss: 1.5258\n",
      "Epoch 48/1000, Train Loss: 1.4998, Val Loss: 1.5237, Best Val Loss: 1.5237\n",
      "Epoch 54/1000, Train Loss: 1.4734, Val Loss: 1.4920, Best Val Loss: 1.4920\n",
      "Epoch 69/1000, Train Loss: 1.4344, Val Loss: 1.4778, Best Val Loss: 1.4778\n",
      "Epoch 77/1000, Train Loss: 1.4109, Val Loss: 1.4566, Best Val Loss: 1.4566\n",
      "Early stopping at epoch 127, Best Val Loss: 1.4566\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 113.1164, Val Loss: 5.4901, Best Val Loss: 5.4901\n",
      "Epoch 2/1000, Train Loss: 5.4280, Val Loss: 5.3713, Best Val Loss: 5.3713\n",
      "Epoch 3/1000, Train Loss: 5.3279, Val Loss: 5.2860, Best Val Loss: 5.2860\n",
      "Epoch 4/1000, Train Loss: 5.2420, Val Loss: 5.1920, Best Val Loss: 5.1920\n",
      "Epoch 5/1000, Train Loss: 5.0568, Val Loss: 4.5372, Best Val Loss: 4.5372\n",
      "Epoch 6/1000, Train Loss: 2.5784, Val Loss: 2.2451, Best Val Loss: 2.2451\n",
      "Epoch 7/1000, Train Loss: 2.1350, Val Loss: 2.0592, Best Val Loss: 2.0592\n",
      "Epoch 8/1000, Train Loss: 1.9884, Val Loss: 1.9537, Best Val Loss: 1.9537\n",
      "Epoch 9/1000, Train Loss: 1.8966, Val Loss: 1.8796, Best Val Loss: 1.8796\n",
      "Epoch 10/1000, Train Loss: 1.8463, Val Loss: 1.8391, Best Val Loss: 1.8391\n",
      "Epoch 11/1000, Train Loss: 1.8048, Val Loss: 1.8237, Best Val Loss: 1.8237\n",
      "Epoch 12/1000, Train Loss: 1.7775, Val Loss: 1.7650, Best Val Loss: 1.7650\n",
      "Epoch 14/1000, Train Loss: 1.7376, Val Loss: 1.7472, Best Val Loss: 1.7472\n",
      "Epoch 17/1000, Train Loss: 1.6944, Val Loss: 1.7151, Best Val Loss: 1.7151\n",
      "Epoch 19/1000, Train Loss: 1.6682, Val Loss: 1.6765, Best Val Loss: 1.6765\n",
      "Epoch 22/1000, Train Loss: 1.6411, Val Loss: 1.6718, Best Val Loss: 1.6718\n",
      "Epoch 23/1000, Train Loss: 1.6407, Val Loss: 1.6619, Best Val Loss: 1.6619\n",
      "Epoch 25/1000, Train Loss: 1.6222, Val Loss: 1.6319, Best Val Loss: 1.6319\n",
      "Epoch 29/1000, Train Loss: 1.5912, Val Loss: 1.6183, Best Val Loss: 1.6183\n",
      "Epoch 30/1000, Train Loss: 1.5752, Val Loss: 1.5920, Best Val Loss: 1.5920\n",
      "Epoch 31/1000, Train Loss: 1.5761, Val Loss: 1.5771, Best Val Loss: 1.5771\n",
      "Epoch 34/1000, Train Loss: 1.5445, Val Loss: 1.5717, Best Val Loss: 1.5717\n",
      "Epoch 36/1000, Train Loss: 1.5465, Val Loss: 1.5580, Best Val Loss: 1.5580\n",
      "Epoch 38/1000, Train Loss: 1.5284, Val Loss: 1.5389, Best Val Loss: 1.5389\n",
      "Epoch 41/1000, Train Loss: 1.5036, Val Loss: 1.5215, Best Val Loss: 1.5215\n",
      "Epoch 52/1000, Train Loss: 1.4708, Val Loss: 1.5122, Best Val Loss: 1.5122\n",
      "Epoch 53/1000, Train Loss: 1.4697, Val Loss: 1.5052, Best Val Loss: 1.5052\n",
      "Epoch 64/1000, Train Loss: 1.4384, Val Loss: 1.4969, Best Val Loss: 1.4969\n",
      "Epoch 69/1000, Train Loss: 1.4328, Val Loss: 1.4964, Best Val Loss: 1.4964\n",
      "Epoch 70/1000, Train Loss: 1.4205, Val Loss: 1.4909, Best Val Loss: 1.4909\n",
      "Epoch 75/1000, Train Loss: 1.4121, Val Loss: 1.4817, Best Val Loss: 1.4817\n",
      "Epoch 84/1000, Train Loss: 1.3945, Val Loss: 1.4722, Best Val Loss: 1.4722\n",
      "Early stopping at epoch 134, Best Val Loss: 1.4722\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 142.4738, Val Loss: 5.4270, Best Val Loss: 5.4270\n",
      "Epoch 2/1000, Train Loss: 5.3498, Val Loss: 5.2544, Best Val Loss: 5.2544\n",
      "Epoch 3/1000, Train Loss: 5.1777, Val Loss: 5.0805, Best Val Loss: 5.0805\n",
      "Epoch 4/1000, Train Loss: 4.7374, Val Loss: 3.7028, Best Val Loss: 3.7028\n",
      "Epoch 5/1000, Train Loss: 2.9066, Val Loss: 2.5962, Best Val Loss: 2.5962\n",
      "Epoch 6/1000, Train Loss: 2.4005, Val Loss: 2.2637, Best Val Loss: 2.2637\n",
      "Epoch 7/1000, Train Loss: 2.1623, Val Loss: 2.0933, Best Val Loss: 2.0933\n",
      "Epoch 8/1000, Train Loss: 2.0151, Val Loss: 1.9943, Best Val Loss: 1.9943\n",
      "Epoch 9/1000, Train Loss: 1.9229, Val Loss: 1.9299, Best Val Loss: 1.9299\n",
      "Epoch 10/1000, Train Loss: 1.8649, Val Loss: 1.8684, Best Val Loss: 1.8684\n",
      "Epoch 11/1000, Train Loss: 1.8185, Val Loss: 1.8127, Best Val Loss: 1.8127\n",
      "Epoch 12/1000, Train Loss: 1.7852, Val Loss: 1.7869, Best Val Loss: 1.7869\n",
      "Epoch 13/1000, Train Loss: 1.7619, Val Loss: 1.7791, Best Val Loss: 1.7791\n",
      "Epoch 15/1000, Train Loss: 1.7220, Val Loss: 1.7311, Best Val Loss: 1.7311\n",
      "Epoch 16/1000, Train Loss: 1.7193, Val Loss: 1.7192, Best Val Loss: 1.7192\n",
      "Epoch 17/1000, Train Loss: 1.6891, Val Loss: 1.6823, Best Val Loss: 1.6823\n",
      "Epoch 19/1000, Train Loss: 1.6808, Val Loss: 1.6803, Best Val Loss: 1.6803\n",
      "Epoch 23/1000, Train Loss: 1.6424, Val Loss: 1.6469, Best Val Loss: 1.6469\n",
      "Epoch 24/1000, Train Loss: 1.6407, Val Loss: 1.6281, Best Val Loss: 1.6281\n",
      "Epoch 30/1000, Train Loss: 1.5979, Val Loss: 1.6065, Best Val Loss: 1.6065\n",
      "Epoch 34/1000, Train Loss: 1.5801, Val Loss: 1.5967, Best Val Loss: 1.5967\n",
      "Epoch 37/1000, Train Loss: 1.5756, Val Loss: 1.5896, Best Val Loss: 1.5896\n",
      "Epoch 42/1000, Train Loss: 1.5467, Val Loss: 1.5659, Best Val Loss: 1.5659\n",
      "Epoch 44/1000, Train Loss: 1.5319, Val Loss: 1.5622, Best Val Loss: 1.5622\n",
      "Epoch 50/1000, Train Loss: 1.5138, Val Loss: 1.5303, Best Val Loss: 1.5303\n",
      "Epoch 55/1000, Train Loss: 1.5009, Val Loss: 1.5291, Best Val Loss: 1.5291\n",
      "Epoch 61/1000, Train Loss: 1.4861, Val Loss: 1.5188, Best Val Loss: 1.5188\n",
      "Epoch 63/1000, Train Loss: 1.4790, Val Loss: 1.5144, Best Val Loss: 1.5144\n",
      "Epoch 75/1000, Train Loss: 1.4483, Val Loss: 1.5118, Best Val Loss: 1.5118\n",
      "Epoch 81/1000, Train Loss: 1.4410, Val Loss: 1.4977, Best Val Loss: 1.4977\n",
      "Epoch 90/1000, Train Loss: 1.4229, Val Loss: 1.4897, Best Val Loss: 1.4897\n",
      "Epoch 100/1000, Train Loss: 1.4049, Val Loss: 1.4843, Best Val Loss: 1.4843\n",
      "Epoch 101/1000, Train Loss: 1.4134, Val Loss: 1.4782, Best Val Loss: 1.4782\n",
      "Epoch 122/1000, Train Loss: 1.3676, Val Loss: 1.4712, Best Val Loss: 1.4712\n",
      "Early stopping at epoch 172, Best Val Loss: 1.4712\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 150.6478, Val Loss: 5.5429, Best Val Loss: 5.5429\n",
      "Epoch 2/1000, Train Loss: 5.4851, Val Loss: 5.4372, Best Val Loss: 5.4372\n",
      "Epoch 3/1000, Train Loss: 5.3939, Val Loss: 5.3538, Best Val Loss: 5.3538\n",
      "Epoch 4/1000, Train Loss: 5.3134, Val Loss: 5.2771, Best Val Loss: 5.2771\n",
      "Epoch 5/1000, Train Loss: 5.2372, Val Loss: 5.1982, Best Val Loss: 5.1982\n",
      "Epoch 6/1000, Train Loss: 5.1437, Val Loss: 5.0790, Best Val Loss: 5.0790\n",
      "Epoch 7/1000, Train Loss: 4.6836, Val Loss: 2.6373, Best Val Loss: 2.6373\n",
      "Epoch 8/1000, Train Loss: 2.2637, Val Loss: 2.1394, Best Val Loss: 2.1394\n",
      "Epoch 9/1000, Train Loss: 2.0257, Val Loss: 1.9831, Best Val Loss: 1.9831\n",
      "Epoch 10/1000, Train Loss: 1.9131, Val Loss: 1.8724, Best Val Loss: 1.8724\n",
      "Epoch 11/1000, Train Loss: 1.8566, Val Loss: 1.8527, Best Val Loss: 1.8527\n",
      "Epoch 12/1000, Train Loss: 1.8223, Val Loss: 1.8130, Best Val Loss: 1.8130\n",
      "Epoch 13/1000, Train Loss: 1.7878, Val Loss: 1.7709, Best Val Loss: 1.7709\n",
      "Epoch 14/1000, Train Loss: 1.7550, Val Loss: 1.7382, Best Val Loss: 1.7382\n",
      "Epoch 16/1000, Train Loss: 1.7238, Val Loss: 1.7276, Best Val Loss: 1.7276\n",
      "Epoch 19/1000, Train Loss: 1.6905, Val Loss: 1.7037, Best Val Loss: 1.7037\n",
      "Epoch 20/1000, Train Loss: 1.6773, Val Loss: 1.6936, Best Val Loss: 1.6936\n",
      "Epoch 22/1000, Train Loss: 1.6699, Val Loss: 1.6741, Best Val Loss: 1.6741\n",
      "Epoch 23/1000, Train Loss: 1.6549, Val Loss: 1.6488, Best Val Loss: 1.6488\n",
      "Epoch 25/1000, Train Loss: 1.6371, Val Loss: 1.6443, Best Val Loss: 1.6443\n",
      "Epoch 27/1000, Train Loss: 1.6232, Val Loss: 1.6378, Best Val Loss: 1.6378\n",
      "Epoch 31/1000, Train Loss: 1.5945, Val Loss: 1.6362, Best Val Loss: 1.6362\n",
      "Epoch 33/1000, Train Loss: 1.5795, Val Loss: 1.5919, Best Val Loss: 1.5919\n",
      "Epoch 35/1000, Train Loss: 1.5695, Val Loss: 1.5800, Best Val Loss: 1.5800\n",
      "Epoch 38/1000, Train Loss: 1.5434, Val Loss: 1.5760, Best Val Loss: 1.5760\n",
      "Epoch 39/1000, Train Loss: 1.5399, Val Loss: 1.5432, Best Val Loss: 1.5432\n",
      "Epoch 48/1000, Train Loss: 1.5017, Val Loss: 1.5382, Best Val Loss: 1.5382\n",
      "Epoch 49/1000, Train Loss: 1.4853, Val Loss: 1.5186, Best Val Loss: 1.5186\n",
      "Epoch 64/1000, Train Loss: 1.4441, Val Loss: 1.5139, Best Val Loss: 1.5139\n",
      "Epoch 66/1000, Train Loss: 1.4333, Val Loss: 1.5078, Best Val Loss: 1.5078\n",
      "Epoch 70/1000, Train Loss: 1.4333, Val Loss: 1.4997, Best Val Loss: 1.4997\n",
      "Epoch 74/1000, Train Loss: 1.4228, Val Loss: 1.4942, Best Val Loss: 1.4942\n",
      "Epoch 76/1000, Train Loss: 1.4239, Val Loss: 1.4852, Best Val Loss: 1.4852\n",
      "Epoch 83/1000, Train Loss: 1.4043, Val Loss: 1.4740, Best Val Loss: 1.4740\n",
      "Epoch 96/1000, Train Loss: 1.3753, Val Loss: 1.4736, Best Val Loss: 1.4736\n",
      "Early stopping at epoch 146, Best Val Loss: 1.4736\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 117.1112, Val Loss: 5.5366, Best Val Loss: 5.5366\n",
      "Epoch 2/1000, Train Loss: 5.4747, Val Loss: 5.4159, Best Val Loss: 5.4159\n",
      "Epoch 3/1000, Train Loss: 5.3696, Val Loss: 5.3267, Best Val Loss: 5.3267\n",
      "Epoch 4/1000, Train Loss: 5.2936, Val Loss: 5.2630, Best Val Loss: 5.2630\n",
      "Epoch 5/1000, Train Loss: 5.2348, Val Loss: 5.2061, Best Val Loss: 5.2061\n",
      "Epoch 6/1000, Train Loss: 5.1684, Val Loss: 5.1250, Best Val Loss: 5.1250\n",
      "Epoch 7/1000, Train Loss: 5.0235, Val Loss: 4.7719, Best Val Loss: 4.7719\n",
      "Epoch 8/1000, Train Loss: 2.6401, Val Loss: 2.1969, Best Val Loss: 2.1969\n",
      "Epoch 9/1000, Train Loss: 2.0637, Val Loss: 2.0038, Best Val Loss: 2.0038\n",
      "Epoch 10/1000, Train Loss: 1.9332, Val Loss: 1.9173, Best Val Loss: 1.9173\n",
      "Epoch 11/1000, Train Loss: 1.8610, Val Loss: 1.8691, Best Val Loss: 1.8691\n",
      "Epoch 12/1000, Train Loss: 1.8187, Val Loss: 1.8216, Best Val Loss: 1.8216\n",
      "Epoch 14/1000, Train Loss: 1.7634, Val Loss: 1.7932, Best Val Loss: 1.7932\n",
      "Epoch 15/1000, Train Loss: 1.7431, Val Loss: 1.7426, Best Val Loss: 1.7426\n",
      "Epoch 16/1000, Train Loss: 1.7265, Val Loss: 1.7343, Best Val Loss: 1.7343\n",
      "Epoch 17/1000, Train Loss: 1.7181, Val Loss: 1.7057, Best Val Loss: 1.7057\n",
      "Epoch 21/1000, Train Loss: 1.6592, Val Loss: 1.6776, Best Val Loss: 1.6776\n",
      "Epoch 23/1000, Train Loss: 1.6411, Val Loss: 1.6448, Best Val Loss: 1.6448\n",
      "Epoch 29/1000, Train Loss: 1.5975, Val Loss: 1.6168, Best Val Loss: 1.6168\n",
      "Epoch 32/1000, Train Loss: 1.5749, Val Loss: 1.5968, Best Val Loss: 1.5968\n",
      "Epoch 33/1000, Train Loss: 1.5630, Val Loss: 1.5964, Best Val Loss: 1.5964\n",
      "Epoch 34/1000, Train Loss: 1.5664, Val Loss: 1.5793, Best Val Loss: 1.5793\n",
      "Epoch 40/1000, Train Loss: 1.5278, Val Loss: 1.5717, Best Val Loss: 1.5717\n",
      "Epoch 41/1000, Train Loss: 1.5154, Val Loss: 1.5417, Best Val Loss: 1.5417\n",
      "Epoch 49/1000, Train Loss: 1.4889, Val Loss: 1.5383, Best Val Loss: 1.5383\n",
      "Epoch 51/1000, Train Loss: 1.4772, Val Loss: 1.5207, Best Val Loss: 1.5207\n",
      "Epoch 54/1000, Train Loss: 1.4683, Val Loss: 1.4991, Best Val Loss: 1.4991\n",
      "Epoch 73/1000, Train Loss: 1.4239, Val Loss: 1.4689, Best Val Loss: 1.4689\n",
      "Epoch 94/1000, Train Loss: 1.3802, Val Loss: 1.4661, Best Val Loss: 1.4661\n",
      "Epoch 96/1000, Train Loss: 1.3868, Val Loss: 1.4555, Best Val Loss: 1.4555\n",
      "Early stopping at epoch 146, Best Val Loss: 1.4555\n",
      "Epistemic Variance: 0.919660\n",
      "Aleatoric Variance: 9.633337\n",
      " (1/n) Calculating accuracy metrics\n",
      " (2/n) Calculating average calibration metrics\n",
      " (3/n) Calculating adversarial group calibration metrics\n",
      "  [1/2] for mean absolute calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [2/2] for root mean squared calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (4/n) Calculating sharpness metrics\n",
      " (n/n) Calculating proper scoring rule metrics\n",
      "**Finished Calculating All Metrics**\n",
      "\n",
      "\n",
      "===================== Accuracy Metrics =====================\n",
      "  MAE           1.980\n",
      "  RMSE          2.797\n",
      "  MDAE          1.465\n",
      "  MARPD         1.729\n",
      "  R2            0.863\n",
      "  Correlation   0.929\n",
      "=============== Average Calibration Metrics ================\n",
      "  Root-mean-squared Calibration Error   0.030\n",
      "  Mean-absolute Calibration Error       0.026\n",
      "  Miscalibration Area                   0.027\n",
      "========== Adversarial Group Calibration Metrics ===========\n",
      "  Mean-absolute Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.038\n",
      "     Group Size: 0.56 -- Calibration Error: 0.030\n",
      "     Group Size: 1.00 -- Calibration Error: 0.026\n",
      "  Root-mean-squared Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.046\n",
      "     Group Size: 0.56 -- Calibration Error: 0.035\n",
      "     Group Size: 1.00 -- Calibration Error: 0.030\n",
      "==================== Sharpness Metrics =====================\n",
      "  Sharpness   3.249\n",
      "=================== Scoring Rule Metrics ===================\n",
      "  Negative-log-likelihood   2.282\n",
      "  CRPS                      1.419\n",
      "  Check Score               0.716\n",
      "  Interval Score            7.119\n",
      "{'accuracy': {'mae': 1.9795458945023374, 'rmse': np.float64(2.796578451216053), 'mdae': 1.4651736938476603, 'marpd': np.float64(1.7287886101981287), 'r2': 0.8630354459814187, 'corr': np.float64(0.9290851418744073)}, 'avg_calibration': {'rms_cal': np.float64(0.030280775472968487), 'ma_cal': np.float64(0.02636934567243129), 'miscal_area': np.float64(0.026633819097807248)}, 'adv_group_calibration': {'ma_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.37578283, 0.03803215, 0.03331795, 0.03412928, 0.03103681,\n",
      "       0.03003018, 0.02981068, 0.028727  , 0.02831702, 0.02636935]), 'adv_group_cali_stderr': array([7.65193842e-02, 4.83792836e-03, 2.16962495e-03, 2.55129793e-03,\n",
      "       2.28900217e-03, 2.29867703e-03, 9.32618287e-04, 1.17883258e-03,\n",
      "       9.45889376e-04, 3.65711820e-18])}, 'rms_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.42494029, 0.04582846, 0.0398267 , 0.03728014, 0.03574031,\n",
      "       0.0349037 , 0.03322847, 0.03275167, 0.0319394 , 0.03028078]), 'adv_group_cali_stderr': array([0.05538515, 0.00374151, 0.00248791, 0.00295331, 0.00095433,\n",
      "       0.00163896, 0.00119803, 0.0009051 , 0.0008428 , 0.        ])}}, 'sharpness': {'sharp': np.float32(3.2485378)}, 'scoring_rule': {'nll': np.float64(2.2816881388503742), 'crps': np.float64(1.41870340841148), 'check': np.float64(0.7163267761963674), 'interval': np.float64(7.11897319945172)}}\n",
      "coverage: 0.9540517158511967, MPIW: 10.255678692738515\n",
      "Run 5 with seed 5250\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 136.2163, Val Loss: 5.5831, Best Val Loss: 5.5831\n",
      "Epoch 2/1000, Train Loss: 5.5236, Val Loss: 5.4598, Best Val Loss: 5.4598\n",
      "Epoch 3/1000, Train Loss: 5.4162, Val Loss: 5.3626, Best Val Loss: 5.3626\n",
      "Epoch 4/1000, Train Loss: 5.3135, Val Loss: 5.2508, Best Val Loss: 5.2508\n",
      "Epoch 5/1000, Train Loss: 5.1513, Val Loss: 4.9922, Best Val Loss: 4.9922\n",
      "Epoch 6/1000, Train Loss: 3.8083, Val Loss: 2.4888, Best Val Loss: 2.4888\n",
      "Epoch 7/1000, Train Loss: 2.3390, Val Loss: 2.2224, Best Val Loss: 2.2224\n",
      "Epoch 8/1000, Train Loss: 2.1188, Val Loss: 2.0572, Best Val Loss: 2.0572\n",
      "Epoch 9/1000, Train Loss: 1.9779, Val Loss: 1.9454, Best Val Loss: 1.9454\n",
      "Epoch 10/1000, Train Loss: 1.8899, Val Loss: 1.8798, Best Val Loss: 1.8798\n",
      "Epoch 11/1000, Train Loss: 1.8370, Val Loss: 1.8454, Best Val Loss: 1.8454\n",
      "Epoch 12/1000, Train Loss: 1.7949, Val Loss: 1.8046, Best Val Loss: 1.8046\n",
      "Epoch 13/1000, Train Loss: 1.7762, Val Loss: 1.7527, Best Val Loss: 1.7527\n",
      "Epoch 16/1000, Train Loss: 1.7300, Val Loss: 1.7182, Best Val Loss: 1.7182\n",
      "Epoch 18/1000, Train Loss: 1.7091, Val Loss: 1.6967, Best Val Loss: 1.6967\n",
      "Epoch 20/1000, Train Loss: 1.6957, Val Loss: 1.6885, Best Val Loss: 1.6885\n",
      "Epoch 25/1000, Train Loss: 1.6572, Val Loss: 1.6521, Best Val Loss: 1.6521\n",
      "Epoch 27/1000, Train Loss: 1.6389, Val Loss: 1.6319, Best Val Loss: 1.6319\n",
      "Epoch 29/1000, Train Loss: 1.6313, Val Loss: 1.6056, Best Val Loss: 1.6056\n",
      "Epoch 35/1000, Train Loss: 1.5984, Val Loss: 1.5924, Best Val Loss: 1.5924\n",
      "Epoch 36/1000, Train Loss: 1.5940, Val Loss: 1.5862, Best Val Loss: 1.5862\n",
      "Epoch 38/1000, Train Loss: 1.5792, Val Loss: 1.5705, Best Val Loss: 1.5705\n",
      "Epoch 43/1000, Train Loss: 1.5539, Val Loss: 1.5594, Best Val Loss: 1.5594\n",
      "Epoch 44/1000, Train Loss: 1.5433, Val Loss: 1.5516, Best Val Loss: 1.5516\n",
      "Epoch 54/1000, Train Loss: 1.5051, Val Loss: 1.5396, Best Val Loss: 1.5396\n",
      "Epoch 55/1000, Train Loss: 1.4954, Val Loss: 1.5297, Best Val Loss: 1.5297\n",
      "Epoch 56/1000, Train Loss: 1.5040, Val Loss: 1.5169, Best Val Loss: 1.5169\n",
      "Epoch 65/1000, Train Loss: 1.4684, Val Loss: 1.5105, Best Val Loss: 1.5105\n",
      "Epoch 71/1000, Train Loss: 1.4622, Val Loss: 1.5098, Best Val Loss: 1.5098\n",
      "Epoch 81/1000, Train Loss: 1.4464, Val Loss: 1.5088, Best Val Loss: 1.5088\n",
      "Epoch 84/1000, Train Loss: 1.4305, Val Loss: 1.4944, Best Val Loss: 1.4944\n",
      "Epoch 94/1000, Train Loss: 1.4156, Val Loss: 1.4910, Best Val Loss: 1.4910\n",
      "Epoch 100/1000, Train Loss: 1.4165, Val Loss: 1.4780, Best Val Loss: 1.4780\n",
      "Epoch 114/1000, Train Loss: 1.3833, Val Loss: 1.4777, Best Val Loss: 1.4777\n",
      "Early stopping at epoch 164, Best Val Loss: 1.4777\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 139.7724, Val Loss: 5.5034, Best Val Loss: 5.5034\n",
      "Epoch 2/1000, Train Loss: 5.4299, Val Loss: 5.3693, Best Val Loss: 5.3693\n",
      "Epoch 3/1000, Train Loss: 5.3373, Val Loss: 5.2991, Best Val Loss: 5.2991\n",
      "Epoch 4/1000, Train Loss: 5.2703, Val Loss: 5.2366, Best Val Loss: 5.2366\n",
      "Epoch 5/1000, Train Loss: 5.2054, Val Loss: 5.1686, Best Val Loss: 5.1686\n",
      "Epoch 6/1000, Train Loss: 5.1045, Val Loss: 4.9714, Best Val Loss: 4.9714\n",
      "Epoch 7/1000, Train Loss: 3.1545, Val Loss: 2.2373, Best Val Loss: 2.2373\n",
      "Epoch 8/1000, Train Loss: 2.1140, Val Loss: 2.0205, Best Val Loss: 2.0205\n",
      "Epoch 9/1000, Train Loss: 1.9634, Val Loss: 1.9282, Best Val Loss: 1.9282\n",
      "Epoch 11/1000, Train Loss: 1.8233, Val Loss: 1.8059, Best Val Loss: 1.8059\n",
      "Epoch 13/1000, Train Loss: 1.7692, Val Loss: 1.7892, Best Val Loss: 1.7892\n",
      "Epoch 15/1000, Train Loss: 1.7302, Val Loss: 1.7551, Best Val Loss: 1.7551\n",
      "Epoch 16/1000, Train Loss: 1.7203, Val Loss: 1.7294, Best Val Loss: 1.7294\n",
      "Epoch 17/1000, Train Loss: 1.7051, Val Loss: 1.7050, Best Val Loss: 1.7050\n",
      "Epoch 20/1000, Train Loss: 1.6869, Val Loss: 1.6997, Best Val Loss: 1.6997\n",
      "Epoch 22/1000, Train Loss: 1.6525, Val Loss: 1.6503, Best Val Loss: 1.6503\n",
      "Epoch 25/1000, Train Loss: 1.6303, Val Loss: 1.6107, Best Val Loss: 1.6107\n",
      "Epoch 30/1000, Train Loss: 1.5823, Val Loss: 1.5907, Best Val Loss: 1.5907\n",
      "Epoch 34/1000, Train Loss: 1.5559, Val Loss: 1.5621, Best Val Loss: 1.5621\n",
      "Epoch 35/1000, Train Loss: 1.5603, Val Loss: 1.5563, Best Val Loss: 1.5563\n",
      "Epoch 40/1000, Train Loss: 1.5142, Val Loss: 1.5484, Best Val Loss: 1.5484\n",
      "Epoch 45/1000, Train Loss: 1.4932, Val Loss: 1.5145, Best Val Loss: 1.5145\n",
      "Epoch 57/1000, Train Loss: 1.4535, Val Loss: 1.5138, Best Val Loss: 1.5138\n",
      "Epoch 59/1000, Train Loss: 1.4583, Val Loss: 1.5015, Best Val Loss: 1.5015\n",
      "Epoch 64/1000, Train Loss: 1.4382, Val Loss: 1.4893, Best Val Loss: 1.4893\n",
      "Epoch 73/1000, Train Loss: 1.4142, Val Loss: 1.4886, Best Val Loss: 1.4886\n",
      "Epoch 98/1000, Train Loss: 1.3738, Val Loss: 1.4832, Best Val Loss: 1.4832\n",
      "Early stopping at epoch 148, Best Val Loss: 1.4832\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 127.9004, Val Loss: 5.4402, Best Val Loss: 5.4402\n",
      "Epoch 2/1000, Train Loss: 5.3908, Val Loss: 5.3413, Best Val Loss: 5.3413\n",
      "Epoch 3/1000, Train Loss: 5.3115, Val Loss: 5.2777, Best Val Loss: 5.2777\n",
      "Epoch 4/1000, Train Loss: 5.2538, Val Loss: 5.2271, Best Val Loss: 5.2271\n",
      "Epoch 5/1000, Train Loss: 5.2030, Val Loss: 5.1727, Best Val Loss: 5.1727\n",
      "Epoch 6/1000, Train Loss: 4.9935, Val Loss: 3.6216, Best Val Loss: 3.6216\n",
      "Epoch 7/1000, Train Loss: 2.4757, Val Loss: 2.1982, Best Val Loss: 2.1982\n",
      "Epoch 8/1000, Train Loss: 2.0522, Val Loss: 1.9890, Best Val Loss: 1.9890\n",
      "Epoch 9/1000, Train Loss: 1.9290, Val Loss: 1.8905, Best Val Loss: 1.8905\n",
      "Epoch 10/1000, Train Loss: 1.8583, Val Loss: 1.8660, Best Val Loss: 1.8660\n",
      "Epoch 12/1000, Train Loss: 1.7723, Val Loss: 1.8465, Best Val Loss: 1.8465\n",
      "Epoch 13/1000, Train Loss: 1.7598, Val Loss: 1.7591, Best Val Loss: 1.7591\n",
      "Epoch 16/1000, Train Loss: 1.7064, Val Loss: 1.7430, Best Val Loss: 1.7430\n",
      "Epoch 17/1000, Train Loss: 1.6792, Val Loss: 1.7029, Best Val Loss: 1.7029\n",
      "Epoch 19/1000, Train Loss: 1.6641, Val Loss: 1.6820, Best Val Loss: 1.6820\n",
      "Epoch 22/1000, Train Loss: 1.6306, Val Loss: 1.6633, Best Val Loss: 1.6633\n",
      "Epoch 23/1000, Train Loss: 1.6274, Val Loss: 1.6570, Best Val Loss: 1.6570\n",
      "Epoch 24/1000, Train Loss: 1.6218, Val Loss: 1.6489, Best Val Loss: 1.6489\n",
      "Epoch 25/1000, Train Loss: 1.6153, Val Loss: 1.6383, Best Val Loss: 1.6383\n",
      "Epoch 29/1000, Train Loss: 1.5899, Val Loss: 1.6075, Best Val Loss: 1.6075\n",
      "Epoch 30/1000, Train Loss: 1.5759, Val Loss: 1.6024, Best Val Loss: 1.6024\n",
      "Epoch 34/1000, Train Loss: 1.5567, Val Loss: 1.5732, Best Val Loss: 1.5732\n",
      "Epoch 35/1000, Train Loss: 1.5484, Val Loss: 1.5665, Best Val Loss: 1.5665\n",
      "Epoch 37/1000, Train Loss: 1.5317, Val Loss: 1.5529, Best Val Loss: 1.5529\n",
      "Epoch 39/1000, Train Loss: 1.5200, Val Loss: 1.5413, Best Val Loss: 1.5413\n",
      "Epoch 43/1000, Train Loss: 1.5058, Val Loss: 1.5359, Best Val Loss: 1.5359\n",
      "Epoch 48/1000, Train Loss: 1.4814, Val Loss: 1.5345, Best Val Loss: 1.5345\n",
      "Epoch 50/1000, Train Loss: 1.4792, Val Loss: 1.5173, Best Val Loss: 1.5173\n",
      "Epoch 55/1000, Train Loss: 1.4589, Val Loss: 1.5063, Best Val Loss: 1.5063\n",
      "Epoch 63/1000, Train Loss: 1.4467, Val Loss: 1.5013, Best Val Loss: 1.5013\n",
      "Epoch 68/1000, Train Loss: 1.4274, Val Loss: 1.4907, Best Val Loss: 1.4907\n",
      "Epoch 83/1000, Train Loss: 1.4088, Val Loss: 1.4816, Best Val Loss: 1.4816\n",
      "Epoch 86/1000, Train Loss: 1.3828, Val Loss: 1.4774, Best Val Loss: 1.4774\n",
      "Epoch 116/1000, Train Loss: 1.3347, Val Loss: 1.4768, Best Val Loss: 1.4768\n",
      "Epoch 117/1000, Train Loss: 1.3332, Val Loss: 1.4683, Best Val Loss: 1.4683\n",
      "Early stopping at epoch 167, Best Val Loss: 1.4683\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 143.6859, Val Loss: 5.5210, Best Val Loss: 5.5210\n",
      "Epoch 2/1000, Train Loss: 5.4611, Val Loss: 5.3948, Best Val Loss: 5.3948\n",
      "Epoch 3/1000, Train Loss: 5.2937, Val Loss: 5.1258, Best Val Loss: 5.1258\n",
      "Epoch 4/1000, Train Loss: 4.1154, Val Loss: 2.6976, Best Val Loss: 2.6976\n",
      "Epoch 5/1000, Train Loss: 2.5360, Val Loss: 2.4201, Best Val Loss: 2.4201\n",
      "Epoch 6/1000, Train Loss: 2.3044, Val Loss: 2.2240, Best Val Loss: 2.2240\n",
      "Epoch 7/1000, Train Loss: 2.1291, Val Loss: 2.0827, Best Val Loss: 2.0827\n",
      "Epoch 8/1000, Train Loss: 2.0081, Val Loss: 1.9962, Best Val Loss: 1.9962\n",
      "Epoch 9/1000, Train Loss: 1.9083, Val Loss: 1.8962, Best Val Loss: 1.8962\n",
      "Epoch 10/1000, Train Loss: 1.8423, Val Loss: 1.8267, Best Val Loss: 1.8267\n",
      "Epoch 11/1000, Train Loss: 1.8086, Val Loss: 1.7824, Best Val Loss: 1.7824\n",
      "Epoch 12/1000, Train Loss: 1.7708, Val Loss: 1.7717, Best Val Loss: 1.7717\n",
      "Epoch 14/1000, Train Loss: 1.7438, Val Loss: 1.7360, Best Val Loss: 1.7360\n",
      "Epoch 17/1000, Train Loss: 1.7019, Val Loss: 1.6854, Best Val Loss: 1.6854\n",
      "Epoch 19/1000, Train Loss: 1.6766, Val Loss: 1.6703, Best Val Loss: 1.6703\n",
      "Epoch 21/1000, Train Loss: 1.6721, Val Loss: 1.6562, Best Val Loss: 1.6562\n",
      "Epoch 23/1000, Train Loss: 1.6439, Val Loss: 1.6459, Best Val Loss: 1.6459\n",
      "Epoch 25/1000, Train Loss: 1.6533, Val Loss: 1.6290, Best Val Loss: 1.6290\n",
      "Epoch 26/1000, Train Loss: 1.6357, Val Loss: 1.6079, Best Val Loss: 1.6079\n",
      "Epoch 32/1000, Train Loss: 1.5970, Val Loss: 1.6001, Best Val Loss: 1.6001\n",
      "Epoch 36/1000, Train Loss: 1.5879, Val Loss: 1.5883, Best Val Loss: 1.5883\n",
      "Epoch 38/1000, Train Loss: 1.5612, Val Loss: 1.5847, Best Val Loss: 1.5847\n",
      "Epoch 39/1000, Train Loss: 1.5602, Val Loss: 1.5796, Best Val Loss: 1.5796\n",
      "Epoch 42/1000, Train Loss: 1.5480, Val Loss: 1.5666, Best Val Loss: 1.5666\n",
      "Epoch 47/1000, Train Loss: 1.5286, Val Loss: 1.5660, Best Val Loss: 1.5660\n",
      "Epoch 49/1000, Train Loss: 1.5176, Val Loss: 1.5651, Best Val Loss: 1.5651\n",
      "Epoch 50/1000, Train Loss: 1.5168, Val Loss: 1.5633, Best Val Loss: 1.5633\n",
      "Epoch 51/1000, Train Loss: 1.5167, Val Loss: 1.5388, Best Val Loss: 1.5388\n",
      "Epoch 54/1000, Train Loss: 1.4997, Val Loss: 1.5331, Best Val Loss: 1.5331\n",
      "Epoch 56/1000, Train Loss: 1.5103, Val Loss: 1.5271, Best Val Loss: 1.5271\n",
      "Epoch 61/1000, Train Loss: 1.4888, Val Loss: 1.5181, Best Val Loss: 1.5181\n",
      "Epoch 63/1000, Train Loss: 1.4895, Val Loss: 1.5054, Best Val Loss: 1.5054\n",
      "Epoch 65/1000, Train Loss: 1.4662, Val Loss: 1.4996, Best Val Loss: 1.4996\n",
      "Epoch 74/1000, Train Loss: 1.4570, Val Loss: 1.4966, Best Val Loss: 1.4966\n",
      "Epoch 81/1000, Train Loss: 1.4396, Val Loss: 1.4803, Best Val Loss: 1.4803\n",
      "Epoch 101/1000, Train Loss: 1.4000, Val Loss: 1.4763, Best Val Loss: 1.4763\n",
      "Epoch 106/1000, Train Loss: 1.3996, Val Loss: 1.4762, Best Val Loss: 1.4762\n",
      "Epoch 107/1000, Train Loss: 1.3885, Val Loss: 1.4675, Best Val Loss: 1.4675\n",
      "Epoch 135/1000, Train Loss: 1.3520, Val Loss: 1.4674, Best Val Loss: 1.4674\n",
      "Epoch 163/1000, Train Loss: 1.3212, Val Loss: 1.4674, Best Val Loss: 1.4674\n",
      "Epoch 195/1000, Train Loss: 1.2865, Val Loss: 1.4660, Best Val Loss: 1.4660\n",
      "Early stopping at epoch 245, Best Val Loss: 1.4660\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 126.3599, Val Loss: 5.5340, Best Val Loss: 5.5340\n",
      "Epoch 2/1000, Train Loss: 5.4846, Val Loss: 5.4271, Best Val Loss: 5.4271\n",
      "Epoch 3/1000, Train Loss: 5.3918, Val Loss: 5.3476, Best Val Loss: 5.3476\n",
      "Epoch 4/1000, Train Loss: 5.3157, Val Loss: 5.2774, Best Val Loss: 5.2774\n",
      "Epoch 5/1000, Train Loss: 5.2421, Val Loss: 5.1972, Best Val Loss: 5.1972\n",
      "Epoch 6/1000, Train Loss: 5.0579, Val Loss: 4.2504, Best Val Loss: 4.2504\n",
      "Epoch 7/1000, Train Loss: 2.4458, Val Loss: 2.2119, Best Val Loss: 2.2119\n",
      "Epoch 8/1000, Train Loss: 2.0963, Val Loss: 2.0334, Best Val Loss: 2.0334\n",
      "Epoch 9/1000, Train Loss: 1.9671, Val Loss: 1.9235, Best Val Loss: 1.9235\n",
      "Epoch 10/1000, Train Loss: 1.8899, Val Loss: 1.8962, Best Val Loss: 1.8962\n",
      "Epoch 11/1000, Train Loss: 1.8481, Val Loss: 1.8379, Best Val Loss: 1.8379\n",
      "Epoch 12/1000, Train Loss: 1.8138, Val Loss: 1.8113, Best Val Loss: 1.8113\n",
      "Epoch 14/1000, Train Loss: 1.7605, Val Loss: 1.7580, Best Val Loss: 1.7580\n",
      "Epoch 15/1000, Train Loss: 1.7471, Val Loss: 1.7331, Best Val Loss: 1.7331\n",
      "Epoch 18/1000, Train Loss: 1.6925, Val Loss: 1.6807, Best Val Loss: 1.6807\n",
      "Epoch 21/1000, Train Loss: 1.6680, Val Loss: 1.6799, Best Val Loss: 1.6799\n",
      "Epoch 23/1000, Train Loss: 1.6462, Val Loss: 1.6503, Best Val Loss: 1.6503\n",
      "Epoch 25/1000, Train Loss: 1.6308, Val Loss: 1.6354, Best Val Loss: 1.6354\n",
      "Epoch 26/1000, Train Loss: 1.6253, Val Loss: 1.6293, Best Val Loss: 1.6293\n",
      "Epoch 28/1000, Train Loss: 1.6061, Val Loss: 1.6011, Best Val Loss: 1.6011\n",
      "Epoch 38/1000, Train Loss: 1.5375, Val Loss: 1.5954, Best Val Loss: 1.5954\n",
      "Epoch 39/1000, Train Loss: 1.5397, Val Loss: 1.5586, Best Val Loss: 1.5586\n",
      "Epoch 46/1000, Train Loss: 1.4985, Val Loss: 1.5441, Best Val Loss: 1.5441\n",
      "Epoch 51/1000, Train Loss: 1.4862, Val Loss: 1.5196, Best Val Loss: 1.5196\n",
      "Epoch 54/1000, Train Loss: 1.4800, Val Loss: 1.5095, Best Val Loss: 1.5095\n",
      "Epoch 63/1000, Train Loss: 1.4566, Val Loss: 1.4993, Best Val Loss: 1.4993\n",
      "Epoch 72/1000, Train Loss: 1.4368, Val Loss: 1.4867, Best Val Loss: 1.4867\n",
      "Epoch 86/1000, Train Loss: 1.4083, Val Loss: 1.4815, Best Val Loss: 1.4815\n",
      "Epoch 93/1000, Train Loss: 1.3930, Val Loss: 1.4799, Best Val Loss: 1.4799\n",
      "Epoch 105/1000, Train Loss: 1.3656, Val Loss: 1.4789, Best Val Loss: 1.4789\n",
      "Epoch 122/1000, Train Loss: 1.3333, Val Loss: 1.4695, Best Val Loss: 1.4695\n",
      "Early stopping at epoch 172, Best Val Loss: 1.4695\n",
      "Epistemic Variance: 0.945110\n",
      "Aleatoric Variance: 12.521072\n",
      " (1/n) Calculating accuracy metrics\n",
      " (2/n) Calculating average calibration metrics\n",
      " (3/n) Calculating adversarial group calibration metrics\n",
      "  [1/2] for mean absolute calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [2/2] for root mean squared calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (4/n) Calculating sharpness metrics\n",
      " (n/n) Calculating proper scoring rule metrics\n",
      "**Finished Calculating All Metrics**\n",
      "\n",
      "\n",
      "===================== Accuracy Metrics =====================\n",
      "  MAE           1.968\n",
      "  RMSE          2.774\n",
      "  MDAE          1.463\n",
      "  MARPD         1.719\n",
      "  R2            0.865\n",
      "  Correlation   0.931\n",
      "=============== Average Calibration Metrics ================\n",
      "  Root-mean-squared Calibration Error   0.028\n",
      "  Mean-absolute Calibration Error       0.025\n",
      "  Miscalibration Area                   0.025\n",
      "========== Adversarial Group Calibration Metrics ===========\n",
      "  Mean-absolute Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.035\n",
      "     Group Size: 0.56 -- Calibration Error: 0.029\n",
      "     Group Size: 1.00 -- Calibration Error: 0.025\n",
      "  Root-mean-squared Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.039\n",
      "     Group Size: 0.56 -- Calibration Error: 0.031\n",
      "     Group Size: 1.00 -- Calibration Error: 0.028\n",
      "==================== Sharpness Metrics =====================\n",
      "  Sharpness   3.670\n",
      "=================== Scoring Rule Metrics ===================\n",
      "  Negative-log-likelihood   2.289\n",
      "  CRPS                      1.424\n",
      "  Check Score               0.719\n",
      "  Interval Score            7.181\n",
      "{'accuracy': {'mae': 1.9676792836238646, 'rmse': np.float64(2.773567785734614), 'mdae': 1.4627147094726496, 'marpd': np.float64(1.7185099377019313), 'r2': 0.8652801027896064, 'corr': np.float64(0.9306695091136319)}, 'avg_calibration': {'rms_cal': np.float64(0.02780828360860038), 'ma_cal': np.float64(0.02499123698777641), 'miscal_area': np.float64(0.02523749543941734)}, 'adv_group_calibration': {'ma_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.34844444, 0.03539358, 0.03304696, 0.03232788, 0.0296994 ,\n",
      "       0.02891188, 0.02793847, 0.02747195, 0.02687606, 0.02499124]), 'adv_group_cali_stderr': array([0.04767901, 0.00314161, 0.00279926, 0.00207692, 0.00170819,\n",
      "       0.00157316, 0.00102544, 0.00093234, 0.0006677 , 0.        ])}, 'rms_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.41463673, 0.03900413, 0.03656138, 0.0345026 , 0.03312302,\n",
      "       0.03130553, 0.03145238, 0.03002402, 0.02943856, 0.02780828]), 'adv_group_cali_stderr': array([0.0702711 , 0.00335498, 0.0020204 , 0.00269697, 0.00206363,\n",
      "       0.00172595, 0.00055567, 0.00055192, 0.00061252, 0.        ])}}, 'sharpness': {'sharp': np.float32(3.66963)}, 'scoring_rule': {'nll': np.float64(2.2885620125794), 'crps': np.float64(1.4242802756825077), 'check': np.float64(0.7191308256532791), 'interval': np.float64(7.18081122878677)}}\n",
      "coverage: 0.9508795539748149, MPIW: 10.326637509591155\n",
      "Run 6 with seed 8888\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 130.9563, Val Loss: 5.3921, Best Val Loss: 5.3921\n",
      "Epoch 2/1000, Train Loss: 5.3172, Val Loss: 5.2745, Best Val Loss: 5.2745\n",
      "Epoch 3/1000, Train Loss: 5.2490, Val Loss: 5.2304, Best Val Loss: 5.2304\n",
      "Epoch 4/1000, Train Loss: 5.2070, Val Loss: 5.1834, Best Val Loss: 5.1834\n",
      "Epoch 5/1000, Train Loss: 5.1395, Val Loss: 5.0758, Best Val Loss: 5.0758\n",
      "Epoch 6/1000, Train Loss: 4.6667, Val Loss: 3.6272, Best Val Loss: 3.6272\n",
      "Epoch 7/1000, Train Loss: 2.8213, Val Loss: 2.4416, Best Val Loss: 2.4416\n",
      "Epoch 8/1000, Train Loss: 2.2597, Val Loss: 2.1655, Best Val Loss: 2.1655\n",
      "Epoch 9/1000, Train Loss: 2.0632, Val Loss: 1.9960, Best Val Loss: 1.9960\n",
      "Epoch 10/1000, Train Loss: 1.9467, Val Loss: 1.9075, Best Val Loss: 1.9075\n",
      "Epoch 11/1000, Train Loss: 1.8778, Val Loss: 1.8486, Best Val Loss: 1.8486\n",
      "Epoch 13/1000, Train Loss: 1.7924, Val Loss: 1.8032, Best Val Loss: 1.8032\n",
      "Epoch 14/1000, Train Loss: 1.7779, Val Loss: 1.7778, Best Val Loss: 1.7778\n",
      "Epoch 16/1000, Train Loss: 1.7334, Val Loss: 1.7396, Best Val Loss: 1.7396\n",
      "Epoch 17/1000, Train Loss: 1.7080, Val Loss: 1.7125, Best Val Loss: 1.7125\n",
      "Epoch 19/1000, Train Loss: 1.6872, Val Loss: 1.7089, Best Val Loss: 1.7089\n",
      "Epoch 20/1000, Train Loss: 1.6736, Val Loss: 1.6545, Best Val Loss: 1.6545\n",
      "Epoch 21/1000, Train Loss: 1.6644, Val Loss: 1.6420, Best Val Loss: 1.6420\n",
      "Epoch 24/1000, Train Loss: 1.6418, Val Loss: 1.6372, Best Val Loss: 1.6372\n",
      "Epoch 26/1000, Train Loss: 1.6211, Val Loss: 1.6241, Best Val Loss: 1.6241\n",
      "Epoch 27/1000, Train Loss: 1.6113, Val Loss: 1.6206, Best Val Loss: 1.6206\n",
      "Epoch 30/1000, Train Loss: 1.5866, Val Loss: 1.6004, Best Val Loss: 1.6004\n",
      "Epoch 33/1000, Train Loss: 1.5666, Val Loss: 1.5927, Best Val Loss: 1.5927\n",
      "Epoch 35/1000, Train Loss: 1.5499, Val Loss: 1.5784, Best Val Loss: 1.5784\n",
      "Epoch 36/1000, Train Loss: 1.5454, Val Loss: 1.5682, Best Val Loss: 1.5682\n",
      "Epoch 37/1000, Train Loss: 1.5457, Val Loss: 1.5637, Best Val Loss: 1.5637\n",
      "Epoch 39/1000, Train Loss: 1.5217, Val Loss: 1.5487, Best Val Loss: 1.5487\n",
      "Epoch 45/1000, Train Loss: 1.4936, Val Loss: 1.5296, Best Val Loss: 1.5296\n",
      "Epoch 48/1000, Train Loss: 1.4795, Val Loss: 1.5264, Best Val Loss: 1.5264\n",
      "Epoch 52/1000, Train Loss: 1.4651, Val Loss: 1.5112, Best Val Loss: 1.5112\n",
      "Epoch 54/1000, Train Loss: 1.4545, Val Loss: 1.5049, Best Val Loss: 1.5049\n",
      "Epoch 59/1000, Train Loss: 1.4429, Val Loss: 1.4953, Best Val Loss: 1.4953\n",
      "Epoch 62/1000, Train Loss: 1.4340, Val Loss: 1.4939, Best Val Loss: 1.4939\n",
      "Epoch 70/1000, Train Loss: 1.4120, Val Loss: 1.4867, Best Val Loss: 1.4867\n",
      "Epoch 73/1000, Train Loss: 1.4089, Val Loss: 1.4694, Best Val Loss: 1.4694\n",
      "Epoch 98/1000, Train Loss: 1.3532, Val Loss: 1.4583, Best Val Loss: 1.4583\n",
      "Early stopping at epoch 148, Best Val Loss: 1.4583\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 121.9328, Val Loss: 5.5523, Best Val Loss: 5.5523\n",
      "Epoch 2/1000, Train Loss: 5.4669, Val Loss: 5.3833, Best Val Loss: 5.3833\n",
      "Epoch 3/1000, Train Loss: 5.3293, Val Loss: 5.2783, Best Val Loss: 5.2783\n",
      "Epoch 4/1000, Train Loss: 5.2535, Val Loss: 5.2298, Best Val Loss: 5.2298\n",
      "Epoch 5/1000, Train Loss: 5.2051, Val Loss: 5.1810, Best Val Loss: 5.1810\n",
      "Epoch 6/1000, Train Loss: 5.1404, Val Loss: 5.0834, Best Val Loss: 5.0834\n",
      "Epoch 7/1000, Train Loss: 4.6444, Val Loss: 3.1329, Best Val Loss: 3.1329\n",
      "Epoch 8/1000, Train Loss: 2.5378, Val Loss: 2.2402, Best Val Loss: 2.2402\n",
      "Epoch 9/1000, Train Loss: 2.1238, Val Loss: 2.0480, Best Val Loss: 2.0480\n",
      "Epoch 10/1000, Train Loss: 1.9814, Val Loss: 1.9512, Best Val Loss: 1.9512\n",
      "Epoch 11/1000, Train Loss: 1.8984, Val Loss: 1.8825, Best Val Loss: 1.8825\n",
      "Epoch 12/1000, Train Loss: 1.8493, Val Loss: 1.8323, Best Val Loss: 1.8323\n",
      "Epoch 13/1000, Train Loss: 1.8140, Val Loss: 1.8135, Best Val Loss: 1.8135\n",
      "Epoch 15/1000, Train Loss: 1.7608, Val Loss: 1.8091, Best Val Loss: 1.8091\n",
      "Epoch 16/1000, Train Loss: 1.7413, Val Loss: 1.7721, Best Val Loss: 1.7721\n",
      "Epoch 17/1000, Train Loss: 1.7338, Val Loss: 1.7257, Best Val Loss: 1.7257\n",
      "Epoch 19/1000, Train Loss: 1.7002, Val Loss: 1.7123, Best Val Loss: 1.7123\n",
      "Epoch 20/1000, Train Loss: 1.6850, Val Loss: 1.6972, Best Val Loss: 1.6972\n",
      "Epoch 22/1000, Train Loss: 1.6645, Val Loss: 1.6620, Best Val Loss: 1.6620\n",
      "Epoch 23/1000, Train Loss: 1.6510, Val Loss: 1.6516, Best Val Loss: 1.6516\n",
      "Epoch 24/1000, Train Loss: 1.6501, Val Loss: 1.6323, Best Val Loss: 1.6323\n",
      "Epoch 31/1000, Train Loss: 1.5969, Val Loss: 1.6089, Best Val Loss: 1.6089\n",
      "Epoch 32/1000, Train Loss: 1.5810, Val Loss: 1.5782, Best Val Loss: 1.5782\n",
      "Epoch 38/1000, Train Loss: 1.5423, Val Loss: 1.5665, Best Val Loss: 1.5665\n",
      "Epoch 39/1000, Train Loss: 1.5408, Val Loss: 1.5571, Best Val Loss: 1.5571\n",
      "Epoch 48/1000, Train Loss: 1.4931, Val Loss: 1.5428, Best Val Loss: 1.5428\n",
      "Epoch 49/1000, Train Loss: 1.4943, Val Loss: 1.5380, Best Val Loss: 1.5380\n",
      "Epoch 50/1000, Train Loss: 1.4961, Val Loss: 1.5277, Best Val Loss: 1.5277\n",
      "Epoch 51/1000, Train Loss: 1.4818, Val Loss: 1.5221, Best Val Loss: 1.5221\n",
      "Epoch 56/1000, Train Loss: 1.4701, Val Loss: 1.5057, Best Val Loss: 1.5057\n",
      "Epoch 63/1000, Train Loss: 1.4452, Val Loss: 1.5025, Best Val Loss: 1.5025\n",
      "Epoch 66/1000, Train Loss: 1.4429, Val Loss: 1.4939, Best Val Loss: 1.4939\n",
      "Epoch 67/1000, Train Loss: 1.4330, Val Loss: 1.4827, Best Val Loss: 1.4827\n",
      "Epoch 77/1000, Train Loss: 1.4156, Val Loss: 1.4689, Best Val Loss: 1.4689\n",
      "Epoch 90/1000, Train Loss: 1.3849, Val Loss: 1.4538, Best Val Loss: 1.4538\n",
      "Early stopping at epoch 140, Best Val Loss: 1.4538\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 137.8711, Val Loss: 5.4876, Best Val Loss: 5.4876\n",
      "Epoch 2/1000, Train Loss: 5.4447, Val Loss: 5.3947, Best Val Loss: 5.3947\n",
      "Epoch 3/1000, Train Loss: 5.3567, Val Loss: 5.3021, Best Val Loss: 5.3021\n",
      "Epoch 4/1000, Train Loss: 5.2270, Val Loss: 5.1138, Best Val Loss: 5.1138\n",
      "Epoch 5/1000, Train Loss: 4.5396, Val Loss: 2.6069, Best Val Loss: 2.6069\n",
      "Epoch 6/1000, Train Loss: 2.4074, Val Loss: 2.2747, Best Val Loss: 2.2747\n",
      "Epoch 7/1000, Train Loss: 2.1686, Val Loss: 2.0968, Best Val Loss: 2.0968\n",
      "Epoch 8/1000, Train Loss: 2.0197, Val Loss: 1.9631, Best Val Loss: 1.9631\n",
      "Epoch 9/1000, Train Loss: 1.9215, Val Loss: 1.8950, Best Val Loss: 1.8950\n",
      "Epoch 10/1000, Train Loss: 1.8567, Val Loss: 1.8647, Best Val Loss: 1.8647\n",
      "Epoch 11/1000, Train Loss: 1.8205, Val Loss: 1.8220, Best Val Loss: 1.8220\n",
      "Epoch 12/1000, Train Loss: 1.7794, Val Loss: 1.8046, Best Val Loss: 1.8046\n",
      "Epoch 14/1000, Train Loss: 1.7446, Val Loss: 1.7724, Best Val Loss: 1.7724\n",
      "Epoch 15/1000, Train Loss: 1.7194, Val Loss: 1.7349, Best Val Loss: 1.7349\n",
      "Epoch 16/1000, Train Loss: 1.7096, Val Loss: 1.7203, Best Val Loss: 1.7203\n",
      "Epoch 17/1000, Train Loss: 1.6972, Val Loss: 1.7059, Best Val Loss: 1.7059\n",
      "Epoch 18/1000, Train Loss: 1.6859, Val Loss: 1.6805, Best Val Loss: 1.6805\n",
      "Epoch 23/1000, Train Loss: 1.6471, Val Loss: 1.6504, Best Val Loss: 1.6504\n",
      "Epoch 24/1000, Train Loss: 1.6352, Val Loss: 1.6490, Best Val Loss: 1.6490\n",
      "Epoch 25/1000, Train Loss: 1.6424, Val Loss: 1.6442, Best Val Loss: 1.6442\n",
      "Epoch 26/1000, Train Loss: 1.6229, Val Loss: 1.6336, Best Val Loss: 1.6336\n",
      "Epoch 28/1000, Train Loss: 1.6091, Val Loss: 1.6127, Best Val Loss: 1.6127\n",
      "Epoch 29/1000, Train Loss: 1.6081, Val Loss: 1.6118, Best Val Loss: 1.6118\n",
      "Epoch 31/1000, Train Loss: 1.5910, Val Loss: 1.5955, Best Val Loss: 1.5955\n",
      "Epoch 36/1000, Train Loss: 1.5729, Val Loss: 1.5919, Best Val Loss: 1.5919\n",
      "Epoch 37/1000, Train Loss: 1.5691, Val Loss: 1.5717, Best Val Loss: 1.5717\n",
      "Epoch 45/1000, Train Loss: 1.5359, Val Loss: 1.5477, Best Val Loss: 1.5477\n",
      "Epoch 47/1000, Train Loss: 1.5271, Val Loss: 1.5385, Best Val Loss: 1.5385\n",
      "Epoch 50/1000, Train Loss: 1.5117, Val Loss: 1.5206, Best Val Loss: 1.5206\n",
      "Epoch 67/1000, Train Loss: 1.4687, Val Loss: 1.5159, Best Val Loss: 1.5159\n",
      "Epoch 69/1000, Train Loss: 1.4690, Val Loss: 1.5003, Best Val Loss: 1.5003\n",
      "Epoch 75/1000, Train Loss: 1.4486, Val Loss: 1.4857, Best Val Loss: 1.4857\n",
      "Epoch 80/1000, Train Loss: 1.4356, Val Loss: 1.4787, Best Val Loss: 1.4787\n",
      "Epoch 84/1000, Train Loss: 1.4249, Val Loss: 1.4748, Best Val Loss: 1.4748\n",
      "Epoch 101/1000, Train Loss: 1.3993, Val Loss: 1.4677, Best Val Loss: 1.4677\n",
      "Early stopping at epoch 151, Best Val Loss: 1.4677\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 129.1054, Val Loss: 5.4260, Best Val Loss: 5.4260\n",
      "Epoch 2/1000, Train Loss: 5.3810, Val Loss: 5.3378, Best Val Loss: 5.3378\n",
      "Epoch 3/1000, Train Loss: 5.3079, Val Loss: 5.2741, Best Val Loss: 5.2741\n",
      "Epoch 4/1000, Train Loss: 5.2514, Val Loss: 5.2299, Best Val Loss: 5.2299\n",
      "Epoch 5/1000, Train Loss: 5.2106, Val Loss: 5.1916, Best Val Loss: 5.1916\n",
      "Epoch 6/1000, Train Loss: 5.1692, Val Loss: 5.1464, Best Val Loss: 5.1464\n",
      "Epoch 7/1000, Train Loss: 5.1095, Val Loss: 5.0589, Best Val Loss: 5.0589\n",
      "Epoch 8/1000, Train Loss: 4.0899, Val Loss: 2.2137, Best Val Loss: 2.2137\n",
      "Epoch 9/1000, Train Loss: 2.0650, Val Loss: 2.0064, Best Val Loss: 2.0064\n",
      "Epoch 10/1000, Train Loss: 1.9241, Val Loss: 1.9232, Best Val Loss: 1.9232\n",
      "Epoch 11/1000, Train Loss: 1.8530, Val Loss: 1.8588, Best Val Loss: 1.8588\n",
      "Epoch 12/1000, Train Loss: 1.8065, Val Loss: 1.8130, Best Val Loss: 1.8130\n",
      "Epoch 14/1000, Train Loss: 1.7515, Val Loss: 1.7608, Best Val Loss: 1.7608\n",
      "Epoch 15/1000, Train Loss: 1.7335, Val Loss: 1.7498, Best Val Loss: 1.7498\n",
      "Epoch 16/1000, Train Loss: 1.7278, Val Loss: 1.7214, Best Val Loss: 1.7214\n",
      "Epoch 19/1000, Train Loss: 1.6914, Val Loss: 1.6831, Best Val Loss: 1.6831\n",
      "Epoch 21/1000, Train Loss: 1.6576, Val Loss: 1.6542, Best Val Loss: 1.6542\n",
      "Epoch 23/1000, Train Loss: 1.6427, Val Loss: 1.6403, Best Val Loss: 1.6403\n",
      "Epoch 27/1000, Train Loss: 1.6172, Val Loss: 1.6166, Best Val Loss: 1.6166\n",
      "Epoch 29/1000, Train Loss: 1.5956, Val Loss: 1.5940, Best Val Loss: 1.5940\n",
      "Epoch 34/1000, Train Loss: 1.5571, Val Loss: 1.5862, Best Val Loss: 1.5862\n",
      "Epoch 35/1000, Train Loss: 1.5557, Val Loss: 1.5625, Best Val Loss: 1.5625\n",
      "Epoch 47/1000, Train Loss: 1.5047, Val Loss: 1.5446, Best Val Loss: 1.5446\n",
      "Epoch 49/1000, Train Loss: 1.4917, Val Loss: 1.5444, Best Val Loss: 1.5444\n",
      "Epoch 52/1000, Train Loss: 1.4766, Val Loss: 1.5440, Best Val Loss: 1.5440\n",
      "Epoch 53/1000, Train Loss: 1.4820, Val Loss: 1.5272, Best Val Loss: 1.5272\n",
      "Epoch 54/1000, Train Loss: 1.4708, Val Loss: 1.5175, Best Val Loss: 1.5175\n",
      "Epoch 59/1000, Train Loss: 1.4632, Val Loss: 1.5163, Best Val Loss: 1.5163\n",
      "Epoch 65/1000, Train Loss: 1.4477, Val Loss: 1.4986, Best Val Loss: 1.4986\n",
      "Epoch 70/1000, Train Loss: 1.4265, Val Loss: 1.4906, Best Val Loss: 1.4906\n",
      "Epoch 91/1000, Train Loss: 1.3852, Val Loss: 1.4679, Best Val Loss: 1.4679\n",
      "Early stopping at epoch 141, Best Val Loss: 1.4679\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 143.9459, Val Loss: 5.5488, Best Val Loss: 5.5488\n",
      "Epoch 2/1000, Train Loss: 5.4986, Val Loss: 5.4424, Best Val Loss: 5.4424\n",
      "Epoch 3/1000, Train Loss: 5.4105, Val Loss: 5.3685, Best Val Loss: 5.3685\n",
      "Epoch 4/1000, Train Loss: 5.3378, Val Loss: 5.3007, Best Val Loss: 5.3007\n",
      "Epoch 5/1000, Train Loss: 5.2681, Val Loss: 5.2329, Best Val Loss: 5.2329\n",
      "Epoch 6/1000, Train Loss: 5.1850, Val Loss: 5.1184, Best Val Loss: 5.1184\n",
      "Epoch 7/1000, Train Loss: 4.4237, Val Loss: 2.5921, Best Val Loss: 2.5921\n",
      "Epoch 8/1000, Train Loss: 2.3290, Val Loss: 2.1888, Best Val Loss: 2.1888\n",
      "Epoch 9/1000, Train Loss: 2.0934, Val Loss: 2.0539, Best Val Loss: 2.0539\n",
      "Epoch 10/1000, Train Loss: 1.9712, Val Loss: 1.9312, Best Val Loss: 1.9312\n",
      "Epoch 11/1000, Train Loss: 1.8915, Val Loss: 1.8758, Best Val Loss: 1.8758\n",
      "Epoch 12/1000, Train Loss: 1.8462, Val Loss: 1.8244, Best Val Loss: 1.8244\n",
      "Epoch 13/1000, Train Loss: 1.8099, Val Loss: 1.8218, Best Val Loss: 1.8218\n",
      "Epoch 14/1000, Train Loss: 1.7835, Val Loss: 1.8049, Best Val Loss: 1.8049\n",
      "Epoch 15/1000, Train Loss: 1.7635, Val Loss: 1.7649, Best Val Loss: 1.7649\n",
      "Epoch 16/1000, Train Loss: 1.7410, Val Loss: 1.7649, Best Val Loss: 1.7649\n",
      "Epoch 17/1000, Train Loss: 1.7270, Val Loss: 1.7171, Best Val Loss: 1.7171\n",
      "Epoch 20/1000, Train Loss: 1.7036, Val Loss: 1.6858, Best Val Loss: 1.6858\n",
      "Epoch 21/1000, Train Loss: 1.6941, Val Loss: 1.6829, Best Val Loss: 1.6829\n",
      "Epoch 22/1000, Train Loss: 1.6648, Val Loss: 1.6481, Best Val Loss: 1.6481\n",
      "Epoch 28/1000, Train Loss: 1.6258, Val Loss: 1.6124, Best Val Loss: 1.6124\n",
      "Epoch 31/1000, Train Loss: 1.6014, Val Loss: 1.6018, Best Val Loss: 1.6018\n",
      "Epoch 34/1000, Train Loss: 1.5741, Val Loss: 1.5770, Best Val Loss: 1.5770\n",
      "Epoch 43/1000, Train Loss: 1.5280, Val Loss: 1.5737, Best Val Loss: 1.5737\n",
      "Epoch 45/1000, Train Loss: 1.5250, Val Loss: 1.5623, Best Val Loss: 1.5623\n",
      "Epoch 48/1000, Train Loss: 1.5115, Val Loss: 1.5429, Best Val Loss: 1.5429\n",
      "Epoch 60/1000, Train Loss: 1.4688, Val Loss: 1.5378, Best Val Loss: 1.5378\n",
      "Epoch 61/1000, Train Loss: 1.4700, Val Loss: 1.5270, Best Val Loss: 1.5270\n",
      "Epoch 64/1000, Train Loss: 1.4544, Val Loss: 1.5001, Best Val Loss: 1.5001\n",
      "Epoch 75/1000, Train Loss: 1.4360, Val Loss: 1.5001, Best Val Loss: 1.5001\n",
      "Epoch 80/1000, Train Loss: 1.4228, Val Loss: 1.4930, Best Val Loss: 1.4930\n",
      "Epoch 81/1000, Train Loss: 1.4244, Val Loss: 1.4743, Best Val Loss: 1.4743\n",
      "Epoch 90/1000, Train Loss: 1.3987, Val Loss: 1.4740, Best Val Loss: 1.4740\n",
      "Epoch 99/1000, Train Loss: 1.3873, Val Loss: 1.4739, Best Val Loss: 1.4739\n",
      "Epoch 106/1000, Train Loss: 1.3772, Val Loss: 1.4733, Best Val Loss: 1.4733\n",
      "Early stopping at epoch 156, Best Val Loss: 1.4733\n",
      "Epistemic Variance: 1.046975\n",
      "Aleatoric Variance: 8.330327\n",
      " (1/n) Calculating accuracy metrics\n",
      " (2/n) Calculating average calibration metrics\n",
      " (3/n) Calculating adversarial group calibration metrics\n",
      "  [1/2] for mean absolute calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [2/2] for root mean squared calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (4/n) Calculating sharpness metrics\n",
      " (n/n) Calculating proper scoring rule metrics\n",
      "**Finished Calculating All Metrics**\n",
      "\n",
      "\n",
      "===================== Accuracy Metrics =====================\n",
      "  MAE           1.989\n",
      "  RMSE          2.786\n",
      "  MDAE          1.473\n",
      "  MARPD         1.736\n",
      "  R2            0.864\n",
      "  Correlation   0.930\n",
      "=============== Average Calibration Metrics ================\n",
      "  Root-mean-squared Calibration Error   0.039\n",
      "  Mean-absolute Calibration Error       0.034\n",
      "  Miscalibration Area                   0.035\n",
      "========== Adversarial Group Calibration Metrics ===========\n",
      "  Mean-absolute Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.047\n",
      "     Group Size: 0.56 -- Calibration Error: 0.038\n",
      "     Group Size: 1.00 -- Calibration Error: 0.034\n",
      "  Root-mean-squared Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.051\n",
      "     Group Size: 0.56 -- Calibration Error: 0.043\n",
      "     Group Size: 1.00 -- Calibration Error: 0.039\n",
      "==================== Sharpness Metrics =====================\n",
      "  Sharpness   3.062\n",
      "=================== Scoring Rule Metrics ===================\n",
      "  Negative-log-likelihood   2.291\n",
      "  CRPS                      1.424\n",
      "  Check Score               0.719\n",
      "  Interval Score            7.138\n",
      "{'accuracy': {'mae': 1.9887849853722148, 'rmse': np.float64(2.7856598516269733), 'mdae': 1.4726665283203175, 'marpd': np.float64(1.7362085949570398), 'r2': 0.864102851603441, 'corr': np.float64(0.9299197517497786)}, 'avg_calibration': {'rms_cal': np.float64(0.039199323337588646), 'ma_cal': np.float64(0.034438948749243824), 'miscal_area': np.float64(0.034780794527152596)}, 'adv_group_calibration': {'ma_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.372     , 0.04672286, 0.04229955, 0.04033566, 0.0397087 ,\n",
      "       0.03753159, 0.03677531, 0.03704518, 0.03586168, 0.03443895]), 'adv_group_cali_stderr': array([6.07719307e-02, 4.56522268e-03, 3.39528173e-03, 2.61546894e-03,\n",
      "       2.01198367e-03, 1.33043666e-03, 8.45798741e-04, 8.65613338e-04,\n",
      "       4.43836227e-04, 7.31423639e-18])}, 'rms_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.42595252, 0.05109502, 0.04740434, 0.04555205, 0.04323545,\n",
      "       0.04309516, 0.04191612, 0.04136559, 0.04080661, 0.03919932]), 'adv_group_cali_stderr': array([0.09682369, 0.00640968, 0.00180529, 0.00208276, 0.00226645,\n",
      "       0.00168938, 0.00097766, 0.0008678 , 0.00046597, 0.        ])}}, 'sharpness': {'sharp': np.float32(3.062238)}, 'scoring_rule': {'nll': np.float64(2.291441464938911), 'crps': np.float64(1.4238628354623886), 'check': np.float64(0.7189421667238983), 'interval': np.float64(7.137835663359023)}}\n",
      "coverage: 0.9598192828991637, MPIW: 10.735786063378074\n",
      "Run 7 with seed 9876\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 136.0894, Val Loss: 5.3993, Best Val Loss: 5.3993\n",
      "Epoch 2/1000, Train Loss: 5.2945, Val Loss: 5.2397, Best Val Loss: 5.2397\n",
      "Epoch 3/1000, Train Loss: 5.2019, Val Loss: 5.1625, Best Val Loss: 5.1625\n",
      "Epoch 4/1000, Train Loss: 5.0778, Val Loss: 4.9039, Best Val Loss: 4.9039\n",
      "Epoch 5/1000, Train Loss: 3.6410, Val Loss: 2.8047, Best Val Loss: 2.8047\n",
      "Epoch 6/1000, Train Loss: 2.5437, Val Loss: 2.3333, Best Val Loss: 2.3333\n",
      "Epoch 7/1000, Train Loss: 2.2099, Val Loss: 2.1288, Best Val Loss: 2.1288\n",
      "Epoch 8/1000, Train Loss: 2.0483, Val Loss: 2.0200, Best Val Loss: 2.0200\n",
      "Epoch 9/1000, Train Loss: 1.9501, Val Loss: 1.9537, Best Val Loss: 1.9537\n",
      "Epoch 10/1000, Train Loss: 1.8939, Val Loss: 1.9033, Best Val Loss: 1.9033\n",
      "Epoch 11/1000, Train Loss: 1.8465, Val Loss: 1.8470, Best Val Loss: 1.8470\n",
      "Epoch 12/1000, Train Loss: 1.8158, Val Loss: 1.8103, Best Val Loss: 1.8103\n",
      "Epoch 13/1000, Train Loss: 1.7845, Val Loss: 1.7844, Best Val Loss: 1.7844\n",
      "Epoch 15/1000, Train Loss: 1.7408, Val Loss: 1.7541, Best Val Loss: 1.7541\n",
      "Epoch 16/1000, Train Loss: 1.7309, Val Loss: 1.7240, Best Val Loss: 1.7240\n",
      "Epoch 17/1000, Train Loss: 1.7146, Val Loss: 1.7108, Best Val Loss: 1.7108\n",
      "Epoch 22/1000, Train Loss: 1.6570, Val Loss: 1.6541, Best Val Loss: 1.6541\n",
      "Epoch 26/1000, Train Loss: 1.6398, Val Loss: 1.6412, Best Val Loss: 1.6412\n",
      "Epoch 29/1000, Train Loss: 1.6067, Val Loss: 1.6403, Best Val Loss: 1.6403\n",
      "Epoch 30/1000, Train Loss: 1.6268, Val Loss: 1.6365, Best Val Loss: 1.6365\n",
      "Epoch 31/1000, Train Loss: 1.5926, Val Loss: 1.6239, Best Val Loss: 1.6239\n",
      "Epoch 33/1000, Train Loss: 1.5896, Val Loss: 1.6050, Best Val Loss: 1.6050\n",
      "Epoch 38/1000, Train Loss: 1.5552, Val Loss: 1.5578, Best Val Loss: 1.5578\n",
      "Epoch 48/1000, Train Loss: 1.5094, Val Loss: 1.5498, Best Val Loss: 1.5498\n",
      "Epoch 49/1000, Train Loss: 1.5082, Val Loss: 1.5453, Best Val Loss: 1.5453\n",
      "Epoch 51/1000, Train Loss: 1.5103, Val Loss: 1.5280, Best Val Loss: 1.5280\n",
      "Epoch 59/1000, Train Loss: 1.4844, Val Loss: 1.5199, Best Val Loss: 1.5199\n",
      "Epoch 62/1000, Train Loss: 1.4720, Val Loss: 1.5183, Best Val Loss: 1.5183\n",
      "Epoch 64/1000, Train Loss: 1.4644, Val Loss: 1.5022, Best Val Loss: 1.5022\n",
      "Epoch 65/1000, Train Loss: 1.4654, Val Loss: 1.5006, Best Val Loss: 1.5006\n",
      "Epoch 77/1000, Train Loss: 1.4398, Val Loss: 1.4877, Best Val Loss: 1.4877\n",
      "Epoch 88/1000, Train Loss: 1.4130, Val Loss: 1.4601, Best Val Loss: 1.4601\n",
      "Epoch 106/1000, Train Loss: 1.3814, Val Loss: 1.4536, Best Val Loss: 1.4536\n",
      "Early stopping at epoch 156, Best Val Loss: 1.4536\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 139.8915, Val Loss: 5.5170, Best Val Loss: 5.5170\n",
      "Epoch 2/1000, Train Loss: 5.4768, Val Loss: 5.4337, Best Val Loss: 5.4337\n",
      "Epoch 3/1000, Train Loss: 5.3975, Val Loss: 5.3556, Best Val Loss: 5.3556\n",
      "Epoch 4/1000, Train Loss: 5.3196, Val Loss: 5.2813, Best Val Loss: 5.2813\n",
      "Epoch 5/1000, Train Loss: 5.2453, Val Loss: 5.2091, Best Val Loss: 5.2091\n",
      "Epoch 6/1000, Train Loss: 5.1712, Val Loss: 5.1289, Best Val Loss: 5.1289\n",
      "Epoch 7/1000, Train Loss: 5.0576, Val Loss: 4.9383, Best Val Loss: 4.9383\n",
      "Epoch 8/1000, Train Loss: 3.2347, Val Loss: 2.2289, Best Val Loss: 2.2289\n",
      "Epoch 9/1000, Train Loss: 2.0982, Val Loss: 2.0327, Best Val Loss: 2.0327\n",
      "Epoch 10/1000, Train Loss: 1.9666, Val Loss: 1.9180, Best Val Loss: 1.9180\n",
      "Epoch 11/1000, Train Loss: 1.8835, Val Loss: 1.8495, Best Val Loss: 1.8495\n",
      "Epoch 13/1000, Train Loss: 1.7989, Val Loss: 1.8024, Best Val Loss: 1.8024\n",
      "Epoch 14/1000, Train Loss: 1.7697, Val Loss: 1.7754, Best Val Loss: 1.7754\n",
      "Epoch 16/1000, Train Loss: 1.7326, Val Loss: 1.7323, Best Val Loss: 1.7323\n",
      "Epoch 17/1000, Train Loss: 1.7233, Val Loss: 1.7276, Best Val Loss: 1.7276\n",
      "Epoch 19/1000, Train Loss: 1.7000, Val Loss: 1.6945, Best Val Loss: 1.6945\n",
      "Epoch 22/1000, Train Loss: 1.6700, Val Loss: 1.6843, Best Val Loss: 1.6843\n",
      "Epoch 25/1000, Train Loss: 1.6361, Val Loss: 1.6522, Best Val Loss: 1.6522\n",
      "Epoch 27/1000, Train Loss: 1.6322, Val Loss: 1.6368, Best Val Loss: 1.6368\n",
      "Epoch 29/1000, Train Loss: 1.6031, Val Loss: 1.5957, Best Val Loss: 1.5957\n",
      "Epoch 30/1000, Train Loss: 1.5993, Val Loss: 1.5881, Best Val Loss: 1.5881\n",
      "Epoch 34/1000, Train Loss: 1.5691, Val Loss: 1.5747, Best Val Loss: 1.5747\n",
      "Epoch 41/1000, Train Loss: 1.5308, Val Loss: 1.5607, Best Val Loss: 1.5607\n",
      "Epoch 42/1000, Train Loss: 1.5243, Val Loss: 1.5402, Best Val Loss: 1.5402\n",
      "Epoch 46/1000, Train Loss: 1.5057, Val Loss: 1.5332, Best Val Loss: 1.5332\n",
      "Epoch 48/1000, Train Loss: 1.5019, Val Loss: 1.5174, Best Val Loss: 1.5174\n",
      "Epoch 58/1000, Train Loss: 1.4738, Val Loss: 1.5137, Best Val Loss: 1.5137\n",
      "Epoch 64/1000, Train Loss: 1.4525, Val Loss: 1.5016, Best Val Loss: 1.5016\n",
      "Epoch 66/1000, Train Loss: 1.4507, Val Loss: 1.4826, Best Val Loss: 1.4826\n",
      "Epoch 80/1000, Train Loss: 1.4084, Val Loss: 1.4679, Best Val Loss: 1.4679\n",
      "Epoch 120/1000, Train Loss: 1.3385, Val Loss: 1.4630, Best Val Loss: 1.4630\n",
      "Early stopping at epoch 170, Best Val Loss: 1.4630\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 135.7790, Val Loss: 5.5394, Best Val Loss: 5.5394\n",
      "Epoch 2/1000, Train Loss: 5.4544, Val Loss: 5.3730, Best Val Loss: 5.3730\n",
      "Epoch 3/1000, Train Loss: 5.3297, Val Loss: 5.2918, Best Val Loss: 5.2918\n",
      "Epoch 4/1000, Train Loss: 5.2671, Val Loss: 5.2417, Best Val Loss: 5.2417\n",
      "Epoch 5/1000, Train Loss: 5.2183, Val Loss: 5.1922, Best Val Loss: 5.1922\n",
      "Epoch 6/1000, Train Loss: 5.1580, Val Loss: 5.1143, Best Val Loss: 5.1143\n",
      "Epoch 7/1000, Train Loss: 4.6695, Val Loss: 2.4105, Best Val Loss: 2.4105\n",
      "Epoch 8/1000, Train Loss: 2.1617, Val Loss: 2.0404, Best Val Loss: 2.0404\n",
      "Epoch 9/1000, Train Loss: 1.9641, Val Loss: 1.9397, Best Val Loss: 1.9397\n",
      "Epoch 10/1000, Train Loss: 1.8856, Val Loss: 1.8863, Best Val Loss: 1.8863\n",
      "Epoch 11/1000, Train Loss: 1.8236, Val Loss: 1.8299, Best Val Loss: 1.8299\n",
      "Epoch 12/1000, Train Loss: 1.7963, Val Loss: 1.7907, Best Val Loss: 1.7907\n",
      "Epoch 13/1000, Train Loss: 1.7543, Val Loss: 1.7622, Best Val Loss: 1.7622\n",
      "Epoch 15/1000, Train Loss: 1.7128, Val Loss: 1.7222, Best Val Loss: 1.7222\n",
      "Epoch 16/1000, Train Loss: 1.7074, Val Loss: 1.7181, Best Val Loss: 1.7181\n",
      "Epoch 17/1000, Train Loss: 1.6892, Val Loss: 1.6936, Best Val Loss: 1.6936\n",
      "Epoch 18/1000, Train Loss: 1.6818, Val Loss: 1.6692, Best Val Loss: 1.6692\n",
      "Epoch 20/1000, Train Loss: 1.6594, Val Loss: 1.6521, Best Val Loss: 1.6521\n",
      "Epoch 23/1000, Train Loss: 1.6316, Val Loss: 1.6456, Best Val Loss: 1.6456\n",
      "Epoch 30/1000, Train Loss: 1.5807, Val Loss: 1.5992, Best Val Loss: 1.5992\n",
      "Epoch 33/1000, Train Loss: 1.5642, Val Loss: 1.5793, Best Val Loss: 1.5793\n",
      "Epoch 34/1000, Train Loss: 1.5509, Val Loss: 1.5631, Best Val Loss: 1.5631\n",
      "Epoch 40/1000, Train Loss: 1.5315, Val Loss: 1.5547, Best Val Loss: 1.5547\n",
      "Epoch 43/1000, Train Loss: 1.5254, Val Loss: 1.5512, Best Val Loss: 1.5512\n",
      "Epoch 46/1000, Train Loss: 1.5050, Val Loss: 1.5451, Best Val Loss: 1.5451\n",
      "Epoch 49/1000, Train Loss: 1.4964, Val Loss: 1.5370, Best Val Loss: 1.5370\n",
      "Epoch 51/1000, Train Loss: 1.4893, Val Loss: 1.5310, Best Val Loss: 1.5310\n",
      "Epoch 53/1000, Train Loss: 1.4833, Val Loss: 1.5271, Best Val Loss: 1.5271\n",
      "Epoch 54/1000, Train Loss: 1.4831, Val Loss: 1.5192, Best Val Loss: 1.5192\n",
      "Epoch 56/1000, Train Loss: 1.4721, Val Loss: 1.5099, Best Val Loss: 1.5099\n",
      "Epoch 64/1000, Train Loss: 1.4586, Val Loss: 1.4933, Best Val Loss: 1.4933\n",
      "Epoch 66/1000, Train Loss: 1.4493, Val Loss: 1.4825, Best Val Loss: 1.4825\n",
      "Epoch 79/1000, Train Loss: 1.4087, Val Loss: 1.4798, Best Val Loss: 1.4798\n",
      "Epoch 88/1000, Train Loss: 1.3960, Val Loss: 1.4593, Best Val Loss: 1.4593\n",
      "Epoch 115/1000, Train Loss: 1.3465, Val Loss: 1.4542, Best Val Loss: 1.4542\n",
      "Early stopping at epoch 165, Best Val Loss: 1.4542\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 154.2416, Val Loss: 5.5701, Best Val Loss: 5.5701\n",
      "Epoch 2/1000, Train Loss: 5.4883, Val Loss: 5.4120, Best Val Loss: 5.4120\n",
      "Epoch 3/1000, Train Loss: 5.3446, Val Loss: 5.2431, Best Val Loss: 5.2431\n",
      "Epoch 4/1000, Train Loss: 4.9841, Val Loss: 4.3988, Best Val Loss: 4.3988\n",
      "Epoch 5/1000, Train Loss: 2.8749, Val Loss: 2.5235, Best Val Loss: 2.5235\n",
      "Epoch 6/1000, Train Loss: 2.3862, Val Loss: 2.2899, Best Val Loss: 2.2899\n",
      "Epoch 7/1000, Train Loss: 2.1863, Val Loss: 2.1215, Best Val Loss: 2.1215\n",
      "Epoch 8/1000, Train Loss: 2.0470, Val Loss: 2.0001, Best Val Loss: 2.0001\n",
      "Epoch 9/1000, Train Loss: 1.9547, Val Loss: 1.9385, Best Val Loss: 1.9385\n",
      "Epoch 10/1000, Train Loss: 1.8953, Val Loss: 1.9078, Best Val Loss: 1.9078\n",
      "Epoch 11/1000, Train Loss: 1.8544, Val Loss: 1.8593, Best Val Loss: 1.8593\n",
      "Epoch 12/1000, Train Loss: 1.8164, Val Loss: 1.8333, Best Val Loss: 1.8333\n",
      "Epoch 14/1000, Train Loss: 1.7677, Val Loss: 1.7668, Best Val Loss: 1.7668\n",
      "Epoch 15/1000, Train Loss: 1.7578, Val Loss: 1.7578, Best Val Loss: 1.7578\n",
      "Epoch 16/1000, Train Loss: 1.7367, Val Loss: 1.7265, Best Val Loss: 1.7265\n",
      "Epoch 19/1000, Train Loss: 1.7044, Val Loss: 1.7029, Best Val Loss: 1.7029\n",
      "Epoch 23/1000, Train Loss: 1.6707, Val Loss: 1.6652, Best Val Loss: 1.6652\n",
      "Epoch 25/1000, Train Loss: 1.6629, Val Loss: 1.6131, Best Val Loss: 1.6131\n",
      "Epoch 31/1000, Train Loss: 1.6107, Val Loss: 1.5971, Best Val Loss: 1.5971\n",
      "Epoch 35/1000, Train Loss: 1.5830, Val Loss: 1.5757, Best Val Loss: 1.5757\n",
      "Epoch 38/1000, Train Loss: 1.5737, Val Loss: 1.5728, Best Val Loss: 1.5728\n",
      "Epoch 40/1000, Train Loss: 1.5665, Val Loss: 1.5686, Best Val Loss: 1.5686\n",
      "Epoch 50/1000, Train Loss: 1.5242, Val Loss: 1.5506, Best Val Loss: 1.5506\n",
      "Epoch 51/1000, Train Loss: 1.5140, Val Loss: 1.5445, Best Val Loss: 1.5445\n",
      "Epoch 56/1000, Train Loss: 1.5215, Val Loss: 1.5389, Best Val Loss: 1.5389\n",
      "Epoch 60/1000, Train Loss: 1.4929, Val Loss: 1.5228, Best Val Loss: 1.5228\n",
      "Epoch 62/1000, Train Loss: 1.4905, Val Loss: 1.4739, Best Val Loss: 1.4739\n",
      "Epoch 101/1000, Train Loss: 1.4017, Val Loss: 1.4633, Best Val Loss: 1.4633\n",
      "Epoch 108/1000, Train Loss: 1.3877, Val Loss: 1.4616, Best Val Loss: 1.4616\n",
      "Epoch 135/1000, Train Loss: 1.3486, Val Loss: 1.4570, Best Val Loss: 1.4570\n",
      "Epoch 143/1000, Train Loss: 1.3407, Val Loss: 1.4537, Best Val Loss: 1.4537\n",
      "Early stopping at epoch 193, Best Val Loss: 1.4537\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 152.2323, Val Loss: 5.4664, Best Val Loss: 5.4664\n",
      "Epoch 2/1000, Train Loss: 5.4153, Val Loss: 5.3621, Best Val Loss: 5.3621\n",
      "Epoch 3/1000, Train Loss: 5.3275, Val Loss: 5.2895, Best Val Loss: 5.2895\n",
      "Epoch 4/1000, Train Loss: 5.2593, Val Loss: 5.2257, Best Val Loss: 5.2257\n",
      "Epoch 5/1000, Train Loss: 5.1834, Val Loss: 5.1261, Best Val Loss: 5.1261\n",
      "Epoch 6/1000, Train Loss: 4.6279, Val Loss: 2.5967, Best Val Loss: 2.5967\n",
      "Epoch 7/1000, Train Loss: 2.2606, Val Loss: 2.1222, Best Val Loss: 2.1222\n",
      "Epoch 8/1000, Train Loss: 2.0200, Val Loss: 1.9634, Best Val Loss: 1.9634\n",
      "Epoch 9/1000, Train Loss: 1.9129, Val Loss: 1.8853, Best Val Loss: 1.8853\n",
      "Epoch 10/1000, Train Loss: 1.8530, Val Loss: 1.8453, Best Val Loss: 1.8453\n",
      "Epoch 11/1000, Train Loss: 1.8135, Val Loss: 1.8189, Best Val Loss: 1.8189\n",
      "Epoch 12/1000, Train Loss: 1.7826, Val Loss: 1.7895, Best Val Loss: 1.7895\n",
      "Epoch 13/1000, Train Loss: 1.7639, Val Loss: 1.7628, Best Val Loss: 1.7628\n",
      "Epoch 14/1000, Train Loss: 1.7417, Val Loss: 1.7456, Best Val Loss: 1.7456\n",
      "Epoch 18/1000, Train Loss: 1.6921, Val Loss: 1.6958, Best Val Loss: 1.6958\n",
      "Epoch 19/1000, Train Loss: 1.6813, Val Loss: 1.6694, Best Val Loss: 1.6694\n",
      "Epoch 20/1000, Train Loss: 1.6699, Val Loss: 1.6657, Best Val Loss: 1.6657\n",
      "Epoch 25/1000, Train Loss: 1.6355, Val Loss: 1.6612, Best Val Loss: 1.6612\n",
      "Epoch 26/1000, Train Loss: 1.6340, Val Loss: 1.6346, Best Val Loss: 1.6346\n",
      "Epoch 32/1000, Train Loss: 1.5907, Val Loss: 1.6081, Best Val Loss: 1.6081\n",
      "Epoch 36/1000, Train Loss: 1.5611, Val Loss: 1.5911, Best Val Loss: 1.5911\n",
      "Epoch 37/1000, Train Loss: 1.5544, Val Loss: 1.5718, Best Val Loss: 1.5718\n",
      "Epoch 38/1000, Train Loss: 1.5476, Val Loss: 1.5681, Best Val Loss: 1.5681\n",
      "Epoch 47/1000, Train Loss: 1.5073, Val Loss: 1.5357, Best Val Loss: 1.5357\n",
      "Epoch 50/1000, Train Loss: 1.5027, Val Loss: 1.5231, Best Val Loss: 1.5231\n",
      "Epoch 51/1000, Train Loss: 1.4911, Val Loss: 1.5150, Best Val Loss: 1.5150\n",
      "Epoch 65/1000, Train Loss: 1.4493, Val Loss: 1.4843, Best Val Loss: 1.4843\n",
      "Epoch 68/1000, Train Loss: 1.4441, Val Loss: 1.4817, Best Val Loss: 1.4817\n",
      "Epoch 85/1000, Train Loss: 1.4029, Val Loss: 1.4764, Best Val Loss: 1.4764\n",
      "Epoch 96/1000, Train Loss: 1.3853, Val Loss: 1.4737, Best Val Loss: 1.4737\n",
      "Epoch 100/1000, Train Loss: 1.3748, Val Loss: 1.4677, Best Val Loss: 1.4677\n",
      "Epoch 111/1000, Train Loss: 1.3584, Val Loss: 1.4643, Best Val Loss: 1.4643\n",
      "Early stopping at epoch 161, Best Val Loss: 1.4643\n",
      "Epistemic Variance: 0.904564\n",
      "Aleatoric Variance: 7.032503\n",
      " (1/n) Calculating accuracy metrics\n",
      " (2/n) Calculating average calibration metrics\n",
      " (3/n) Calculating adversarial group calibration metrics\n",
      "  [1/2] for mean absolute calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [2/2] for root mean squared calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (4/n) Calculating sharpness metrics\n",
      " (n/n) Calculating proper scoring rule metrics\n",
      "**Finished Calculating All Metrics**\n",
      "\n",
      "\n",
      "===================== Accuracy Metrics =====================\n",
      "  MAE           1.981\n",
      "  RMSE          2.793\n",
      "  MDAE          1.491\n",
      "  MARPD         1.730\n",
      "  R2            0.863\n",
      "  Correlation   0.929\n",
      "=============== Average Calibration Metrics ================\n",
      "  Root-mean-squared Calibration Error   0.024\n",
      "  Mean-absolute Calibration Error       0.021\n",
      "  Miscalibration Area                   0.021\n",
      "========== Adversarial Group Calibration Metrics ===========\n",
      "  Mean-absolute Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.033\n",
      "     Group Size: 0.56 -- Calibration Error: 0.025\n",
      "     Group Size: 1.00 -- Calibration Error: 0.021\n",
      "  Root-mean-squared Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.037\n",
      "     Group Size: 0.56 -- Calibration Error: 0.030\n",
      "     Group Size: 1.00 -- Calibration Error: 0.024\n",
      "==================== Sharpness Metrics =====================\n",
      "  Sharpness   2.817\n",
      "=================== Scoring Rule Metrics ===================\n",
      "  Negative-log-likelihood   2.288\n",
      "  CRPS                      1.417\n",
      "  Check Score               0.715\n",
      "  Interval Score            7.105\n",
      "{'accuracy': {'mae': 1.9811315987059397, 'rmse': np.float64(2.7934507600083656), 'mdae': 1.4908690673828175, 'marpd': np.float64(1.7298635990513775), 'r2': 0.8633416367694272, 'corr': np.float64(0.9294616515779985)}, 'avg_calibration': {'rms_cal': np.float64(0.024027894061398655), 'ma_cal': np.float64(0.020936015931690227), 'miscal_area': np.float64(0.021145424462017635)}, 'adv_group_calibration': {'ma_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.38348485, 0.03292291, 0.02905929, 0.02650623, 0.02629196,\n",
      "       0.02490192, 0.02383617, 0.02366002, 0.02292055, 0.02093602]), 'adv_group_cali_stderr': array([0.07483481, 0.00520541, 0.00395479, 0.00171945, 0.00195642,\n",
      "       0.00167356, 0.00090114, 0.00088606, 0.00054908, 0.        ])}, 'rms_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.42043661, 0.03736986, 0.03512278, 0.03182604, 0.02880253,\n",
      "       0.02983046, 0.02775798, 0.02680575, 0.02543702, 0.02402789]), 'adv_group_cali_stderr': array([0.08106263, 0.00385057, 0.00404214, 0.00247361, 0.00185265,\n",
      "       0.00202626, 0.00135855, 0.00093511, 0.00067294, 0.        ])}}, 'sharpness': {'sharp': np.float32(2.81728)}, 'scoring_rule': {'nll': np.float64(2.2879378146076124), 'crps': np.float64(1.4169408178311655), 'check': np.float64(0.7154332051362339), 'interval': np.float64(7.105245636721301)}}\n",
      "coverage: 0.9499182928001538, MPIW: 10.040916990379985\n",
      "Run 8 with seed 10001\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 160.8476, Val Loss: 5.5751, Best Val Loss: 5.5751\n",
      "Epoch 2/1000, Train Loss: 5.5141, Val Loss: 5.4497, Best Val Loss: 5.4497\n",
      "Epoch 3/1000, Train Loss: 5.3996, Val Loss: 5.3368, Best Val Loss: 5.3368\n",
      "Epoch 4/1000, Train Loss: 5.2552, Val Loss: 5.1282, Best Val Loss: 5.1282\n",
      "Epoch 5/1000, Train Loss: 4.2093, Val Loss: 2.5839, Best Val Loss: 2.5839\n",
      "Epoch 6/1000, Train Loss: 2.4078, Val Loss: 2.2705, Best Val Loss: 2.2705\n",
      "Epoch 7/1000, Train Loss: 2.1572, Val Loss: 2.0804, Best Val Loss: 2.0804\n",
      "Epoch 8/1000, Train Loss: 1.9992, Val Loss: 1.9444, Best Val Loss: 1.9444\n",
      "Epoch 9/1000, Train Loss: 1.9068, Val Loss: 1.8751, Best Val Loss: 1.8751\n",
      "Epoch 10/1000, Train Loss: 1.8449, Val Loss: 1.8598, Best Val Loss: 1.8598\n",
      "Epoch 11/1000, Train Loss: 1.8034, Val Loss: 1.7839, Best Val Loss: 1.7839\n",
      "Epoch 12/1000, Train Loss: 1.7868, Val Loss: 1.7672, Best Val Loss: 1.7672\n",
      "Epoch 13/1000, Train Loss: 1.7626, Val Loss: 1.7591, Best Val Loss: 1.7591\n",
      "Epoch 15/1000, Train Loss: 1.7336, Val Loss: 1.7191, Best Val Loss: 1.7191\n",
      "Epoch 20/1000, Train Loss: 1.6796, Val Loss: 1.6768, Best Val Loss: 1.6768\n",
      "Epoch 23/1000, Train Loss: 1.6534, Val Loss: 1.6753, Best Val Loss: 1.6753\n",
      "Epoch 24/1000, Train Loss: 1.6482, Val Loss: 1.6648, Best Val Loss: 1.6648\n",
      "Epoch 25/1000, Train Loss: 1.6404, Val Loss: 1.6498, Best Val Loss: 1.6498\n",
      "Epoch 26/1000, Train Loss: 1.6420, Val Loss: 1.6328, Best Val Loss: 1.6328\n",
      "Epoch 28/1000, Train Loss: 1.6236, Val Loss: 1.6315, Best Val Loss: 1.6315\n",
      "Epoch 29/1000, Train Loss: 1.6081, Val Loss: 1.6042, Best Val Loss: 1.6042\n",
      "Epoch 31/1000, Train Loss: 1.6020, Val Loss: 1.5785, Best Val Loss: 1.5785\n",
      "Epoch 37/1000, Train Loss: 1.5712, Val Loss: 1.5612, Best Val Loss: 1.5612\n",
      "Epoch 48/1000, Train Loss: 1.5171, Val Loss: 1.5330, Best Val Loss: 1.5330\n",
      "Epoch 53/1000, Train Loss: 1.5013, Val Loss: 1.5298, Best Val Loss: 1.5298\n",
      "Epoch 55/1000, Train Loss: 1.4952, Val Loss: 1.5151, Best Val Loss: 1.5151\n",
      "Epoch 57/1000, Train Loss: 1.4838, Val Loss: 1.5104, Best Val Loss: 1.5104\n",
      "Epoch 62/1000, Train Loss: 1.4720, Val Loss: 1.5072, Best Val Loss: 1.5072\n",
      "Epoch 71/1000, Train Loss: 1.4446, Val Loss: 1.4839, Best Val Loss: 1.4839\n",
      "Epoch 91/1000, Train Loss: 1.4048, Val Loss: 1.4831, Best Val Loss: 1.4831\n",
      "Epoch 93/1000, Train Loss: 1.4113, Val Loss: 1.4804, Best Val Loss: 1.4804\n",
      "Epoch 121/1000, Train Loss: 1.3645, Val Loss: 1.4775, Best Val Loss: 1.4775\n",
      "Epoch 130/1000, Train Loss: 1.3527, Val Loss: 1.4738, Best Val Loss: 1.4738\n",
      "Epoch 132/1000, Train Loss: 1.3492, Val Loss: 1.4709, Best Val Loss: 1.4709\n",
      "Epoch 153/1000, Train Loss: 1.3172, Val Loss: 1.4704, Best Val Loss: 1.4704\n",
      "Early stopping at epoch 203, Best Val Loss: 1.4704\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 131.0774, Val Loss: 5.5103, Best Val Loss: 5.5103\n",
      "Epoch 2/1000, Train Loss: 5.4333, Val Loss: 5.3677, Best Val Loss: 5.3677\n",
      "Epoch 3/1000, Train Loss: 5.3265, Val Loss: 5.2864, Best Val Loss: 5.2864\n",
      "Epoch 4/1000, Train Loss: 5.2598, Val Loss: 5.2329, Best Val Loss: 5.2329\n",
      "Epoch 5/1000, Train Loss: 5.2094, Val Loss: 5.1829, Best Val Loss: 5.1829\n",
      "Epoch 6/1000, Train Loss: 5.1493, Val Loss: 5.1043, Best Val Loss: 5.1043\n",
      "Epoch 7/1000, Train Loss: 4.8726, Val Loss: 3.0414, Best Val Loss: 3.0414\n",
      "Epoch 8/1000, Train Loss: 2.2519, Val Loss: 2.0822, Best Val Loss: 2.0822\n",
      "Epoch 9/1000, Train Loss: 1.9726, Val Loss: 1.9232, Best Val Loss: 1.9232\n",
      "Epoch 10/1000, Train Loss: 1.8769, Val Loss: 1.8726, Best Val Loss: 1.8726\n",
      "Epoch 11/1000, Train Loss: 1.8302, Val Loss: 1.7941, Best Val Loss: 1.7941\n",
      "Epoch 12/1000, Train Loss: 1.7920, Val Loss: 1.7766, Best Val Loss: 1.7766\n",
      "Epoch 13/1000, Train Loss: 1.7589, Val Loss: 1.7737, Best Val Loss: 1.7737\n",
      "Epoch 14/1000, Train Loss: 1.7402, Val Loss: 1.7542, Best Val Loss: 1.7542\n",
      "Epoch 15/1000, Train Loss: 1.7253, Val Loss: 1.7268, Best Val Loss: 1.7268\n",
      "Epoch 20/1000, Train Loss: 1.6659, Val Loss: 1.7090, Best Val Loss: 1.7090\n",
      "Epoch 22/1000, Train Loss: 1.6619, Val Loss: 1.6784, Best Val Loss: 1.6784\n",
      "Epoch 24/1000, Train Loss: 1.6342, Val Loss: 1.6671, Best Val Loss: 1.6671\n",
      "Epoch 25/1000, Train Loss: 1.6329, Val Loss: 1.6610, Best Val Loss: 1.6610\n",
      "Epoch 27/1000, Train Loss: 1.6192, Val Loss: 1.6195, Best Val Loss: 1.6195\n",
      "Epoch 28/1000, Train Loss: 1.6075, Val Loss: 1.6192, Best Val Loss: 1.6192\n",
      "Epoch 29/1000, Train Loss: 1.5983, Val Loss: 1.6048, Best Val Loss: 1.6048\n",
      "Epoch 31/1000, Train Loss: 1.5908, Val Loss: 1.6024, Best Val Loss: 1.6024\n",
      "Epoch 34/1000, Train Loss: 1.5672, Val Loss: 1.5694, Best Val Loss: 1.5694\n",
      "Epoch 42/1000, Train Loss: 1.5214, Val Loss: 1.5534, Best Val Loss: 1.5534\n",
      "Epoch 44/1000, Train Loss: 1.5050, Val Loss: 1.5452, Best Val Loss: 1.5452\n",
      "Epoch 47/1000, Train Loss: 1.5069, Val Loss: 1.5348, Best Val Loss: 1.5348\n",
      "Epoch 50/1000, Train Loss: 1.4786, Val Loss: 1.5285, Best Val Loss: 1.5285\n",
      "Epoch 54/1000, Train Loss: 1.4750, Val Loss: 1.5250, Best Val Loss: 1.5250\n",
      "Epoch 60/1000, Train Loss: 1.4608, Val Loss: 1.4965, Best Val Loss: 1.4965\n",
      "Epoch 70/1000, Train Loss: 1.4212, Val Loss: 1.4913, Best Val Loss: 1.4913\n",
      "Epoch 76/1000, Train Loss: 1.4140, Val Loss: 1.4892, Best Val Loss: 1.4892\n",
      "Epoch 112/1000, Train Loss: 1.3371, Val Loss: 1.4849, Best Val Loss: 1.4849\n",
      "Early stopping at epoch 162, Best Val Loss: 1.4849\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 146.7584, Val Loss: 5.6231, Best Val Loss: 5.6231\n",
      "Epoch 2/1000, Train Loss: 5.5323, Val Loss: 5.4484, Best Val Loss: 5.4484\n",
      "Epoch 3/1000, Train Loss: 5.4001, Val Loss: 5.3457, Best Val Loss: 5.3457\n",
      "Epoch 4/1000, Train Loss: 5.3033, Val Loss: 5.2559, Best Val Loss: 5.2559\n",
      "Epoch 5/1000, Train Loss: 5.2047, Val Loss: 5.1377, Best Val Loss: 5.1377\n",
      "Epoch 6/1000, Train Loss: 4.3799, Val Loss: 2.4959, Best Val Loss: 2.4959\n",
      "Epoch 7/1000, Train Loss: 2.3126, Val Loss: 2.1879, Best Val Loss: 2.1879\n",
      "Epoch 8/1000, Train Loss: 2.1022, Val Loss: 2.0326, Best Val Loss: 2.0326\n",
      "Epoch 9/1000, Train Loss: 1.9739, Val Loss: 1.9509, Best Val Loss: 1.9509\n",
      "Epoch 10/1000, Train Loss: 1.8918, Val Loss: 1.8827, Best Val Loss: 1.8827\n",
      "Epoch 11/1000, Train Loss: 1.8408, Val Loss: 1.8192, Best Val Loss: 1.8192\n",
      "Epoch 14/1000, Train Loss: 1.7517, Val Loss: 1.7482, Best Val Loss: 1.7482\n",
      "Epoch 15/1000, Train Loss: 1.7270, Val Loss: 1.7167, Best Val Loss: 1.7167\n",
      "Epoch 16/1000, Train Loss: 1.7031, Val Loss: 1.6965, Best Val Loss: 1.6965\n",
      "Epoch 17/1000, Train Loss: 1.6940, Val Loss: 1.6870, Best Val Loss: 1.6870\n",
      "Epoch 19/1000, Train Loss: 1.6665, Val Loss: 1.6660, Best Val Loss: 1.6660\n",
      "Epoch 21/1000, Train Loss: 1.6558, Val Loss: 1.6515, Best Val Loss: 1.6515\n",
      "Epoch 23/1000, Train Loss: 1.6381, Val Loss: 1.6485, Best Val Loss: 1.6485\n",
      "Epoch 24/1000, Train Loss: 1.6371, Val Loss: 1.6344, Best Val Loss: 1.6344\n",
      "Epoch 28/1000, Train Loss: 1.6046, Val Loss: 1.6093, Best Val Loss: 1.6093\n",
      "Epoch 32/1000, Train Loss: 1.5743, Val Loss: 1.5768, Best Val Loss: 1.5768\n",
      "Epoch 37/1000, Train Loss: 1.5481, Val Loss: 1.5750, Best Val Loss: 1.5750\n",
      "Epoch 38/1000, Train Loss: 1.5456, Val Loss: 1.5724, Best Val Loss: 1.5724\n",
      "Epoch 40/1000, Train Loss: 1.5251, Val Loss: 1.5670, Best Val Loss: 1.5670\n",
      "Epoch 43/1000, Train Loss: 1.5194, Val Loss: 1.5449, Best Val Loss: 1.5449\n",
      "Epoch 46/1000, Train Loss: 1.4980, Val Loss: 1.5394, Best Val Loss: 1.5394\n",
      "Epoch 49/1000, Train Loss: 1.4932, Val Loss: 1.5348, Best Val Loss: 1.5348\n",
      "Epoch 54/1000, Train Loss: 1.4824, Val Loss: 1.5284, Best Val Loss: 1.5284\n",
      "Epoch 55/1000, Train Loss: 1.4706, Val Loss: 1.5147, Best Val Loss: 1.5147\n",
      "Epoch 57/1000, Train Loss: 1.4607, Val Loss: 1.5121, Best Val Loss: 1.5121\n",
      "Epoch 64/1000, Train Loss: 1.4477, Val Loss: 1.4993, Best Val Loss: 1.4993\n",
      "Epoch 68/1000, Train Loss: 1.4394, Val Loss: 1.4902, Best Val Loss: 1.4902\n",
      "Epoch 87/1000, Train Loss: 1.3996, Val Loss: 1.4899, Best Val Loss: 1.4899\n",
      "Epoch 90/1000, Train Loss: 1.3923, Val Loss: 1.4850, Best Val Loss: 1.4850\n",
      "Epoch 91/1000, Train Loss: 1.3991, Val Loss: 1.4641, Best Val Loss: 1.4641\n",
      "Epoch 129/1000, Train Loss: 1.3338, Val Loss: 1.4560, Best Val Loss: 1.4560\n",
      "Early stopping at epoch 179, Best Val Loss: 1.4560\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 149.8877, Val Loss: 5.5648, Best Val Loss: 5.5648\n",
      "Epoch 2/1000, Train Loss: 5.5079, Val Loss: 5.4378, Best Val Loss: 5.4378\n",
      "Epoch 3/1000, Train Loss: 5.3974, Val Loss: 5.3394, Best Val Loss: 5.3394\n",
      "Epoch 4/1000, Train Loss: 5.2820, Val Loss: 5.1965, Best Val Loss: 5.1965\n",
      "Epoch 5/1000, Train Loss: 5.0035, Val Loss: 4.5672, Best Val Loss: 4.5672\n",
      "Epoch 6/1000, Train Loss: 2.8816, Val Loss: 2.4177, Best Val Loss: 2.4177\n",
      "Epoch 7/1000, Train Loss: 2.2914, Val Loss: 2.2002, Best Val Loss: 2.2002\n",
      "Epoch 8/1000, Train Loss: 2.1109, Val Loss: 2.0790, Best Val Loss: 2.0790\n",
      "Epoch 9/1000, Train Loss: 1.9925, Val Loss: 1.9653, Best Val Loss: 1.9653\n",
      "Epoch 10/1000, Train Loss: 1.9142, Val Loss: 1.8975, Best Val Loss: 1.8975\n",
      "Epoch 12/1000, Train Loss: 1.8054, Val Loss: 1.8225, Best Val Loss: 1.8225\n",
      "Epoch 13/1000, Train Loss: 1.7862, Val Loss: 1.7731, Best Val Loss: 1.7731\n",
      "Epoch 14/1000, Train Loss: 1.7599, Val Loss: 1.7518, Best Val Loss: 1.7518\n",
      "Epoch 16/1000, Train Loss: 1.7440, Val Loss: 1.7228, Best Val Loss: 1.7228\n",
      "Epoch 17/1000, Train Loss: 1.7156, Val Loss: 1.7049, Best Val Loss: 1.7049\n",
      "Epoch 21/1000, Train Loss: 1.6927, Val Loss: 1.6631, Best Val Loss: 1.6631\n",
      "Epoch 24/1000, Train Loss: 1.6567, Val Loss: 1.6497, Best Val Loss: 1.6497\n",
      "Epoch 28/1000, Train Loss: 1.6256, Val Loss: 1.6306, Best Val Loss: 1.6306\n",
      "Epoch 32/1000, Train Loss: 1.5941, Val Loss: 1.6246, Best Val Loss: 1.6246\n",
      "Epoch 35/1000, Train Loss: 1.5917, Val Loss: 1.5838, Best Val Loss: 1.5838\n",
      "Epoch 40/1000, Train Loss: 1.5579, Val Loss: 1.5836, Best Val Loss: 1.5836\n",
      "Epoch 41/1000, Train Loss: 1.5438, Val Loss: 1.5618, Best Val Loss: 1.5618\n",
      "Epoch 44/1000, Train Loss: 1.5369, Val Loss: 1.5521, Best Val Loss: 1.5521\n",
      "Epoch 51/1000, Train Loss: 1.5142, Val Loss: 1.5421, Best Val Loss: 1.5421\n",
      "Epoch 53/1000, Train Loss: 1.5023, Val Loss: 1.5412, Best Val Loss: 1.5412\n",
      "Epoch 54/1000, Train Loss: 1.5109, Val Loss: 1.5286, Best Val Loss: 1.5286\n",
      "Epoch 60/1000, Train Loss: 1.4875, Val Loss: 1.5200, Best Val Loss: 1.5200\n",
      "Epoch 67/1000, Train Loss: 1.4773, Val Loss: 1.5165, Best Val Loss: 1.5165\n",
      "Epoch 68/1000, Train Loss: 1.4670, Val Loss: 1.5022, Best Val Loss: 1.5022\n",
      "Epoch 74/1000, Train Loss: 1.4517, Val Loss: 1.5012, Best Val Loss: 1.5012\n",
      "Epoch 77/1000, Train Loss: 1.4539, Val Loss: 1.4989, Best Val Loss: 1.4989\n",
      "Epoch 97/1000, Train Loss: 1.4228, Val Loss: 1.4985, Best Val Loss: 1.4985\n",
      "Epoch 103/1000, Train Loss: 1.3998, Val Loss: 1.4920, Best Val Loss: 1.4920\n",
      "Epoch 111/1000, Train Loss: 1.3819, Val Loss: 1.4613, Best Val Loss: 1.4613\n",
      "Early stopping at epoch 161, Best Val Loss: 1.4613\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 148.2153, Val Loss: 5.5114, Best Val Loss: 5.5114\n",
      "Epoch 2/1000, Train Loss: 5.4648, Val Loss: 5.4210, Best Val Loss: 5.4210\n",
      "Epoch 3/1000, Train Loss: 5.3845, Val Loss: 5.3461, Best Val Loss: 5.3461\n",
      "Epoch 4/1000, Train Loss: 5.3083, Val Loss: 5.2685, Best Val Loss: 5.2685\n",
      "Epoch 5/1000, Train Loss: 5.2153, Val Loss: 5.1456, Best Val Loss: 5.1456\n",
      "Epoch 6/1000, Train Loss: 4.5161, Val Loss: 2.6108, Best Val Loss: 2.6108\n",
      "Epoch 7/1000, Train Loss: 2.3699, Val Loss: 2.2298, Best Val Loss: 2.2298\n",
      "Epoch 8/1000, Train Loss: 2.1164, Val Loss: 2.0382, Best Val Loss: 2.0382\n",
      "Epoch 9/1000, Train Loss: 1.9786, Val Loss: 1.9398, Best Val Loss: 1.9398\n",
      "Epoch 10/1000, Train Loss: 1.8952, Val Loss: 1.8710, Best Val Loss: 1.8710\n",
      "Epoch 11/1000, Train Loss: 1.8497, Val Loss: 1.8040, Best Val Loss: 1.8040\n",
      "Epoch 13/1000, Train Loss: 1.7829, Val Loss: 1.7917, Best Val Loss: 1.7917\n",
      "Epoch 14/1000, Train Loss: 1.7549, Val Loss: 1.7252, Best Val Loss: 1.7252\n",
      "Epoch 16/1000, Train Loss: 1.7278, Val Loss: 1.7228, Best Val Loss: 1.7228\n",
      "Epoch 18/1000, Train Loss: 1.7030, Val Loss: 1.7094, Best Val Loss: 1.7094\n",
      "Epoch 20/1000, Train Loss: 1.6792, Val Loss: 1.6840, Best Val Loss: 1.6840\n",
      "Epoch 21/1000, Train Loss: 1.6626, Val Loss: 1.6825, Best Val Loss: 1.6825\n",
      "Epoch 22/1000, Train Loss: 1.6635, Val Loss: 1.6488, Best Val Loss: 1.6488\n",
      "Epoch 24/1000, Train Loss: 1.6466, Val Loss: 1.6465, Best Val Loss: 1.6465\n",
      "Epoch 25/1000, Train Loss: 1.6434, Val Loss: 1.6378, Best Val Loss: 1.6378\n",
      "Epoch 30/1000, Train Loss: 1.6187, Val Loss: 1.6375, Best Val Loss: 1.6375\n",
      "Epoch 31/1000, Train Loss: 1.6022, Val Loss: 1.6244, Best Val Loss: 1.6244\n",
      "Epoch 36/1000, Train Loss: 1.5641, Val Loss: 1.6196, Best Val Loss: 1.6196\n",
      "Epoch 37/1000, Train Loss: 1.5666, Val Loss: 1.6076, Best Val Loss: 1.6076\n",
      "Epoch 39/1000, Train Loss: 1.5482, Val Loss: 1.5770, Best Val Loss: 1.5770\n",
      "Epoch 42/1000, Train Loss: 1.5410, Val Loss: 1.5712, Best Val Loss: 1.5712\n",
      "Epoch 43/1000, Train Loss: 1.5338, Val Loss: 1.5636, Best Val Loss: 1.5636\n",
      "Epoch 45/1000, Train Loss: 1.5230, Val Loss: 1.5310, Best Val Loss: 1.5310\n",
      "Epoch 57/1000, Train Loss: 1.4850, Val Loss: 1.5199, Best Val Loss: 1.5199\n",
      "Epoch 60/1000, Train Loss: 1.4800, Val Loss: 1.5110, Best Val Loss: 1.5110\n",
      "Epoch 72/1000, Train Loss: 1.4466, Val Loss: 1.4901, Best Val Loss: 1.4901\n",
      "Epoch 87/1000, Train Loss: 1.4232, Val Loss: 1.4791, Best Val Loss: 1.4791\n",
      "Epoch 100/1000, Train Loss: 1.3999, Val Loss: 1.4779, Best Val Loss: 1.4779\n",
      "Epoch 133/1000, Train Loss: 1.3478, Val Loss: 1.4633, Best Val Loss: 1.4633\n",
      "Early stopping at epoch 183, Best Val Loss: 1.4633\n",
      "Epistemic Variance: 0.846175\n",
      "Aleatoric Variance: 9.700246\n",
      " (1/n) Calculating accuracy metrics\n",
      " (2/n) Calculating average calibration metrics\n",
      " (3/n) Calculating adversarial group calibration metrics\n",
      "  [1/2] for mean absolute calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [2/2] for root mean squared calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (4/n) Calculating sharpness metrics\n",
      " (n/n) Calculating proper scoring rule metrics\n",
      "**Finished Calculating All Metrics**\n",
      "\n",
      "\n",
      "===================== Accuracy Metrics =====================\n",
      "  MAE           1.977\n",
      "  RMSE          2.766\n",
      "  MDAE          1.457\n",
      "  MARPD         1.727\n",
      "  R2            0.866\n",
      "  Correlation   0.931\n",
      "=============== Average Calibration Metrics ================\n",
      "  Root-mean-squared Calibration Error   0.033\n",
      "  Mean-absolute Calibration Error       0.028\n",
      "  Miscalibration Area                   0.028\n",
      "========== Adversarial Group Calibration Metrics ===========\n",
      "  Mean-absolute Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.044\n",
      "     Group Size: 0.56 -- Calibration Error: 0.031\n",
      "     Group Size: 1.00 -- Calibration Error: 0.028\n",
      "  Root-mean-squared Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.046\n",
      "     Group Size: 0.56 -- Calibration Error: 0.036\n",
      "     Group Size: 1.00 -- Calibration Error: 0.033\n",
      "==================== Sharpness Metrics =====================\n",
      "  Sharpness   3.248\n",
      "=================== Scoring Rule Metrics ===================\n",
      "  Negative-log-likelihood   2.285\n",
      "  CRPS                      1.416\n",
      "  Check Score               0.715\n",
      "  Interval Score            7.113\n",
      "{'accuracy': {'mae': 1.9769504351692235, 'rmse': np.float64(2.7656761334682893), 'mdae': 1.456980859374994, 'marpd': np.float64(1.7273390924960756), 'r2': 0.8660456511029008, 'corr': np.float64(0.9308998206087401)}, 'avg_calibration': {'rms_cal': np.float64(0.03272556653746979), 'ma_cal': np.float64(0.027570271590265785), 'miscal_area': np.float64(0.027842480022774067)}, 'adv_group_calibration': {'ma_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.3765    , 0.04385574, 0.03658344, 0.0329801 , 0.03292622,\n",
      "       0.03061827, 0.03001819, 0.02990591, 0.02898535, 0.02757027]), 'adv_group_cali_stderr': array([4.85116254e-02, 5.33625144e-03, 2.74209424e-03, 2.67441057e-03,\n",
      "       1.24382257e-03, 1.06019866e-03, 8.17001018e-04, 1.50698485e-03,\n",
      "       6.03178484e-04, 3.65711820e-18])}, 'rms_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.45902213, 0.04647776, 0.04171573, 0.03837041, 0.03817333,\n",
      "       0.03614727, 0.03614667, 0.03508266, 0.0347758 , 0.03272557]), 'adv_group_cali_stderr': array([0.06303107, 0.00304413, 0.00398055, 0.00217238, 0.00139203,\n",
      "       0.00124782, 0.00106814, 0.00083866, 0.00059912, 0.        ])}}, 'sharpness': {'sharp': np.float32(3.2475255)}, 'scoring_rule': {'nll': np.float64(2.2847498734998273), 'crps': np.float64(1.4156780276093872), 'check': np.float64(0.7147932856780381), 'interval': np.float64(7.112986387773111)}}\n",
      "coverage: 0.9536672113813323, MPIW: 10.37957672555416\n",
      "Run 9 with seed 31415\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 146.3950, Val Loss: 5.5080, Best Val Loss: 5.5080\n",
      "Epoch 2/1000, Train Loss: 5.4657, Val Loss: 5.4078, Best Val Loss: 5.4078\n",
      "Epoch 3/1000, Train Loss: 5.3500, Val Loss: 5.2605, Best Val Loss: 5.2605\n",
      "Epoch 4/1000, Train Loss: 5.0628, Val Loss: 4.6854, Best Val Loss: 4.6854\n",
      "Epoch 5/1000, Train Loss: 3.1199, Val Loss: 2.4725, Best Val Loss: 2.4725\n",
      "Epoch 6/1000, Train Loss: 2.3445, Val Loss: 2.2443, Best Val Loss: 2.2443\n",
      "Epoch 7/1000, Train Loss: 2.1589, Val Loss: 2.0915, Best Val Loss: 2.0915\n",
      "Epoch 8/1000, Train Loss: 2.0318, Val Loss: 1.9906, Best Val Loss: 1.9906\n",
      "Epoch 9/1000, Train Loss: 1.9414, Val Loss: 1.9191, Best Val Loss: 1.9191\n",
      "Epoch 10/1000, Train Loss: 1.8705, Val Loss: 1.8780, Best Val Loss: 1.8780\n",
      "Epoch 11/1000, Train Loss: 1.8320, Val Loss: 1.8079, Best Val Loss: 1.8079\n",
      "Epoch 13/1000, Train Loss: 1.7638, Val Loss: 1.7690, Best Val Loss: 1.7690\n",
      "Epoch 15/1000, Train Loss: 1.7378, Val Loss: 1.7550, Best Val Loss: 1.7550\n",
      "Epoch 16/1000, Train Loss: 1.7203, Val Loss: 1.7239, Best Val Loss: 1.7239\n",
      "Epoch 17/1000, Train Loss: 1.7121, Val Loss: 1.7062, Best Val Loss: 1.7062\n",
      "Epoch 19/1000, Train Loss: 1.6980, Val Loss: 1.6798, Best Val Loss: 1.6798\n",
      "Epoch 23/1000, Train Loss: 1.6637, Val Loss: 1.6559, Best Val Loss: 1.6559\n",
      "Epoch 26/1000, Train Loss: 1.6462, Val Loss: 1.6511, Best Val Loss: 1.6511\n",
      "Epoch 28/1000, Train Loss: 1.6332, Val Loss: 1.6197, Best Val Loss: 1.6197\n",
      "Epoch 36/1000, Train Loss: 1.5967, Val Loss: 1.6065, Best Val Loss: 1.6065\n",
      "Epoch 40/1000, Train Loss: 1.5746, Val Loss: 1.5730, Best Val Loss: 1.5730\n",
      "Epoch 46/1000, Train Loss: 1.5566, Val Loss: 1.5480, Best Val Loss: 1.5480\n",
      "Epoch 55/1000, Train Loss: 1.5330, Val Loss: 1.5393, Best Val Loss: 1.5393\n",
      "Epoch 64/1000, Train Loss: 1.5046, Val Loss: 1.5158, Best Val Loss: 1.5158\n",
      "Epoch 83/1000, Train Loss: 1.4543, Val Loss: 1.5082, Best Val Loss: 1.5082\n",
      "Epoch 87/1000, Train Loss: 1.4568, Val Loss: 1.4996, Best Val Loss: 1.4996\n",
      "Epoch 94/1000, Train Loss: 1.4395, Val Loss: 1.4994, Best Val Loss: 1.4994\n",
      "Epoch 101/1000, Train Loss: 1.4270, Val Loss: 1.4898, Best Val Loss: 1.4898\n",
      "Epoch 107/1000, Train Loss: 1.4123, Val Loss: 1.4775, Best Val Loss: 1.4775\n",
      "Epoch 108/1000, Train Loss: 1.4174, Val Loss: 1.4762, Best Val Loss: 1.4762\n",
      "Epoch 118/1000, Train Loss: 1.4030, Val Loss: 1.4721, Best Val Loss: 1.4721\n",
      "Epoch 123/1000, Train Loss: 1.3849, Val Loss: 1.4679, Best Val Loss: 1.4679\n",
      "Epoch 148/1000, Train Loss: 1.3477, Val Loss: 1.4632, Best Val Loss: 1.4632\n",
      "Epoch 163/1000, Train Loss: 1.3379, Val Loss: 1.4627, Best Val Loss: 1.4627\n",
      "Epoch 177/1000, Train Loss: 1.3122, Val Loss: 1.4546, Best Val Loss: 1.4546\n",
      "Early stopping at epoch 227, Best Val Loss: 1.4546\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 146.2940, Val Loss: 5.4899, Best Val Loss: 5.4899\n",
      "Epoch 2/1000, Train Loss: 5.4204, Val Loss: 5.3091, Best Val Loss: 5.3091\n",
      "Epoch 3/1000, Train Loss: 5.1159, Val Loss: 4.7727, Best Val Loss: 4.7727\n",
      "Epoch 4/1000, Train Loss: 3.6349, Val Loss: 2.8482, Best Val Loss: 2.8482\n",
      "Epoch 5/1000, Train Loss: 2.6633, Val Loss: 2.5193, Best Val Loss: 2.5193\n",
      "Epoch 6/1000, Train Loss: 2.4006, Val Loss: 2.3077, Best Val Loss: 2.3077\n",
      "Epoch 7/1000, Train Loss: 2.2133, Val Loss: 2.1463, Best Val Loss: 2.1463\n",
      "Epoch 8/1000, Train Loss: 2.0690, Val Loss: 2.0415, Best Val Loss: 2.0415\n",
      "Epoch 9/1000, Train Loss: 1.9671, Val Loss: 1.9429, Best Val Loss: 1.9429\n",
      "Epoch 10/1000, Train Loss: 1.9073, Val Loss: 1.8865, Best Val Loss: 1.8865\n",
      "Epoch 11/1000, Train Loss: 1.8564, Val Loss: 1.8466, Best Val Loss: 1.8466\n",
      "Epoch 12/1000, Train Loss: 1.8172, Val Loss: 1.8336, Best Val Loss: 1.8336\n",
      "Epoch 13/1000, Train Loss: 1.7897, Val Loss: 1.8014, Best Val Loss: 1.8014\n",
      "Epoch 14/1000, Train Loss: 1.7645, Val Loss: 1.7358, Best Val Loss: 1.7358\n",
      "Epoch 20/1000, Train Loss: 1.6923, Val Loss: 1.7046, Best Val Loss: 1.7046\n",
      "Epoch 21/1000, Train Loss: 1.6948, Val Loss: 1.6751, Best Val Loss: 1.6751\n",
      "Epoch 26/1000, Train Loss: 1.6591, Val Loss: 1.6488, Best Val Loss: 1.6488\n",
      "Epoch 29/1000, Train Loss: 1.6335, Val Loss: 1.6466, Best Val Loss: 1.6466\n",
      "Epoch 31/1000, Train Loss: 1.6178, Val Loss: 1.6373, Best Val Loss: 1.6373\n",
      "Epoch 32/1000, Train Loss: 1.6126, Val Loss: 1.6118, Best Val Loss: 1.6118\n",
      "Epoch 35/1000, Train Loss: 1.5985, Val Loss: 1.5989, Best Val Loss: 1.5989\n",
      "Epoch 46/1000, Train Loss: 1.5554, Val Loss: 1.5798, Best Val Loss: 1.5798\n",
      "Epoch 53/1000, Train Loss: 1.5369, Val Loss: 1.5593, Best Val Loss: 1.5593\n",
      "Epoch 56/1000, Train Loss: 1.5183, Val Loss: 1.5528, Best Val Loss: 1.5528\n",
      "Epoch 62/1000, Train Loss: 1.4986, Val Loss: 1.5082, Best Val Loss: 1.5082\n",
      "Epoch 84/1000, Train Loss: 1.4559, Val Loss: 1.4932, Best Val Loss: 1.4932\n",
      "Epoch 98/1000, Train Loss: 1.4209, Val Loss: 1.4757, Best Val Loss: 1.4757\n",
      "Epoch 111/1000, Train Loss: 1.4075, Val Loss: 1.4755, Best Val Loss: 1.4755\n",
      "Early stopping at epoch 161, Best Val Loss: 1.4755\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 136.0681, Val Loss: 5.5166, Best Val Loss: 5.5166\n",
      "Epoch 2/1000, Train Loss: 5.4717, Val Loss: 5.4300, Best Val Loss: 5.4300\n",
      "Epoch 3/1000, Train Loss: 5.3959, Val Loss: 5.3616, Best Val Loss: 5.3616\n",
      "Epoch 4/1000, Train Loss: 5.3300, Val Loss: 5.2981, Best Val Loss: 5.2981\n",
      "Epoch 5/1000, Train Loss: 5.2583, Val Loss: 5.2105, Best Val Loss: 5.2105\n",
      "Epoch 6/1000, Train Loss: 5.1009, Val Loss: 4.9166, Best Val Loss: 4.9166\n",
      "Epoch 7/1000, Train Loss: 3.6637, Val Loss: 2.4311, Best Val Loss: 2.4311\n",
      "Epoch 8/1000, Train Loss: 2.3013, Val Loss: 2.2142, Best Val Loss: 2.2142\n",
      "Epoch 9/1000, Train Loss: 2.1166, Val Loss: 2.0726, Best Val Loss: 2.0726\n",
      "Epoch 10/1000, Train Loss: 1.9951, Val Loss: 1.9630, Best Val Loss: 1.9630\n",
      "Epoch 11/1000, Train Loss: 1.9182, Val Loss: 1.8829, Best Val Loss: 1.8829\n",
      "Epoch 12/1000, Train Loss: 1.8701, Val Loss: 1.8554, Best Val Loss: 1.8554\n",
      "Epoch 14/1000, Train Loss: 1.7993, Val Loss: 1.7911, Best Val Loss: 1.7911\n",
      "Epoch 15/1000, Train Loss: 1.7747, Val Loss: 1.7792, Best Val Loss: 1.7792\n",
      "Epoch 16/1000, Train Loss: 1.7606, Val Loss: 1.7317, Best Val Loss: 1.7317\n",
      "Epoch 17/1000, Train Loss: 1.7402, Val Loss: 1.7177, Best Val Loss: 1.7177\n",
      "Epoch 21/1000, Train Loss: 1.7078, Val Loss: 1.6855, Best Val Loss: 1.6855\n",
      "Epoch 25/1000, Train Loss: 1.6734, Val Loss: 1.6710, Best Val Loss: 1.6710\n",
      "Epoch 30/1000, Train Loss: 1.6324, Val Loss: 1.6423, Best Val Loss: 1.6423\n",
      "Epoch 31/1000, Train Loss: 1.6424, Val Loss: 1.6365, Best Val Loss: 1.6365\n",
      "Epoch 36/1000, Train Loss: 1.6050, Val Loss: 1.5872, Best Val Loss: 1.5872\n",
      "Epoch 42/1000, Train Loss: 1.5753, Val Loss: 1.5756, Best Val Loss: 1.5756\n",
      "Epoch 43/1000, Train Loss: 1.5724, Val Loss: 1.5754, Best Val Loss: 1.5754\n",
      "Epoch 53/1000, Train Loss: 1.5328, Val Loss: 1.5477, Best Val Loss: 1.5477\n",
      "Epoch 58/1000, Train Loss: 1.5197, Val Loss: 1.5411, Best Val Loss: 1.5411\n",
      "Epoch 67/1000, Train Loss: 1.4949, Val Loss: 1.5329, Best Val Loss: 1.5329\n",
      "Epoch 68/1000, Train Loss: 1.4875, Val Loss: 1.5203, Best Val Loss: 1.5203\n",
      "Epoch 71/1000, Train Loss: 1.4808, Val Loss: 1.5186, Best Val Loss: 1.5186\n",
      "Epoch 72/1000, Train Loss: 1.4825, Val Loss: 1.5152, Best Val Loss: 1.5152\n",
      "Epoch 77/1000, Train Loss: 1.4668, Val Loss: 1.5053, Best Val Loss: 1.5053\n",
      "Epoch 79/1000, Train Loss: 1.4688, Val Loss: 1.5053, Best Val Loss: 1.5053\n",
      "Epoch 85/1000, Train Loss: 1.4453, Val Loss: 1.4947, Best Val Loss: 1.4947\n",
      "Epoch 116/1000, Train Loss: 1.4047, Val Loss: 1.4908, Best Val Loss: 1.4908\n",
      "Epoch 118/1000, Train Loss: 1.4037, Val Loss: 1.4799, Best Val Loss: 1.4799\n",
      "Epoch 120/1000, Train Loss: 1.4016, Val Loss: 1.4781, Best Val Loss: 1.4781\n",
      "Epoch 136/1000, Train Loss: 1.3865, Val Loss: 1.4640, Best Val Loss: 1.4640\n",
      "Early stopping at epoch 186, Best Val Loss: 1.4640\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 155.8700, Val Loss: 5.5282, Best Val Loss: 5.5282\n",
      "Epoch 2/1000, Train Loss: 5.4919, Val Loss: 5.4471, Best Val Loss: 5.4471\n",
      "Epoch 3/1000, Train Loss: 5.4167, Val Loss: 5.3760, Best Val Loss: 5.3760\n",
      "Epoch 4/1000, Train Loss: 5.3457, Val Loss: 5.3070, Best Val Loss: 5.3070\n",
      "Epoch 5/1000, Train Loss: 5.2741, Val Loss: 5.2338, Best Val Loss: 5.2338\n",
      "Epoch 6/1000, Train Loss: 5.1823, Val Loss: 5.1058, Best Val Loss: 5.1058\n",
      "Epoch 7/1000, Train Loss: 4.4191, Val Loss: 2.4886, Best Val Loss: 2.4886\n",
      "Epoch 8/1000, Train Loss: 2.3027, Val Loss: 2.2030, Best Val Loss: 2.2030\n",
      "Epoch 9/1000, Train Loss: 2.0907, Val Loss: 2.0482, Best Val Loss: 2.0482\n",
      "Epoch 10/1000, Train Loss: 1.9787, Val Loss: 1.9346, Best Val Loss: 1.9346\n",
      "Epoch 11/1000, Train Loss: 1.9098, Val Loss: 1.8906, Best Val Loss: 1.8906\n",
      "Epoch 12/1000, Train Loss: 1.8581, Val Loss: 1.8301, Best Val Loss: 1.8301\n",
      "Epoch 13/1000, Train Loss: 1.8196, Val Loss: 1.8050, Best Val Loss: 1.8050\n",
      "Epoch 14/1000, Train Loss: 1.7939, Val Loss: 1.7681, Best Val Loss: 1.7681\n",
      "Epoch 16/1000, Train Loss: 1.7497, Val Loss: 1.7491, Best Val Loss: 1.7491\n",
      "Epoch 18/1000, Train Loss: 1.7158, Val Loss: 1.6969, Best Val Loss: 1.6969\n",
      "Epoch 20/1000, Train Loss: 1.6988, Val Loss: 1.6718, Best Val Loss: 1.6718\n",
      "Epoch 25/1000, Train Loss: 1.6542, Val Loss: 1.6605, Best Val Loss: 1.6605\n",
      "Epoch 26/1000, Train Loss: 1.6373, Val Loss: 1.6589, Best Val Loss: 1.6589\n",
      "Epoch 27/1000, Train Loss: 1.6306, Val Loss: 1.6385, Best Val Loss: 1.6385\n",
      "Epoch 29/1000, Train Loss: 1.6234, Val Loss: 1.6197, Best Val Loss: 1.6197\n",
      "Epoch 31/1000, Train Loss: 1.6008, Val Loss: 1.6024, Best Val Loss: 1.6024\n",
      "Epoch 37/1000, Train Loss: 1.5734, Val Loss: 1.5858, Best Val Loss: 1.5858\n",
      "Epoch 41/1000, Train Loss: 1.5413, Val Loss: 1.5607, Best Val Loss: 1.5607\n",
      "Epoch 50/1000, Train Loss: 1.5234, Val Loss: 1.5337, Best Val Loss: 1.5337\n",
      "Epoch 59/1000, Train Loss: 1.4849, Val Loss: 1.5189, Best Val Loss: 1.5189\n",
      "Epoch 60/1000, Train Loss: 1.4851, Val Loss: 1.5171, Best Val Loss: 1.5171\n",
      "Epoch 68/1000, Train Loss: 1.4631, Val Loss: 1.5112, Best Val Loss: 1.5112\n",
      "Epoch 71/1000, Train Loss: 1.4633, Val Loss: 1.4922, Best Val Loss: 1.4922\n",
      "Epoch 81/1000, Train Loss: 1.4392, Val Loss: 1.4888, Best Val Loss: 1.4888\n",
      "Epoch 85/1000, Train Loss: 1.4289, Val Loss: 1.4822, Best Val Loss: 1.4822\n",
      "Epoch 106/1000, Train Loss: 1.4021, Val Loss: 1.4778, Best Val Loss: 1.4778\n",
      "Epoch 110/1000, Train Loss: 1.3998, Val Loss: 1.4757, Best Val Loss: 1.4757\n",
      "Epoch 121/1000, Train Loss: 1.3739, Val Loss: 1.4718, Best Val Loss: 1.4718\n",
      "Epoch 124/1000, Train Loss: 1.3739, Val Loss: 1.4607, Best Val Loss: 1.4607\n",
      "Early stopping at epoch 174, Best Val Loss: 1.4607\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 149.0918, Val Loss: 5.5321, Best Val Loss: 5.5321\n",
      "Epoch 2/1000, Train Loss: 5.4665, Val Loss: 5.4007, Best Val Loss: 5.4007\n",
      "Epoch 3/1000, Train Loss: 5.2780, Val Loss: 5.0506, Best Val Loss: 5.0506\n",
      "Epoch 4/1000, Train Loss: 3.9500, Val Loss: 2.6507, Best Val Loss: 2.6507\n",
      "Epoch 5/1000, Train Loss: 2.4823, Val Loss: 2.3550, Best Val Loss: 2.3550\n",
      "Epoch 6/1000, Train Loss: 2.2563, Val Loss: 2.1852, Best Val Loss: 2.1852\n",
      "Epoch 7/1000, Train Loss: 2.1056, Val Loss: 2.0652, Best Val Loss: 2.0652\n",
      "Epoch 8/1000, Train Loss: 1.9959, Val Loss: 1.9611, Best Val Loss: 1.9611\n",
      "Epoch 9/1000, Train Loss: 1.9147, Val Loss: 1.8893, Best Val Loss: 1.8893\n",
      "Epoch 11/1000, Train Loss: 1.8164, Val Loss: 1.7953, Best Val Loss: 1.7953\n",
      "Epoch 14/1000, Train Loss: 1.7573, Val Loss: 1.7731, Best Val Loss: 1.7731\n",
      "Epoch 15/1000, Train Loss: 1.7366, Val Loss: 1.7670, Best Val Loss: 1.7670\n",
      "Epoch 16/1000, Train Loss: 1.7328, Val Loss: 1.7456, Best Val Loss: 1.7456\n",
      "Epoch 17/1000, Train Loss: 1.7095, Val Loss: 1.7143, Best Val Loss: 1.7143\n",
      "Epoch 20/1000, Train Loss: 1.6931, Val Loss: 1.7065, Best Val Loss: 1.7065\n",
      "Epoch 21/1000, Train Loss: 1.6751, Val Loss: 1.6628, Best Val Loss: 1.6628\n",
      "Epoch 22/1000, Train Loss: 1.6805, Val Loss: 1.6556, Best Val Loss: 1.6556\n",
      "Epoch 28/1000, Train Loss: 1.6240, Val Loss: 1.6475, Best Val Loss: 1.6475\n",
      "Epoch 29/1000, Train Loss: 1.6338, Val Loss: 1.6111, Best Val Loss: 1.6111\n",
      "Epoch 31/1000, Train Loss: 1.6236, Val Loss: 1.6072, Best Val Loss: 1.6072\n",
      "Epoch 37/1000, Train Loss: 1.5827, Val Loss: 1.5677, Best Val Loss: 1.5677\n",
      "Epoch 43/1000, Train Loss: 1.5506, Val Loss: 1.5617, Best Val Loss: 1.5617\n",
      "Epoch 55/1000, Train Loss: 1.5172, Val Loss: 1.5589, Best Val Loss: 1.5589\n",
      "Epoch 57/1000, Train Loss: 1.5172, Val Loss: 1.5520, Best Val Loss: 1.5520\n",
      "Epoch 58/1000, Train Loss: 1.5034, Val Loss: 1.5428, Best Val Loss: 1.5428\n",
      "Epoch 59/1000, Train Loss: 1.5112, Val Loss: 1.5247, Best Val Loss: 1.5247\n",
      "Epoch 64/1000, Train Loss: 1.4891, Val Loss: 1.5101, Best Val Loss: 1.5101\n",
      "Epoch 71/1000, Train Loss: 1.4815, Val Loss: 1.4876, Best Val Loss: 1.4876\n",
      "Epoch 98/1000, Train Loss: 1.4380, Val Loss: 1.4735, Best Val Loss: 1.4735\n",
      "Epoch 104/1000, Train Loss: 1.4202, Val Loss: 1.4694, Best Val Loss: 1.4694\n",
      "Epoch 120/1000, Train Loss: 1.3970, Val Loss: 1.4655, Best Val Loss: 1.4655\n",
      "Epoch 123/1000, Train Loss: 1.3869, Val Loss: 1.4585, Best Val Loss: 1.4585\n",
      "Epoch 150/1000, Train Loss: 1.3569, Val Loss: 1.4471, Best Val Loss: 1.4471\n",
      "Early stopping at epoch 200, Best Val Loss: 1.4471\n",
      "Epistemic Variance: 1.062888\n",
      "Aleatoric Variance: 8.562996\n",
      " (1/n) Calculating accuracy metrics\n",
      " (2/n) Calculating average calibration metrics\n",
      " (3/n) Calculating adversarial group calibration metrics\n",
      "  [1/2] for mean absolute calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [2/2] for root mean squared calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (4/n) Calculating sharpness metrics\n",
      " (n/n) Calculating proper scoring rule metrics\n",
      "**Finished Calculating All Metrics**\n",
      "\n",
      "\n",
      "===================== Accuracy Metrics =====================\n",
      "  MAE           2.002\n",
      "  RMSE          2.835\n",
      "  MDAE          1.488\n",
      "  MARPD         1.748\n",
      "  R2            0.859\n",
      "  Correlation   0.927\n",
      "=============== Average Calibration Metrics ================\n",
      "  Root-mean-squared Calibration Error   0.056\n",
      "  Mean-absolute Calibration Error       0.049\n",
      "  Miscalibration Area                   0.050\n",
      "========== Adversarial Group Calibration Metrics ===========\n",
      "  Mean-absolute Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.060\n",
      "     Group Size: 0.56 -- Calibration Error: 0.053\n",
      "     Group Size: 1.00 -- Calibration Error: 0.049\n",
      "  Root-mean-squared Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.068\n",
      "     Group Size: 0.56 -- Calibration Error: 0.060\n",
      "     Group Size: 1.00 -- Calibration Error: 0.056\n",
      "==================== Sharpness Metrics =====================\n",
      "  Sharpness   3.103\n",
      "=================== Scoring Rule Metrics ===================\n",
      "  Negative-log-likelihood   2.308\n",
      "  CRPS                      1.439\n",
      "  Check Score               0.726\n",
      "  Interval Score            7.231\n",
      "{'accuracy': {'mae': 2.002245351507819, 'rmse': np.float64(2.8345774111503172), 'mdae': 1.4884895263671893, 'marpd': np.float64(1.7482938314818661), 'r2': 0.8592881031088279, 'corr': np.float64(0.9270416616514542)}, 'avg_calibration': {'rms_cal': np.float64(0.05558319477866588), 'ma_cal': np.float64(0.04918965682976061), 'miscal_area': np.float64(0.04968652205026324)}, 'adv_group_calibration': {'ma_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.38697475, 0.06013439, 0.05824183, 0.0547757 , 0.05389836,\n",
      "       0.05312857, 0.05243129, 0.05138945, 0.05062409, 0.04918966]), 'adv_group_cali_stderr': array([0.0513166 , 0.00397666, 0.00298457, 0.00353275, 0.00170636,\n",
      "       0.00153221, 0.00081974, 0.00077715, 0.0003225 , 0.        ])}, 'rms_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.44040378, 0.06839682, 0.06408941, 0.06141868, 0.06131169,\n",
      "       0.05982098, 0.05885718, 0.05805729, 0.05701867, 0.05558319]), 'adv_group_cali_stderr': array([0.04872949, 0.00300247, 0.00346317, 0.00339922, 0.00307647,\n",
      "       0.00174888, 0.00095905, 0.00065121, 0.0005797 , 0.        ])}}, 'sharpness': {'sharp': np.float32(3.102561)}, 'scoring_rule': {'nll': np.float64(2.3084278103554716), 'crps': np.float64(1.438561657426977), 'check': np.float64(0.7263557890662778), 'interval': np.float64(7.231437432069968)}}\n",
      "coverage: 0.9673171200615207, MPIW: 11.18751369228199\n",
      "Run 10 with seed 54321\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 152.4131, Val Loss: 5.4973, Best Val Loss: 5.4973\n",
      "Epoch 2/1000, Train Loss: 5.4104, Val Loss: 5.3215, Best Val Loss: 5.3215\n",
      "Epoch 3/1000, Train Loss: 5.1926, Val Loss: 4.9797, Best Val Loss: 4.9797\n",
      "Epoch 4/1000, Train Loss: 3.7707, Val Loss: 2.7194, Best Val Loss: 2.7194\n",
      "Epoch 5/1000, Train Loss: 2.5363, Val Loss: 2.3971, Best Val Loss: 2.3971\n",
      "Epoch 6/1000, Train Loss: 2.2746, Val Loss: 2.1909, Best Val Loss: 2.1909\n",
      "Epoch 7/1000, Train Loss: 2.1028, Val Loss: 2.0503, Best Val Loss: 2.0503\n",
      "Epoch 8/1000, Train Loss: 1.9975, Val Loss: 1.9679, Best Val Loss: 1.9679\n",
      "Epoch 9/1000, Train Loss: 1.9177, Val Loss: 1.8769, Best Val Loss: 1.8769\n",
      "Epoch 12/1000, Train Loss: 1.7952, Val Loss: 1.8083, Best Val Loss: 1.8083\n",
      "Epoch 13/1000, Train Loss: 1.7733, Val Loss: 1.7581, Best Val Loss: 1.7581\n",
      "Epoch 14/1000, Train Loss: 1.7434, Val Loss: 1.7503, Best Val Loss: 1.7503\n",
      "Epoch 15/1000, Train Loss: 1.7348, Val Loss: 1.7352, Best Val Loss: 1.7352\n",
      "Epoch 16/1000, Train Loss: 1.7079, Val Loss: 1.6967, Best Val Loss: 1.6967\n",
      "Epoch 21/1000, Train Loss: 1.6599, Val Loss: 1.6627, Best Val Loss: 1.6627\n",
      "Epoch 25/1000, Train Loss: 1.6361, Val Loss: 1.6332, Best Val Loss: 1.6332\n",
      "Epoch 30/1000, Train Loss: 1.6213, Val Loss: 1.6303, Best Val Loss: 1.6303\n",
      "Epoch 32/1000, Train Loss: 1.6022, Val Loss: 1.6084, Best Val Loss: 1.6084\n",
      "Epoch 37/1000, Train Loss: 1.5689, Val Loss: 1.5926, Best Val Loss: 1.5926\n",
      "Epoch 39/1000, Train Loss: 1.5633, Val Loss: 1.5770, Best Val Loss: 1.5770\n",
      "Epoch 43/1000, Train Loss: 1.5366, Val Loss: 1.5541, Best Val Loss: 1.5541\n",
      "Epoch 52/1000, Train Loss: 1.5093, Val Loss: 1.5287, Best Val Loss: 1.5287\n",
      "Epoch 61/1000, Train Loss: 1.4836, Val Loss: 1.5184, Best Val Loss: 1.5184\n",
      "Epoch 64/1000, Train Loss: 1.4781, Val Loss: 1.5135, Best Val Loss: 1.5135\n",
      "Epoch 70/1000, Train Loss: 1.4633, Val Loss: 1.5087, Best Val Loss: 1.5087\n",
      "Epoch 72/1000, Train Loss: 1.4626, Val Loss: 1.4880, Best Val Loss: 1.4880\n",
      "Epoch 84/1000, Train Loss: 1.4343, Val Loss: 1.4851, Best Val Loss: 1.4851\n",
      "Epoch 106/1000, Train Loss: 1.3927, Val Loss: 1.4675, Best Val Loss: 1.4675\n",
      "Early stopping at epoch 156, Best Val Loss: 1.4675\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 146.0775, Val Loss: 5.4760, Best Val Loss: 5.4760\n",
      "Epoch 2/1000, Train Loss: 5.4396, Val Loss: 5.3977, Best Val Loss: 5.3977\n",
      "Epoch 3/1000, Train Loss: 5.3660, Val Loss: 5.3297, Best Val Loss: 5.3297\n",
      "Epoch 4/1000, Train Loss: 5.2976, Val Loss: 5.2646, Best Val Loss: 5.2646\n",
      "Epoch 5/1000, Train Loss: 5.2290, Val Loss: 5.1900, Best Val Loss: 5.1900\n",
      "Epoch 6/1000, Train Loss: 5.1239, Val Loss: 5.0257, Best Val Loss: 5.0257\n",
      "Epoch 7/1000, Train Loss: 3.9331, Val Loss: 2.3822, Best Val Loss: 2.3822\n",
      "Epoch 8/1000, Train Loss: 2.2247, Val Loss: 2.1251, Best Val Loss: 2.1251\n",
      "Epoch 9/1000, Train Loss: 2.0386, Val Loss: 1.9758, Best Val Loss: 1.9758\n",
      "Epoch 10/1000, Train Loss: 1.9364, Val Loss: 1.9149, Best Val Loss: 1.9149\n",
      "Epoch 11/1000, Train Loss: 1.8751, Val Loss: 1.8834, Best Val Loss: 1.8834\n",
      "Epoch 12/1000, Train Loss: 1.8279, Val Loss: 1.8110, Best Val Loss: 1.8110\n",
      "Epoch 13/1000, Train Loss: 1.7973, Val Loss: 1.7856, Best Val Loss: 1.7856\n",
      "Epoch 14/1000, Train Loss: 1.7713, Val Loss: 1.7716, Best Val Loss: 1.7716\n",
      "Epoch 15/1000, Train Loss: 1.7540, Val Loss: 1.7536, Best Val Loss: 1.7536\n",
      "Epoch 16/1000, Train Loss: 1.7334, Val Loss: 1.7451, Best Val Loss: 1.7451\n",
      "Epoch 18/1000, Train Loss: 1.7076, Val Loss: 1.7398, Best Val Loss: 1.7398\n",
      "Epoch 19/1000, Train Loss: 1.6953, Val Loss: 1.7127, Best Val Loss: 1.7127\n",
      "Epoch 21/1000, Train Loss: 1.6747, Val Loss: 1.6839, Best Val Loss: 1.6839\n",
      "Epoch 22/1000, Train Loss: 1.6649, Val Loss: 1.6645, Best Val Loss: 1.6645\n",
      "Epoch 23/1000, Train Loss: 1.6552, Val Loss: 1.6418, Best Val Loss: 1.6418\n",
      "Epoch 27/1000, Train Loss: 1.6336, Val Loss: 1.6217, Best Val Loss: 1.6217\n",
      "Epoch 28/1000, Train Loss: 1.6210, Val Loss: 1.6201, Best Val Loss: 1.6201\n",
      "Epoch 35/1000, Train Loss: 1.5848, Val Loss: 1.6171, Best Val Loss: 1.6171\n",
      "Epoch 36/1000, Train Loss: 1.5788, Val Loss: 1.6120, Best Val Loss: 1.6120\n",
      "Epoch 38/1000, Train Loss: 1.5683, Val Loss: 1.6017, Best Val Loss: 1.6017\n",
      "Epoch 40/1000, Train Loss: 1.5591, Val Loss: 1.6008, Best Val Loss: 1.6008\n",
      "Epoch 41/1000, Train Loss: 1.5509, Val Loss: 1.5644, Best Val Loss: 1.5644\n",
      "Epoch 49/1000, Train Loss: 1.5142, Val Loss: 1.5581, Best Val Loss: 1.5581\n",
      "Epoch 52/1000, Train Loss: 1.5056, Val Loss: 1.5446, Best Val Loss: 1.5446\n",
      "Epoch 54/1000, Train Loss: 1.5026, Val Loss: 1.5352, Best Val Loss: 1.5352\n",
      "Epoch 56/1000, Train Loss: 1.4824, Val Loss: 1.5291, Best Val Loss: 1.5291\n",
      "Epoch 57/1000, Train Loss: 1.4859, Val Loss: 1.5276, Best Val Loss: 1.5276\n",
      "Epoch 62/1000, Train Loss: 1.4776, Val Loss: 1.5249, Best Val Loss: 1.5249\n",
      "Epoch 63/1000, Train Loss: 1.4667, Val Loss: 1.4974, Best Val Loss: 1.4974\n",
      "Epoch 76/1000, Train Loss: 1.4394, Val Loss: 1.4859, Best Val Loss: 1.4859\n",
      "Epoch 97/1000, Train Loss: 1.4048, Val Loss: 1.4665, Best Val Loss: 1.4665\n",
      "Epoch 100/1000, Train Loss: 1.3943, Val Loss: 1.4539, Best Val Loss: 1.4539\n",
      "Early stopping at epoch 150, Best Val Loss: 1.4539\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 126.4248, Val Loss: 5.4964, Best Val Loss: 5.4964\n",
      "Epoch 2/1000, Train Loss: 5.4576, Val Loss: 5.4176, Best Val Loss: 5.4176\n",
      "Epoch 3/1000, Train Loss: 5.3856, Val Loss: 5.3495, Best Val Loss: 5.3495\n",
      "Epoch 4/1000, Train Loss: 5.3170, Val Loss: 5.2833, Best Val Loss: 5.2833\n",
      "Epoch 5/1000, Train Loss: 5.2476, Val Loss: 5.2095, Best Val Loss: 5.2095\n",
      "Epoch 6/1000, Train Loss: 5.1469, Val Loss: 5.0590, Best Val Loss: 5.0590\n",
      "Epoch 7/1000, Train Loss: 4.3259, Val Loss: 2.4461, Best Val Loss: 2.4461\n",
      "Epoch 8/1000, Train Loss: 2.2752, Val Loss: 2.2072, Best Val Loss: 2.2072\n",
      "Epoch 9/1000, Train Loss: 2.0858, Val Loss: 2.0422, Best Val Loss: 2.0422\n",
      "Epoch 10/1000, Train Loss: 1.9747, Val Loss: 1.9449, Best Val Loss: 1.9449\n",
      "Epoch 11/1000, Train Loss: 1.9025, Val Loss: 1.8930, Best Val Loss: 1.8930\n",
      "Epoch 12/1000, Train Loss: 1.8476, Val Loss: 1.8620, Best Val Loss: 1.8620\n",
      "Epoch 13/1000, Train Loss: 1.8159, Val Loss: 1.8171, Best Val Loss: 1.8171\n",
      "Epoch 15/1000, Train Loss: 1.7673, Val Loss: 1.7643, Best Val Loss: 1.7643\n",
      "Epoch 16/1000, Train Loss: 1.7496, Val Loss: 1.7258, Best Val Loss: 1.7258\n",
      "Epoch 20/1000, Train Loss: 1.7061, Val Loss: 1.7030, Best Val Loss: 1.7030\n",
      "Epoch 24/1000, Train Loss: 1.6715, Val Loss: 1.6985, Best Val Loss: 1.6985\n",
      "Epoch 25/1000, Train Loss: 1.6657, Val Loss: 1.6516, Best Val Loss: 1.6516\n",
      "Epoch 29/1000, Train Loss: 1.6429, Val Loss: 1.6198, Best Val Loss: 1.6198\n",
      "Epoch 33/1000, Train Loss: 1.6222, Val Loss: 1.6186, Best Val Loss: 1.6186\n",
      "Epoch 34/1000, Train Loss: 1.6197, Val Loss: 1.6018, Best Val Loss: 1.6018\n",
      "Epoch 38/1000, Train Loss: 1.5937, Val Loss: 1.5734, Best Val Loss: 1.5734\n",
      "Epoch 42/1000, Train Loss: 1.5683, Val Loss: 1.5628, Best Val Loss: 1.5628\n",
      "Epoch 53/1000, Train Loss: 1.5284, Val Loss: 1.5394, Best Val Loss: 1.5394\n",
      "Epoch 55/1000, Train Loss: 1.5250, Val Loss: 1.5310, Best Val Loss: 1.5310\n",
      "Epoch 67/1000, Train Loss: 1.4811, Val Loss: 1.5134, Best Val Loss: 1.5134\n",
      "Epoch 72/1000, Train Loss: 1.4653, Val Loss: 1.5109, Best Val Loss: 1.5109\n",
      "Epoch 73/1000, Train Loss: 1.4692, Val Loss: 1.5081, Best Val Loss: 1.5081\n",
      "Epoch 80/1000, Train Loss: 1.4525, Val Loss: 1.4917, Best Val Loss: 1.4917\n",
      "Epoch 88/1000, Train Loss: 1.4276, Val Loss: 1.4829, Best Val Loss: 1.4829\n",
      "Epoch 97/1000, Train Loss: 1.4144, Val Loss: 1.4649, Best Val Loss: 1.4649\n",
      "Epoch 111/1000, Train Loss: 1.3830, Val Loss: 1.4569, Best Val Loss: 1.4569\n",
      "Epoch 122/1000, Train Loss: 1.3765, Val Loss: 1.4561, Best Val Loss: 1.4561\n",
      "Early stopping at epoch 172, Best Val Loss: 1.4561\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 146.9858, Val Loss: 5.5283, Best Val Loss: 5.5283\n",
      "Epoch 2/1000, Train Loss: 5.3990, Val Loss: 5.2957, Best Val Loss: 5.2957\n",
      "Epoch 3/1000, Train Loss: 5.2424, Val Loss: 5.1832, Best Val Loss: 5.1832\n",
      "Epoch 4/1000, Train Loss: 5.0501, Val Loss: 4.7764, Best Val Loss: 4.7764\n",
      "Epoch 5/1000, Train Loss: 3.3445, Val Loss: 2.5178, Best Val Loss: 2.5178\n",
      "Epoch 6/1000, Train Loss: 2.3426, Val Loss: 2.2378, Best Val Loss: 2.2378\n",
      "Epoch 7/1000, Train Loss: 2.1263, Val Loss: 2.0592, Best Val Loss: 2.0592\n",
      "Epoch 8/1000, Train Loss: 2.0106, Val Loss: 1.9641, Best Val Loss: 1.9641\n",
      "Epoch 9/1000, Train Loss: 1.9299, Val Loss: 1.9403, Best Val Loss: 1.9403\n",
      "Epoch 10/1000, Train Loss: 1.8691, Val Loss: 1.8440, Best Val Loss: 1.8440\n",
      "Epoch 11/1000, Train Loss: 1.8297, Val Loss: 1.8204, Best Val Loss: 1.8204\n",
      "Epoch 12/1000, Train Loss: 1.8044, Val Loss: 1.7902, Best Val Loss: 1.7902\n",
      "Epoch 13/1000, Train Loss: 1.7817, Val Loss: 1.7798, Best Val Loss: 1.7798\n",
      "Epoch 14/1000, Train Loss: 1.7595, Val Loss: 1.7365, Best Val Loss: 1.7365\n",
      "Epoch 17/1000, Train Loss: 1.7168, Val Loss: 1.7000, Best Val Loss: 1.7000\n",
      "Epoch 20/1000, Train Loss: 1.6886, Val Loss: 1.6993, Best Val Loss: 1.6993\n",
      "Epoch 24/1000, Train Loss: 1.6559, Val Loss: 1.6444, Best Val Loss: 1.6444\n",
      "Epoch 26/1000, Train Loss: 1.6516, Val Loss: 1.6173, Best Val Loss: 1.6173\n",
      "Epoch 31/1000, Train Loss: 1.6101, Val Loss: 1.5984, Best Val Loss: 1.5984\n",
      "Epoch 32/1000, Train Loss: 1.6014, Val Loss: 1.5922, Best Val Loss: 1.5922\n",
      "Epoch 39/1000, Train Loss: 1.5719, Val Loss: 1.5922, Best Val Loss: 1.5922\n",
      "Epoch 43/1000, Train Loss: 1.5505, Val Loss: 1.5861, Best Val Loss: 1.5861\n",
      "Epoch 45/1000, Train Loss: 1.5371, Val Loss: 1.5780, Best Val Loss: 1.5780\n",
      "Epoch 50/1000, Train Loss: 1.5215, Val Loss: 1.5342, Best Val Loss: 1.5342\n",
      "Epoch 62/1000, Train Loss: 1.4819, Val Loss: 1.5297, Best Val Loss: 1.5297\n",
      "Epoch 65/1000, Train Loss: 1.4765, Val Loss: 1.5209, Best Val Loss: 1.5209\n",
      "Epoch 67/1000, Train Loss: 1.4625, Val Loss: 1.5205, Best Val Loss: 1.5205\n",
      "Epoch 74/1000, Train Loss: 1.4435, Val Loss: 1.5124, Best Val Loss: 1.5124\n",
      "Epoch 77/1000, Train Loss: 1.4471, Val Loss: 1.5102, Best Val Loss: 1.5102\n",
      "Epoch 81/1000, Train Loss: 1.4348, Val Loss: 1.5072, Best Val Loss: 1.5072\n",
      "Epoch 85/1000, Train Loss: 1.4173, Val Loss: 1.4914, Best Val Loss: 1.4914\n",
      "Epoch 86/1000, Train Loss: 1.4253, Val Loss: 1.4848, Best Val Loss: 1.4848\n",
      "Epoch 95/1000, Train Loss: 1.4056, Val Loss: 1.4781, Best Val Loss: 1.4781\n",
      "Epoch 96/1000, Train Loss: 1.4081, Val Loss: 1.4685, Best Val Loss: 1.4685\n",
      "Early stopping at epoch 146, Best Val Loss: 1.4685\n",
      "Using device: cuda\n",
      "Epoch 1/1000, Train Loss: 164.6082, Val Loss: 5.4890, Best Val Loss: 5.4890\n",
      "Epoch 2/1000, Train Loss: 5.4259, Val Loss: 5.3738, Best Val Loss: 5.3738\n",
      "Epoch 3/1000, Train Loss: 5.3381, Val Loss: 5.2973, Best Val Loss: 5.2973\n",
      "Epoch 4/1000, Train Loss: 5.2605, Val Loss: 5.2174, Best Val Loss: 5.2174\n",
      "Epoch 5/1000, Train Loss: 5.1497, Val Loss: 5.0421, Best Val Loss: 5.0421\n",
      "Epoch 6/1000, Train Loss: 3.9402, Val Loss: 2.4329, Best Val Loss: 2.4329\n",
      "Epoch 7/1000, Train Loss: 2.2445, Val Loss: 2.1191, Best Val Loss: 2.1191\n",
      "Epoch 8/1000, Train Loss: 2.0453, Val Loss: 2.0039, Best Val Loss: 2.0039\n",
      "Epoch 9/1000, Train Loss: 1.9464, Val Loss: 1.9239, Best Val Loss: 1.9239\n",
      "Epoch 10/1000, Train Loss: 1.8794, Val Loss: 1.8630, Best Val Loss: 1.8630\n",
      "Epoch 11/1000, Train Loss: 1.8333, Val Loss: 1.8486, Best Val Loss: 1.8486\n",
      "Epoch 12/1000, Train Loss: 1.7977, Val Loss: 1.8070, Best Val Loss: 1.8070\n",
      "Epoch 14/1000, Train Loss: 1.7495, Val Loss: 1.7782, Best Val Loss: 1.7782\n",
      "Epoch 15/1000, Train Loss: 1.7385, Val Loss: 1.7389, Best Val Loss: 1.7389\n",
      "Epoch 17/1000, Train Loss: 1.7139, Val Loss: 1.7188, Best Val Loss: 1.7188\n",
      "Epoch 18/1000, Train Loss: 1.6987, Val Loss: 1.7057, Best Val Loss: 1.7057\n",
      "Epoch 20/1000, Train Loss: 1.6765, Val Loss: 1.6951, Best Val Loss: 1.6951\n",
      "Epoch 21/1000, Train Loss: 1.6690, Val Loss: 1.6537, Best Val Loss: 1.6537\n",
      "Epoch 23/1000, Train Loss: 1.6566, Val Loss: 1.6372, Best Val Loss: 1.6372\n",
      "Epoch 24/1000, Train Loss: 1.6475, Val Loss: 1.6266, Best Val Loss: 1.6266\n",
      "Epoch 26/1000, Train Loss: 1.6442, Val Loss: 1.6238, Best Val Loss: 1.6238\n",
      "Epoch 31/1000, Train Loss: 1.5993, Val Loss: 1.6236, Best Val Loss: 1.6236\n",
      "Epoch 32/1000, Train Loss: 1.5962, Val Loss: 1.6007, Best Val Loss: 1.6007\n",
      "Epoch 34/1000, Train Loss: 1.5787, Val Loss: 1.5834, Best Val Loss: 1.5834\n",
      "Epoch 36/1000, Train Loss: 1.5712, Val Loss: 1.5636, Best Val Loss: 1.5636\n",
      "Epoch 45/1000, Train Loss: 1.5251, Val Loss: 1.5614, Best Val Loss: 1.5614\n",
      "Epoch 46/1000, Train Loss: 1.5308, Val Loss: 1.5598, Best Val Loss: 1.5598\n",
      "Epoch 48/1000, Train Loss: 1.5131, Val Loss: 1.5474, Best Val Loss: 1.5474\n",
      "Epoch 55/1000, Train Loss: 1.4939, Val Loss: 1.5389, Best Val Loss: 1.5389\n",
      "Epoch 61/1000, Train Loss: 1.4689, Val Loss: 1.5110, Best Val Loss: 1.5110\n",
      "Epoch 70/1000, Train Loss: 1.4478, Val Loss: 1.4975, Best Val Loss: 1.4975\n",
      "Epoch 80/1000, Train Loss: 1.4181, Val Loss: 1.4873, Best Val Loss: 1.4873\n",
      "Epoch 87/1000, Train Loss: 1.4069, Val Loss: 1.4670, Best Val Loss: 1.4670\n",
      "Early stopping at epoch 137, Best Val Loss: 1.4670\n",
      "Epistemic Variance: 0.883687\n",
      "Aleatoric Variance: 8.539065\n",
      " (1/n) Calculating accuracy metrics\n",
      " (2/n) Calculating average calibration metrics\n",
      " (3/n) Calculating adversarial group calibration metrics\n",
      "  [1/2] for mean absolute calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [2/2] for root mean squared calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (4/n) Calculating sharpness metrics\n",
      " (n/n) Calculating proper scoring rule metrics\n",
      "**Finished Calculating All Metrics**\n",
      "\n",
      "\n",
      "===================== Accuracy Metrics =====================\n",
      "  MAE           2.000\n",
      "  RMSE          2.804\n",
      "  MDAE          1.498\n",
      "  MARPD         1.746\n",
      "  R2            0.862\n",
      "  Correlation   0.929\n",
      "=============== Average Calibration Metrics ================\n",
      "  Root-mean-squared Calibration Error   0.034\n",
      "  Mean-absolute Calibration Error       0.030\n",
      "  Miscalibration Area                   0.030\n",
      "========== Adversarial Group Calibration Metrics ===========\n",
      "  Mean-absolute Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.041\n",
      "     Group Size: 0.56 -- Calibration Error: 0.033\n",
      "     Group Size: 1.00 -- Calibration Error: 0.030\n",
      "  Root-mean-squared Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.051\n",
      "     Group Size: 0.56 -- Calibration Error: 0.039\n",
      "     Group Size: 1.00 -- Calibration Error: 0.034\n",
      "==================== Sharpness Metrics =====================\n",
      "  Sharpness   3.070\n",
      "=================== Scoring Rule Metrics ===================\n",
      "  Negative-log-likelihood   2.287\n",
      "  CRPS                      1.430\n",
      "  Check Score               0.722\n",
      "  Interval Score            7.155\n",
      "{'accuracy': {'mae': 2.000357220558138, 'rmse': np.float64(2.804365292208052), 'mdae': 1.4979763671875048, 'marpd': np.float64(1.7458260402008459), 'r2': 0.8622716511926961, 'corr': np.float64(0.9289494033230589)}, 'avg_calibration': {'rms_cal': np.float64(0.03353264538314034), 'ma_cal': np.float64(0.029502872617358785), 'miscal_area': np.float64(0.029792291844238053)}, 'adv_group_calibration': {'ma_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.33657576, 0.04091656, 0.03878122, 0.03648396, 0.0337211 ,\n",
      "       0.0330841 , 0.0320073 , 0.03181464, 0.0310446 , 0.02950287]), 'adv_group_cali_stderr': array([6.27262914e-02, 4.19769565e-03, 2.92451592e-03, 1.97986875e-03,\n",
      "       1.77260800e-03, 9.33724881e-04, 9.66312851e-04, 7.03263147e-04,\n",
      "       5.39564710e-04, 3.65711820e-18])}, 'rms_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.40850285, 0.05072484, 0.04288856, 0.04112198, 0.03922002,\n",
      "       0.03901502, 0.03641525, 0.03623458, 0.03516878, 0.03353265]), 'adv_group_cali_stderr': array([0.06658946, 0.00886003, 0.00367999, 0.00228225, 0.00258743,\n",
      "       0.00188458, 0.00123757, 0.00078242, 0.00044609, 0.        ])}}, 'sharpness': {'sharp': np.float32(3.0696504)}, 'scoring_rule': {'nll': np.float64(2.2872669730478723), 'crps': np.float64(1.4295357139213063), 'check': np.float64(0.7218040163903423), 'interval': np.float64(7.154689907372937)}}\n",
      "coverage: 0.9562626165529174, MPIW: 10.516738976388988\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "predictions_list = []\n",
    "list_of_seeds = [42, 123, 777, 2024, 5250, 8888, 9876, 10001, 31415, 54321]\n",
    "DE_prediction_path = r\"C:\\Users\\test\\Masterarbeit\\models\\Modelresults\\Deep Ensembles\"\n",
    "DE_result_path = r\"C:\\Users\\test\\OneDrive\\Master Management und Engineering\\Masterarbeit\\Experimente\\Evaluation\\10 Runs\\Deep Ensembles\"\n",
    "\n",
    "for run, seed in enumerate(list_of_seeds):\n",
    "\n",
    "    print(f\"Run {run+1} with seed {seed}\")\n",
    "    set_seed(seed)\n",
    "\n",
    "    #create an ensemble of 5 networks with the defined net architecture and optimizer\n",
    "    nets_ops = create_ensemble(5, input_dim = X_train.shape[1], hidden_dims=[320,224,156], \n",
    "                            do_rate=0, loss_type='heteroscedastic', lr=0.0004, weight_decay=0.0001)\n",
    "\n",
    "    # lists to store the output means and log variances of each network in the ensemble\n",
    "    outputs_mean = []\n",
    "    outputs_log_var = []\n",
    "\n",
    "    #train the ensemble of networks and make predictions on the test set\n",
    "    for net, ops in nets_ops:\n",
    "        model = train_model(model= net, X_train_tensor=X_train_tensor, y_train_tensor=y_train_tensor,\n",
    "                            X_val_tensor= X_val_tensor, y_val_tensor=y_val_tensor, batch_size=64, \n",
    "                            optimizer=ops, n_epochs=1000, patience=50, loss_type='heteroscedastic',\n",
    "                            )\n",
    "\n",
    "        # set the model to evaluation mode and make predictions on the test set\n",
    "        model.eval()   \n",
    "        with torch.no_grad():\n",
    "            output_mean, output_log_var = model(X_test_tensor.to(device))\n",
    "            # Detach and convert to numpy arrays\n",
    "            output_mean_np, output_log_var_np = output_mean.detach().cpu().numpy(), output_log_var.detach().cpu().numpy()\n",
    "            outputs_mean.append(output_mean_np)\n",
    "            outputs_log_var.append(np.exp(output_log_var_np))\n",
    "\n",
    "    outputs_mean = np.array(outputs_mean)\n",
    "    outputs_log_var = np.array(outputs_log_var)\n",
    "\n",
    "    # Calculate the mean and standard deviation of the predictions on the test data\n",
    "    DE_mean = np.mean(outputs_mean, axis = 0).reshape(-1) # reshape to 1D array\n",
    "\n",
    "    # Calculate epistemic\n",
    "    DE_epistemic_var_heteroscedastic = np.var(outputs_mean, axis=0)\n",
    "    print(f\"Epistemic Variance: {DE_epistemic_var_heteroscedastic.mean():.6f}\")\n",
    "\n",
    "    # Calculate aleatoric variance (heteroscedastic)\n",
    "    DE_aleatoric_var_heteroscedastic = np.mean(outputs_log_var, axis=0)\n",
    "    print(f\"Aleatoric Variance: {DE_aleatoric_var_heteroscedastic.mean():.6f}\")\n",
    "\n",
    "    # Calculate total standard deviation\n",
    "    DE_std = np.sqrt(DE_epistemic_var_heteroscedastic + DE_aleatoric_var_heteroscedastic).reshape(-1) # reshape to 1D array\n",
    "\n",
    "    # Calculate and print all metrics inclunding RMSE, MAE, R²-Score, NLL, CRPS\n",
    "    pnn_metrics = uct.metrics.get_all_metrics(DE_mean, DE_std, y_test)\n",
    "    print(pnn_metrics)\n",
    "\n",
    "    # use own function to calculate coverage and MPIW\n",
    "    ev_intervals = evaluate_intervals(DE_mean, DE_std, y_test, coverage=0.95)\n",
    "    print(f'coverage: {ev_intervals[\"coverage\"]}, MPIW: {ev_intervals[\"MPIW\"]}')\n",
    "\n",
    "    predictions_per_run = {\n",
    "        'mean_prediction': DE_mean,\n",
    "        'std_prediction': DE_std,\n",
    "    }\n",
    "\n",
    "    results_per_run = {\n",
    "    'RMSE': pnn_metrics['accuracy']['rmse'],\n",
    "    'MAE': pnn_metrics['accuracy']['mae'],\n",
    "    'R2': pnn_metrics['accuracy']['r2'], \n",
    "    'Correlation' : pnn_metrics['accuracy']['corr'],\n",
    "    'NLL': pnn_metrics['scoring_rule']['nll'],\n",
    "    'CRPS': pnn_metrics['scoring_rule']['crps'],\n",
    "    'coverage': ev_intervals[\"coverage\"],\n",
    "    'MPIW': ev_intervals[\"MPIW\"],\n",
    "    }\n",
    "\n",
    "    predictions_list.append(predictions_per_run)\n",
    "    results_list.append(results_per_run)\n",
    "#save the predictions \n",
    "with open(os.path.join(DE_prediction_path, \"DE_predictions_list.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(predictions_list, f)\n",
    "\n",
    "#save the results in an excel file\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df.to_excel(os.path.join(DE_result_path, \"DE_results.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b02d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DE_prediction_path = r\"C:\\Users\\test\\Masterarbeit\\models\\Modelresults\\Deep Ensembles\"\n",
    "DE_result_path = r\"C:\\Users\\test\\OneDrive\\Master Management und Engineering\\Masterarbeit\\Experimente\\Evaluation\\10 Runs\\Deep Ensembles\"\n",
    "with open(os.path.join(DE_prediction_path, \"DE_predictions_list.pkl\"), \"rb\") as f:\n",
    "    predictions_list = pickle.load(f)\n",
    "\n",
    "mean_list = []\n",
    "std_list = []\n",
    "\n",
    "for id, run in enumerate(predictions_list):\n",
    "    # extract mean and std predictions\n",
    "    mean = run['mean_prediction']\n",
    "    std = run['std_prediction']\n",
    "    \n",
    "    # append to lists\n",
    "    mean_list.append(mean)\n",
    "    std_list.append(std)\n",
    "    \n",
    "    # calibration Curve with UCT\n",
    "    uct.viz.plot_calibration(mean, std, y_test)\n",
    "    plt.savefig(os.path.join(DE_result_path, f\"calibration_run_{id+1}.svg\"), format ='svg')\n",
    "    plt.savefig(os.path.join(DE_result_path, f\"calibration_run_{id+1}.png\"), format ='png')\n",
    "    plt.close()\n",
    "\n",
    "    # adversarial group calibration\n",
    "    uct.viz.plot_adversarial_group_calibration(mean, std, y_test)\n",
    "    plt.savefig(os.path.join(DE_result_path, f\"adversarial_group_calibration_run_{id+1}.svg\"), format ='svg')\n",
    "    plt.savefig(os.path.join(DE_result_path, f\"adversarial_group_calibration_run_{id+1}.png\"), format ='png')\n",
    "    plt.close()\n",
    "\n",
    "# predictions_list enthält pro Run ein Array mit 10403 Werten\n",
    "mean_matrix = np.array(mean_list)  # Shape: (n_runs, 10403)\n",
    "std_matrix = np.array(std_list)    # Shape: (n_runs, 10403)\n",
    "\n",
    "# Mittelwert und Std für jeden Datenpunkt über alle Runs\n",
    "mean_per_datapoint = np.mean(mean_matrix, axis=0)  # Shape: (10403,)\n",
    "std_per_datapoint = np.mean(std_matrix, axis=0)    # Shape: (10403,)\n",
    "\n",
    "# calibration Curve with UCT\n",
    "uct.viz.plot_calibration(mean_per_datapoint, std_per_datapoint, y_test)\n",
    "plt.savefig(os.path.join(DE_result_path, \"calibration_run_mean.svg\"), format ='svg')\n",
    "plt.savefig(os.path.join(DE_result_path, \"calibration_run_mean.png\"), format ='png')\n",
    "plt.close()\n",
    "\n",
    "# adversarial group calibration\n",
    "uct.viz.plot_adversarial_group_calibration(mean_per_datapoint, std_per_datapoint, y_test)\n",
    "plt.savefig(os.path.join(DE_result_path, \"adversarial_group_calibration_run_mean.svg\"), format ='svg')\n",
    "plt.savefig(os.path.join(DE_result_path, \"adversarial_group_calibration_run_mean.png\"), format ='png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
